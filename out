// -----// IR Dump Before Inliner (inline) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc22 = loc("a_ptr"(#loc))
#loc23 = loc("b_ptr"(#loc))
#loc24 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0"} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %offs = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc25)
    %a = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc26)
    %a_0 = arith.constant 16 : i32 loc(#loc27)
    %a_1 = arith.constant 16 : i32 loc(#loc27)
    %a_2 = arith.constant dense<16> : tensor<16x1xi32> loc(#loc27)
    %a_3 = arith.extsi %a : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc27)
    %a_4 = arith.extsi %a_2 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc27)
    %a_5 = arith.muli %a_3, %a_4 : tensor<16x1xi64> loc(#loc27)
    %a_6 = arith.constant 2147483647 : i64 loc(#loc27)
    %a_7 = arith.constant -2147483648 : i64 loc(#loc27)
    %a_8 = arith.constant dense<2147483647> : tensor<16x1xi64> loc(#loc27)
    %a_9 = arith.cmpi sle, %a_5, %a_8 : tensor<16x1xi64> loc(#loc27)
    %a_10 = arith.constant dense<-2147483648> : tensor<16x1xi64> loc(#loc27)
    %a_11 = arith.cmpi sge, %a_5, %a_10 : tensor<16x1xi64> loc(#loc27)
    %a_12 = arith.andi %a_9, %a_11 : tensor<16x1xi1> loc(#loc27)
    %a_13 = arith.muli %a, %a_2 : tensor<16x1xi32> loc(#loc27)
    %a_14 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc28)
    %a_15 = tt.addptr %a_14, %a_13 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc28)
    %a_16 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc29)
    %a_17 = tt.broadcast %a_15 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc30)
    %a_18 = tt.broadcast %a_16 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc30)
    %a_19 = tt.addptr %a_17, %a_18 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc30)
    %a_20 = tt.load %a_19 : tensor<16x16x!tt.ptr<f16>> loc(#loc31)
    %b = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc32)
    %b_21 = arith.constant 16 : i32 loc(#loc33)
    %b_22 = arith.constant 16 : i32 loc(#loc33)
    %b_23 = arith.constant dense<16> : tensor<16x1xi32> loc(#loc33)
    %b_24 = arith.extsi %b : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc33)
    %b_25 = arith.extsi %b_23 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc33)
    %b_26 = arith.muli %b_24, %b_25 : tensor<16x1xi64> loc(#loc33)
    %b_27 = arith.constant 2147483647 : i64 loc(#loc33)
    %b_28 = arith.constant -2147483648 : i64 loc(#loc33)
    %b_29 = arith.constant dense<2147483647> : tensor<16x1xi64> loc(#loc33)
    %b_30 = arith.cmpi sle, %b_26, %b_29 : tensor<16x1xi64> loc(#loc33)
    %b_31 = arith.constant dense<-2147483648> : tensor<16x1xi64> loc(#loc33)
    %b_32 = arith.cmpi sge, %b_26, %b_31 : tensor<16x1xi64> loc(#loc33)
    %b_33 = arith.andi %b_30, %b_32 : tensor<16x1xi1> loc(#loc33)
    %b_34 = arith.muli %b, %b_23 : tensor<16x1xi32> loc(#loc33)
    %b_35 = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc34)
    %b_36 = tt.addptr %b_35, %b_34 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc34)
    %b_37 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc35)
    %b_38 = tt.broadcast %b_36 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc36)
    %b_39 = tt.broadcast %b_37 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc36)
    %b_40 = tt.addptr %b_38, %b_39 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc36)
    %b_41 = tt.load %b_40 : tensor<16x16x!tt.ptr<f16>> loc(#loc37)
    %c = arith.constant 0.000000e+00 : f32 loc(#loc38)
    %c_42 = arith.constant dense<0.000000e+00> : tensor<16x16xf32> loc(#loc38)
    %c_43 = tt.dot %a_20, %b_41, %c_42, inputPrecision = tf32 : tensor<16x16xf16> * tensor<16x16xf16> -> tensor<16x16xf32> loc(#loc38)
    %0 = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc15)
    %c16_i32 = arith.constant 16 : i32 loc(#loc16)
    %c16_i32_44 = arith.constant 16 : i32 loc(#loc16)
    %cst = arith.constant dense<16> : tensor<16x1xi32> loc(#loc16)
    %1 = arith.extsi %0 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc16)
    %2 = arith.extsi %cst : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc16)
    %3 = arith.muli %1, %2 : tensor<16x1xi64> loc(#loc16)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc16)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc16)
    %cst_45 = arith.constant dense<2147483647> : tensor<16x1xi64> loc(#loc16)
    %4 = arith.cmpi sle, %3, %cst_45 : tensor<16x1xi64> loc(#loc16)
    %cst_46 = arith.constant dense<-2147483648> : tensor<16x1xi64> loc(#loc16)
    %5 = arith.cmpi sge, %3, %cst_46 : tensor<16x1xi64> loc(#loc16)
    %6 = arith.andi %4, %5 : tensor<16x1xi1> loc(#loc16)
    %7 = arith.muli %0, %cst : tensor<16x1xi32> loc(#loc16)
    %8 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc17)
    %9 = tt.addptr %8, %7 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc17)
    %10 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc18)
    %11 = tt.broadcast %9 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc19)
    %12 = tt.broadcast %10 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc19)
    %13 = tt.addptr %11, %12 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc19)
    %14 = arith.truncf %c_43 : tensor<16x16xf32> to tensor<16x16xf16> loc(#loc20)
    tt.store %13, %14 : tensor<16x16x!tt.ptr<f16>> loc(#loc20)
    tt.return loc(#loc21)
  } loc(#loc)
} loc(#loc)
#loc1 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":18:24)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:29)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:40)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:50)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:26)
#loc16 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:37)
#loc17 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc18 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:47)
#loc19 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc20 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc21 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc25 = loc("offs"(#loc1))
#loc26 = loc("a"(#loc2))
#loc27 = loc("a"(#loc3))
#loc28 = loc("a"(#loc4))
#loc29 = loc("a"(#loc5))
#loc30 = loc("a"(#loc6))
#loc31 = loc("a"(#loc7))
#loc32 = loc("b"(#loc8))
#loc33 = loc("b"(#loc9))
#loc34 = loc("b"(#loc10))
#loc35 = loc("b"(#loc11))
#loc36 = loc("b"(#loc12))
#loc37 = loc("b"(#loc13))
#loc38 = loc("c"(#loc14))


// -----// IR Dump Before Canonicalizer (canonicalize) ('tt.func' operation: @tiny_matmul_kernel) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc22 = loc("a_ptr"(#loc))
#loc23 = loc("b_ptr"(#loc))
#loc24 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0"} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %offs = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc25)
    %a = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc26)
    %a_0 = arith.constant 16 : i32 loc(#loc27)
    %a_1 = arith.constant 16 : i32 loc(#loc27)
    %a_2 = arith.constant dense<16> : tensor<16x1xi32> loc(#loc27)
    %a_3 = arith.extsi %a : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc27)
    %a_4 = arith.extsi %a_2 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc27)
    %a_5 = arith.muli %a_3, %a_4 : tensor<16x1xi64> loc(#loc27)
    %a_6 = arith.constant 2147483647 : i64 loc(#loc27)
    %a_7 = arith.constant -2147483648 : i64 loc(#loc27)
    %a_8 = arith.constant dense<2147483647> : tensor<16x1xi64> loc(#loc27)
    %a_9 = arith.cmpi sle, %a_5, %a_8 : tensor<16x1xi64> loc(#loc27)
    %a_10 = arith.constant dense<-2147483648> : tensor<16x1xi64> loc(#loc27)
    %a_11 = arith.cmpi sge, %a_5, %a_10 : tensor<16x1xi64> loc(#loc27)
    %a_12 = arith.andi %a_9, %a_11 : tensor<16x1xi1> loc(#loc27)
    %a_13 = arith.muli %a, %a_2 : tensor<16x1xi32> loc(#loc27)
    %a_14 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc28)
    %a_15 = tt.addptr %a_14, %a_13 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc28)
    %a_16 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc29)
    %a_17 = tt.broadcast %a_15 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc30)
    %a_18 = tt.broadcast %a_16 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc30)
    %a_19 = tt.addptr %a_17, %a_18 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc30)
    %a_20 = tt.load %a_19 : tensor<16x16x!tt.ptr<f16>> loc(#loc31)
    %b = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc32)
    %b_21 = arith.constant 16 : i32 loc(#loc33)
    %b_22 = arith.constant 16 : i32 loc(#loc33)
    %b_23 = arith.constant dense<16> : tensor<16x1xi32> loc(#loc33)
    %b_24 = arith.extsi %b : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc33)
    %b_25 = arith.extsi %b_23 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc33)
    %b_26 = arith.muli %b_24, %b_25 : tensor<16x1xi64> loc(#loc33)
    %b_27 = arith.constant 2147483647 : i64 loc(#loc33)
    %b_28 = arith.constant -2147483648 : i64 loc(#loc33)
    %b_29 = arith.constant dense<2147483647> : tensor<16x1xi64> loc(#loc33)
    %b_30 = arith.cmpi sle, %b_26, %b_29 : tensor<16x1xi64> loc(#loc33)
    %b_31 = arith.constant dense<-2147483648> : tensor<16x1xi64> loc(#loc33)
    %b_32 = arith.cmpi sge, %b_26, %b_31 : tensor<16x1xi64> loc(#loc33)
    %b_33 = arith.andi %b_30, %b_32 : tensor<16x1xi1> loc(#loc33)
    %b_34 = arith.muli %b, %b_23 : tensor<16x1xi32> loc(#loc33)
    %b_35 = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc34)
    %b_36 = tt.addptr %b_35, %b_34 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc34)
    %b_37 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc35)
    %b_38 = tt.broadcast %b_36 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc36)
    %b_39 = tt.broadcast %b_37 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc36)
    %b_40 = tt.addptr %b_38, %b_39 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc36)
    %b_41 = tt.load %b_40 : tensor<16x16x!tt.ptr<f16>> loc(#loc37)
    %c = arith.constant 0.000000e+00 : f32 loc(#loc38)
    %c_42 = arith.constant dense<0.000000e+00> : tensor<16x16xf32> loc(#loc38)
    %c_43 = tt.dot %a_20, %b_41, %c_42, inputPrecision = tf32 : tensor<16x16xf16> * tensor<16x16xf16> -> tensor<16x16xf32> loc(#loc38)
    %0 = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc15)
    %c16_i32 = arith.constant 16 : i32 loc(#loc16)
    %c16_i32_44 = arith.constant 16 : i32 loc(#loc16)
    %cst = arith.constant dense<16> : tensor<16x1xi32> loc(#loc16)
    %1 = arith.extsi %0 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc16)
    %2 = arith.extsi %cst : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc16)
    %3 = arith.muli %1, %2 : tensor<16x1xi64> loc(#loc16)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc16)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc16)
    %cst_45 = arith.constant dense<2147483647> : tensor<16x1xi64> loc(#loc16)
    %4 = arith.cmpi sle, %3, %cst_45 : tensor<16x1xi64> loc(#loc16)
    %cst_46 = arith.constant dense<-2147483648> : tensor<16x1xi64> loc(#loc16)
    %5 = arith.cmpi sge, %3, %cst_46 : tensor<16x1xi64> loc(#loc16)
    %6 = arith.andi %4, %5 : tensor<16x1xi1> loc(#loc16)
    %7 = arith.muli %0, %cst : tensor<16x1xi32> loc(#loc16)
    %8 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc17)
    %9 = tt.addptr %8, %7 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc17)
    %10 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc18)
    %11 = tt.broadcast %9 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc19)
    %12 = tt.broadcast %10 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc19)
    %13 = tt.addptr %11, %12 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc19)
    %14 = arith.truncf %c_43 : tensor<16x16xf32> to tensor<16x16xf16> loc(#loc20)
    tt.store %13, %14 : tensor<16x16x!tt.ptr<f16>> loc(#loc20)
    tt.return loc(#loc21)
  } loc(#loc)
} loc(#loc)
#loc1 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":18:24)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:29)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:40)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:50)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:26)
#loc16 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:37)
#loc17 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc18 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:47)
#loc19 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc20 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc21 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc25 = loc("offs"(#loc1))
#loc26 = loc("a"(#loc2))
#loc27 = loc("a"(#loc3))
#loc28 = loc("a"(#loc4))
#loc29 = loc("a"(#loc5))
#loc30 = loc("a"(#loc6))
#loc31 = loc("a"(#loc7))
#loc32 = loc("b"(#loc8))
#loc33 = loc("b"(#loc9))
#loc34 = loc("b"(#loc10))
#loc35 = loc("b"(#loc11))
#loc36 = loc("b"(#loc12))
#loc37 = loc("b"(#loc13))
#loc38 = loc("c"(#loc14))


// -----// IR Dump Before TritonRewriteTensorPointer (triton-rewrite-tensor-pointer) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc23 = loc("a_ptr"(#loc))
#loc24 = loc("b_ptr"(#loc))
#loc25 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0"} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32> loc(#loc1)
    %offs = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc26)
    %a = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc27)
    %a_1 = arith.muli %a, %cst_0 : tensor<16x1xi32> loc(#loc28)
    %a_2 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc29)
    %a_3 = tt.addptr %a_2, %a_1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc29)
    %a_4 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc30)
    %a_5 = tt.broadcast %a_3 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc31)
    %a_6 = tt.broadcast %a_4 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc31)
    %a_7 = tt.addptr %a_5, %a_6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc31)
    %a_8 = tt.load %a_7 : tensor<16x16x!tt.ptr<f16>> loc(#loc32)
    %b = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc33)
    %b_9 = arith.muli %b, %cst_0 : tensor<16x1xi32> loc(#loc34)
    %b_10 = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc35)
    %b_11 = tt.addptr %b_10, %b_9 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc35)
    %b_12 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc36)
    %b_13 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc37)
    %b_14 = tt.broadcast %b_12 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc37)
    %b_15 = tt.addptr %b_13, %b_14 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc37)
    %b_16 = tt.load %b_15 : tensor<16x16x!tt.ptr<f16>> loc(#loc38)
    %c = tt.dot %a_8, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16> * tensor<16x16xf16> -> tensor<16x16xf32> loc(#loc39)
    %0 = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc16)
    %1 = arith.muli %0, %cst_0 : tensor<16x1xi32> loc(#loc17)
    %2 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc18)
    %3 = tt.addptr %2, %1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc18)
    %4 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc19)
    %5 = tt.broadcast %3 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc20)
    %6 = tt.broadcast %4 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc20)
    %7 = tt.addptr %5, %6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc20)
    %8 = arith.truncf %c : tensor<16x16xf32> to tensor<16x16xf16> loc(#loc21)
    tt.store %7, %8 : tensor<16x16x!tt.ptr<f16>> loc(#loc21)
    tt.return loc(#loc22)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":18:24)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:29)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:40)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:50)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc16 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:26)
#loc17 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:37)
#loc18 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc19 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:47)
#loc20 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc21 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc22 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc26 = loc("offs"(#loc2))
#loc27 = loc("a"(#loc3))
#loc28 = loc("a"(#loc4))
#loc29 = loc("a"(#loc5))
#loc30 = loc("a"(#loc6))
#loc31 = loc("a"(#loc7))
#loc32 = loc("a"(#loc8))
#loc33 = loc("b"(#loc9))
#loc34 = loc("b"(#loc10))
#loc35 = loc("b"(#loc11))
#loc36 = loc("b"(#loc12))
#loc37 = loc("b"(#loc13))
#loc38 = loc("b"(#loc14))
#loc39 = loc("c"(#loc15))


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc23 = loc("a_ptr"(#loc))
#loc24 = loc("b_ptr"(#loc))
#loc25 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0"} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32> loc(#loc1)
    %offs = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc26)
    %a = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc27)
    %a_1 = arith.muli %a, %cst_0 : tensor<16x1xi32> loc(#loc28)
    %a_2 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc29)
    %a_3 = tt.addptr %a_2, %a_1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc29)
    %a_4 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc30)
    %a_5 = tt.broadcast %a_3 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc31)
    %a_6 = tt.broadcast %a_4 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc31)
    %a_7 = tt.addptr %a_5, %a_6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc31)
    %a_8 = tt.load %a_7 : tensor<16x16x!tt.ptr<f16>> loc(#loc32)
    %b = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc33)
    %b_9 = arith.muli %b, %cst_0 : tensor<16x1xi32> loc(#loc34)
    %b_10 = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc35)
    %b_11 = tt.addptr %b_10, %b_9 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc35)
    %b_12 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc36)
    %b_13 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc37)
    %b_14 = tt.broadcast %b_12 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc37)
    %b_15 = tt.addptr %b_13, %b_14 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc37)
    %b_16 = tt.load %b_15 : tensor<16x16x!tt.ptr<f16>> loc(#loc38)
    %c = tt.dot %a_8, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16> * tensor<16x16xf16> -> tensor<16x16xf32> loc(#loc39)
    %0 = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc16)
    %1 = arith.muli %0, %cst_0 : tensor<16x1xi32> loc(#loc17)
    %2 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc18)
    %3 = tt.addptr %2, %1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc18)
    %4 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc19)
    %5 = tt.broadcast %3 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc20)
    %6 = tt.broadcast %4 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc20)
    %7 = tt.addptr %5, %6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc20)
    %8 = arith.truncf %c : tensor<16x16xf32> to tensor<16x16xf16> loc(#loc21)
    tt.store %7, %8 : tensor<16x16x!tt.ptr<f16>> loc(#loc21)
    tt.return loc(#loc22)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":18:24)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:29)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:40)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:50)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc16 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:26)
#loc17 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:37)
#loc18 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc19 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:47)
#loc20 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc21 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc22 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc26 = loc("offs"(#loc2))
#loc27 = loc("a"(#loc3))
#loc28 = loc("a"(#loc4))
#loc29 = loc("a"(#loc5))
#loc30 = loc("a"(#loc6))
#loc31 = loc("a"(#loc7))
#loc32 = loc("a"(#loc8))
#loc33 = loc("b"(#loc9))
#loc34 = loc("b"(#loc10))
#loc35 = loc("b"(#loc11))
#loc36 = loc("b"(#loc12))
#loc37 = loc("b"(#loc13))
#loc38 = loc("b"(#loc14))
#loc39 = loc("c"(#loc15))


// -----// IR Dump Before TritonCombineOps (triton-combine) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc23 = loc("a_ptr"(#loc))
#loc24 = loc("b_ptr"(#loc))
#loc25 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0"} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32> loc(#loc1)
    %offs = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc26)
    %a = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc27)
    %a_1 = arith.muli %a, %cst_0 : tensor<16x1xi32> loc(#loc28)
    %a_2 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc29)
    %a_3 = tt.addptr %a_2, %a_1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc29)
    %a_4 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc30)
    %a_5 = tt.broadcast %a_3 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc31)
    %a_6 = tt.broadcast %a_4 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc31)
    %a_7 = tt.addptr %a_5, %a_6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc31)
    %a_8 = tt.load %a_7 : tensor<16x16x!tt.ptr<f16>> loc(#loc32)
    %b = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc33)
    %b_9 = arith.muli %b, %cst_0 : tensor<16x1xi32> loc(#loc34)
    %b_10 = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc35)
    %b_11 = tt.addptr %b_10, %b_9 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc35)
    %b_12 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc36)
    %b_13 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc37)
    %b_14 = tt.broadcast %b_12 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc37)
    %b_15 = tt.addptr %b_13, %b_14 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc37)
    %b_16 = tt.load %b_15 : tensor<16x16x!tt.ptr<f16>> loc(#loc38)
    %c = tt.dot %a_8, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16> * tensor<16x16xf16> -> tensor<16x16xf32> loc(#loc39)
    %0 = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc16)
    %1 = arith.muli %0, %cst_0 : tensor<16x1xi32> loc(#loc17)
    %2 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc18)
    %3 = tt.addptr %2, %1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc18)
    %4 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc19)
    %5 = tt.broadcast %3 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc20)
    %6 = tt.broadcast %4 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc20)
    %7 = tt.addptr %5, %6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc20)
    %8 = arith.truncf %c : tensor<16x16xf32> to tensor<16x16xf16> loc(#loc21)
    tt.store %7, %8 : tensor<16x16x!tt.ptr<f16>> loc(#loc21)
    tt.return loc(#loc22)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":18:24)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:29)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:40)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:50)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc16 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:26)
#loc17 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:37)
#loc18 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc19 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:47)
#loc20 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc21 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc22 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc26 = loc("offs"(#loc2))
#loc27 = loc("a"(#loc3))
#loc28 = loc("a"(#loc4))
#loc29 = loc("a"(#loc5))
#loc30 = loc("a"(#loc6))
#loc31 = loc("a"(#loc7))
#loc32 = loc("a"(#loc8))
#loc33 = loc("b"(#loc9))
#loc34 = loc("b"(#loc10))
#loc35 = loc("b"(#loc11))
#loc36 = loc("b"(#loc12))
#loc37 = loc("b"(#loc13))
#loc38 = loc("b"(#loc14))
#loc39 = loc("c"(#loc15))


// -----// IR Dump Before TritonReorderBroadcast (triton-reorder-broadcast) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc23 = loc("a_ptr"(#loc))
#loc24 = loc("b_ptr"(#loc))
#loc25 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0"} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32> loc(#loc1)
    %offs = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc26)
    %a = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc27)
    %a_1 = arith.muli %a, %cst_0 : tensor<16x1xi32> loc(#loc28)
    %a_2 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc29)
    %a_3 = tt.addptr %a_2, %a_1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc29)
    %a_4 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc30)
    %a_5 = tt.broadcast %a_3 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc31)
    %a_6 = tt.broadcast %a_4 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc31)
    %a_7 = tt.addptr %a_5, %a_6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc31)
    %a_8 = tt.load %a_7 : tensor<16x16x!tt.ptr<f16>> loc(#loc32)
    %b = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc33)
    %b_9 = arith.muli %b, %cst_0 : tensor<16x1xi32> loc(#loc34)
    %b_10 = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc35)
    %b_11 = tt.addptr %b_10, %b_9 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc35)
    %b_12 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc36)
    %b_13 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc37)
    %b_14 = tt.broadcast %b_12 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc37)
    %b_15 = tt.addptr %b_13, %b_14 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc37)
    %b_16 = tt.load %b_15 : tensor<16x16x!tt.ptr<f16>> loc(#loc38)
    %c = tt.dot %a_8, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16> * tensor<16x16xf16> -> tensor<16x16xf32> loc(#loc39)
    %0 = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc16)
    %1 = arith.muli %0, %cst_0 : tensor<16x1xi32> loc(#loc17)
    %2 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc18)
    %3 = tt.addptr %2, %1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc18)
    %4 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc19)
    %5 = tt.broadcast %3 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc20)
    %6 = tt.broadcast %4 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc20)
    %7 = tt.addptr %5, %6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc20)
    %8 = arith.truncf %c : tensor<16x16xf32> to tensor<16x16xf16> loc(#loc21)
    tt.store %7, %8 : tensor<16x16x!tt.ptr<f16>> loc(#loc21)
    tt.return loc(#loc22)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":18:24)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:29)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:40)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:50)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc16 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:26)
#loc17 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:37)
#loc18 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc19 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:47)
#loc20 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc21 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc22 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc26 = loc("offs"(#loc2))
#loc27 = loc("a"(#loc3))
#loc28 = loc("a"(#loc4))
#loc29 = loc("a"(#loc5))
#loc30 = loc("a"(#loc6))
#loc31 = loc("a"(#loc7))
#loc32 = loc("a"(#loc8))
#loc33 = loc("b"(#loc9))
#loc34 = loc("b"(#loc10))
#loc35 = loc("b"(#loc11))
#loc36 = loc("b"(#loc12))
#loc37 = loc("b"(#loc13))
#loc38 = loc("b"(#loc14))
#loc39 = loc("c"(#loc15))


// -----// IR Dump Before CSE (cse) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc23 = loc("a_ptr"(#loc))
#loc24 = loc("b_ptr"(#loc))
#loc25 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0"} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32> loc(#loc1)
    %offs = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc26)
    %a = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc27)
    %a_1 = arith.muli %a, %cst_0 : tensor<16x1xi32> loc(#loc28)
    %a_2 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc29)
    %a_3 = tt.addptr %a_2, %a_1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc29)
    %a_4 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc30)
    %a_5 = tt.broadcast %a_3 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc31)
    %a_6 = tt.broadcast %a_4 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc31)
    %a_7 = tt.addptr %a_5, %a_6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc31)
    %a_8 = tt.load %a_7 : tensor<16x16x!tt.ptr<f16>> loc(#loc32)
    %b = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc33)
    %b_9 = arith.muli %b, %cst_0 : tensor<16x1xi32> loc(#loc34)
    %b_10 = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc35)
    %b_11 = tt.addptr %b_10, %b_9 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc35)
    %b_12 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc36)
    %b_13 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc37)
    %b_14 = tt.broadcast %b_12 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc37)
    %b_15 = tt.addptr %b_13, %b_14 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc37)
    %b_16 = tt.load %b_15 : tensor<16x16x!tt.ptr<f16>> loc(#loc38)
    %c = tt.dot %a_8, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16> * tensor<16x16xf16> -> tensor<16x16xf32> loc(#loc39)
    %0 = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc16)
    %1 = arith.muli %0, %cst_0 : tensor<16x1xi32> loc(#loc17)
    %2 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc18)
    %3 = tt.addptr %2, %1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc18)
    %4 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc19)
    %5 = tt.broadcast %3 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc20)
    %6 = tt.broadcast %4 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc20)
    %7 = tt.addptr %5, %6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc20)
    %8 = arith.truncf %c : tensor<16x16xf32> to tensor<16x16xf16> loc(#loc21)
    tt.store %7, %8 : tensor<16x16x!tt.ptr<f16>> loc(#loc21)
    tt.return loc(#loc22)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":18:24)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:29)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:40)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:50)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc16 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:26)
#loc17 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:37)
#loc18 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc19 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:47)
#loc20 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc21 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc22 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc26 = loc("offs"(#loc2))
#loc27 = loc("a"(#loc3))
#loc28 = loc("a"(#loc4))
#loc29 = loc("a"(#loc5))
#loc30 = loc("a"(#loc6))
#loc31 = loc("a"(#loc7))
#loc32 = loc("a"(#loc8))
#loc33 = loc("b"(#loc9))
#loc34 = loc("b"(#loc10))
#loc35 = loc("b"(#loc11))
#loc36 = loc("b"(#loc12))
#loc37 = loc("b"(#loc13))
#loc38 = loc("b"(#loc14))
#loc39 = loc("c"(#loc15))


// -----// IR Dump Before SymbolDCE (symbol-dce) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc17 = loc("a_ptr"(#loc))
#loc18 = loc("b_ptr"(#loc))
#loc19 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0"} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32> loc(#loc1)
    %offs = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc20)
    %a = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc21)
    %a_1 = arith.muli %a, %cst_0 : tensor<16x1xi32> loc(#loc22)
    %a_2 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc23)
    %a_3 = tt.addptr %a_2, %a_1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc23)
    %a_4 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc24)
    %a_5 = tt.broadcast %a_3 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc25)
    %a_6 = tt.broadcast %a_4 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc25)
    %a_7 = tt.addptr %a_5, %a_6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc25)
    %a_8 = tt.load %a_7 : tensor<16x16x!tt.ptr<f16>> loc(#loc26)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc27)
    %b_9 = tt.addptr %b, %a_1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc27)
    %b_10 = tt.broadcast %b_9 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc28)
    %b_11 = tt.addptr %b_10, %a_6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc28)
    %b_12 = tt.load %b_11 : tensor<16x16x!tt.ptr<f16>> loc(#loc29)
    %c = tt.dot %a_8, %b_12, %cst, inputPrecision = tf32 : tensor<16x16xf16> * tensor<16x16xf16> -> tensor<16x16xf32> loc(#loc30)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc13)
    %1 = tt.addptr %0, %a_1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc13)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc14)
    %3 = tt.addptr %2, %a_6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc14)
    %4 = arith.truncf %c : tensor<16x16xf32> to tensor<16x16xf16> loc(#loc15)
    tt.store %3, %4 : tensor<16x16x!tt.ptr<f16>> loc(#loc15)
    tt.return loc(#loc16)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":18:24)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc16 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc20 = loc("offs"(#loc2))
#loc21 = loc("a"(#loc3))
#loc22 = loc("a"(#loc4))
#loc23 = loc("a"(#loc5))
#loc24 = loc("a"(#loc6))
#loc25 = loc("a"(#loc7))
#loc26 = loc("a"(#loc8))
#loc27 = loc("b"(#loc9))
#loc28 = loc("b"(#loc10))
#loc29 = loc("b"(#loc11))
#loc30 = loc("c"(#loc12))


// -----// IR Dump Before TritonLoopUnroll (triton-loop-unroll) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc17 = loc("a_ptr"(#loc))
#loc18 = loc("b_ptr"(#loc))
#loc19 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0"} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32> loc(#loc1)
    %offs = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc20)
    %a = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc21)
    %a_1 = arith.muli %a, %cst_0 : tensor<16x1xi32> loc(#loc22)
    %a_2 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc23)
    %a_3 = tt.addptr %a_2, %a_1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc23)
    %a_4 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc24)
    %a_5 = tt.broadcast %a_3 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc25)
    %a_6 = tt.broadcast %a_4 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc25)
    %a_7 = tt.addptr %a_5, %a_6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc25)
    %a_8 = tt.load %a_7 : tensor<16x16x!tt.ptr<f16>> loc(#loc26)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc27)
    %b_9 = tt.addptr %b, %a_1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc27)
    %b_10 = tt.broadcast %b_9 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc28)
    %b_11 = tt.addptr %b_10, %a_6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc28)
    %b_12 = tt.load %b_11 : tensor<16x16x!tt.ptr<f16>> loc(#loc29)
    %c = tt.dot %a_8, %b_12, %cst, inputPrecision = tf32 : tensor<16x16xf16> * tensor<16x16xf16> -> tensor<16x16xf32> loc(#loc30)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc13)
    %1 = tt.addptr %0, %a_1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc13)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc14)
    %3 = tt.addptr %2, %a_6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc14)
    %4 = arith.truncf %c : tensor<16x16xf32> to tensor<16x16xf16> loc(#loc15)
    tt.store %3, %4 : tensor<16x16x!tt.ptr<f16>> loc(#loc15)
    tt.return loc(#loc16)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":18:24)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc16 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc20 = loc("offs"(#loc2))
#loc21 = loc("a"(#loc3))
#loc22 = loc("a"(#loc4))
#loc23 = loc("a"(#loc5))
#loc24 = loc("a"(#loc6))
#loc25 = loc("a"(#loc7))
#loc26 = loc("a"(#loc8))
#loc27 = loc("b"(#loc9))
#loc28 = loc("b"(#loc10))
#loc29 = loc("b"(#loc11))
#loc30 = loc("c"(#loc12))


// -----// IR Dump Before ConvertTritonToTritonGPU (convert-triton-to-tritongpu) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc17 = loc("a_ptr"(#loc))
#loc18 = loc("b_ptr"(#loc))
#loc19 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0"} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32> loc(#loc1)
    %offs = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc20)
    %a = tt.expand_dims %offs {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc21)
    %a_1 = arith.muli %a, %cst_0 : tensor<16x1xi32> loc(#loc22)
    %a_2 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc23)
    %a_3 = tt.addptr %a_2, %a_1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc23)
    %a_4 = tt.expand_dims %offs {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc24)
    %a_5 = tt.broadcast %a_3 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc25)
    %a_6 = tt.broadcast %a_4 : tensor<1x16xi32> -> tensor<16x16xi32> loc(#loc25)
    %a_7 = tt.addptr %a_5, %a_6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc25)
    %a_8 = tt.load %a_7 : tensor<16x16x!tt.ptr<f16>> loc(#loc26)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc27)
    %b_9 = tt.addptr %b, %a_1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc27)
    %b_10 = tt.broadcast %b_9 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc28)
    %b_11 = tt.addptr %b_10, %a_6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc28)
    %b_12 = tt.load %b_11 : tensor<16x16x!tt.ptr<f16>> loc(#loc29)
    %c = tt.dot %a_8, %b_12, %cst, inputPrecision = tf32 : tensor<16x16xf16> * tensor<16x16xf16> -> tensor<16x16xf32> loc(#loc30)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>> loc(#loc13)
    %1 = tt.addptr %0, %a_1 : tensor<16x1x!tt.ptr<f16>>, tensor<16x1xi32> loc(#loc13)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>> -> tensor<16x16x!tt.ptr<f16>> loc(#loc14)
    %3 = tt.addptr %2, %a_6 : tensor<16x16x!tt.ptr<f16>>, tensor<16x16xi32> loc(#loc14)
    %4 = arith.truncf %c : tensor<16x16xf32> to tensor<16x16xf16> loc(#loc15)
    tt.store %3, %4 : tensor<16x16x!tt.ptr<f16>> loc(#loc15)
    tt.return loc(#loc16)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":18:24)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc16 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc20 = loc("offs"(#loc2))
#loc21 = loc("a"(#loc3))
#loc22 = loc("a"(#loc4))
#loc23 = loc("a"(#loc5))
#loc24 = loc("a"(#loc6))
#loc25 = loc("a"(#loc7))
#loc26 = loc("a"(#loc8))
#loc27 = loc("b"(#loc9))
#loc28 = loc("b"(#loc10))
#loc29 = loc("b"(#loc11))
#loc30 = loc("c"(#loc12))


// -----// IR Dump Before TritonGPUCoalesce (tritongpu-coalesce) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc17 = loc("a_ptr"(#loc))
#loc18 = loc("b_ptr"(#loc))
#loc19 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked1> loc(#loc1)
    %offs = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #blocked2> loc(#loc20)
    %a = ttg.convert_layout %offs : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc21)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<16x1xi32, #blocked3> loc(#loc21)
    %a_2 = ttg.convert_layout %a_1 : tensor<16x1xi32, #blocked3> -> tensor<16x1xi32, #blocked1> loc(#loc22)
    %a_3 = arith.muli %a_2, %cst_0 : tensor<16x1xi32, #blocked1> loc(#loc22)
    %a_4 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc23)
    %a_5 = tt.addptr %a_4, %a_3 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc23)
    %a_6 = ttg.convert_layout %offs : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked4}>> loc(#loc24)
    %a_7 = tt.expand_dims %a_6 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked4}>> -> tensor<1x16xi32, #blocked4> loc(#loc24)
    %a_8 = ttg.convert_layout %a_7 : tensor<1x16xi32, #blocked4> -> tensor<1x16xi32, #blocked> loc(#loc25)
    %a_9 = tt.broadcast %a_5 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc25)
    %a_10 = ttg.convert_layout %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc25)
    %a_11 = tt.broadcast %a_8 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc25)
    %a_12 = tt.addptr %a_10, %a_11 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc25)
    %a_13 = tt.load %a_12 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc27)
    %b_14 = tt.addptr %b, %a_3 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc27)
    %b_15 = tt.broadcast %b_14 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc28)
    %b_16 = ttg.convert_layout %b_15 : tensor<16x16x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc28)
    %b_17 = tt.addptr %b_16, %a_11 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc28)
    %b_18 = tt.load %b_17 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc29)
    %a_19 = ttg.convert_layout %a_13 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #blocked}>> loc(#loc26)
    %b_20 = ttg.convert_layout %b_18 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked}>> loc(#loc29)
    %0 = ttg.convert_layout %cst : tensor<16x16xf32, #blocked> -> tensor<16x16xf32, #blocked> loc(#loc1)
    %c = tt.dot %a_19, %b_20, %0, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #blocked}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked}>> -> tensor<16x16xf32, #blocked> loc(#loc30)
    %1 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc13)
    %2 = tt.addptr %1, %a_3 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc13)
    %3 = tt.broadcast %2 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc14)
    %4 = ttg.convert_layout %3 : tensor<16x16x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    %5 = tt.addptr %4, %a_11 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc14)
    %6 = arith.truncf %c : tensor<16x16xf32, #blocked> to tensor<16x16xf16, #blocked> loc(#loc15)
    tt.store %5, %6 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc15)
    tt.return loc(#loc16)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":18:24)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc16 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc20 = loc("offs"(#loc2))
#loc21 = loc("a"(#loc3))
#loc22 = loc("a"(#loc4))
#loc23 = loc("a"(#loc5))
#loc24 = loc("a"(#loc6))
#loc25 = loc("a"(#loc7))
#loc26 = loc("a"(#loc8))
#loc27 = loc("b"(#loc9))
#loc28 = loc("b"(#loc10))
#loc29 = loc("b"(#loc11))
#loc30 = loc("c"(#loc12))


// -----// IR Dump Before TritonGPUF32DotTC (tritongpu-F32DotTC) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked5 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc17 = loc("a_ptr"(#loc))
#loc18 = loc("b_ptr"(#loc))
#loc19 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked1> loc(#loc1)
    %offs = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #blocked2> loc(#loc20)
    %a = ttg.convert_layout %offs : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc21)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<16x1xi32, #blocked3> loc(#loc21)
    %a_2 = ttg.convert_layout %a_1 : tensor<16x1xi32, #blocked3> -> tensor<16x1xi32, #blocked1> loc(#loc22)
    %a_3 = arith.muli %a_2, %cst_0 : tensor<16x1xi32, #blocked1> loc(#loc22)
    %a_4 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc23)
    %a_5 = tt.addptr %a_4, %a_3 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc23)
    %a_6 = ttg.convert_layout %offs : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked4}>> loc(#loc24)
    %a_7 = tt.expand_dims %a_6 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked4}>> -> tensor<1x16xi32, #blocked4> loc(#loc24)
    %a_8 = ttg.convert_layout %a_7 : tensor<1x16xi32, #blocked4> -> tensor<1x16xi32, #blocked> loc(#loc25)
    %a_9 = tt.broadcast %a_5 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc25)
    %a_10 = ttg.convert_layout %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc25)
    %a_11 = tt.broadcast %a_8 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc25)
    %a_12 = tt.addptr %a_10, %a_11 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc25)
    %a_13 = ttg.convert_layout %a_12 : tensor<16x16x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc26)
    %a_14 = tt.load %a_13 : tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc26)
    %a_15 = ttg.convert_layout %a_14 : tensor<16x16xf16, #blocked5> -> tensor<16x16xf16, #blocked> loc(#loc26)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc27)
    %b_16 = tt.addptr %b, %a_3 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc27)
    %b_17 = tt.broadcast %b_16 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc28)
    %b_18 = ttg.convert_layout %b_17 : tensor<16x16x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc28)
    %b_19 = tt.addptr %b_18, %a_11 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc28)
    %b_20 = ttg.convert_layout %b_19 : tensor<16x16x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc29)
    %b_21 = tt.load %b_20 : tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc29)
    %b_22 = ttg.convert_layout %b_21 : tensor<16x16xf16, #blocked5> -> tensor<16x16xf16, #blocked> loc(#loc29)
    %a_23 = ttg.convert_layout %a_15 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #blocked}>> loc(#loc26)
    %b_24 = ttg.convert_layout %b_22 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked}>> loc(#loc29)
    %0 = ttg.convert_layout %cst : tensor<16x16xf32, #blocked> -> tensor<16x16xf32, #blocked> loc(#loc1)
    %c = tt.dot %a_23, %b_24, %0, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #blocked}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked}>> -> tensor<16x16xf32, #blocked> loc(#loc30)
    %1 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc13)
    %2 = tt.addptr %1, %a_3 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc13)
    %3 = tt.broadcast %2 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc14)
    %4 = ttg.convert_layout %3 : tensor<16x16x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    %5 = tt.addptr %4, %a_11 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc14)
    %6 = arith.truncf %c : tensor<16x16xf32, #blocked> to tensor<16x16xf16, #blocked> loc(#loc15)
    %7 = ttg.convert_layout %5 : tensor<16x16x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc15)
    %8 = ttg.convert_layout %6 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #blocked5> loc(#loc15)
    tt.store %7, %8 : tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc15)
    tt.return loc(#loc16)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":18:24)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc16 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc20 = loc("offs"(#loc2))
#loc21 = loc("a"(#loc3))
#loc22 = loc("a"(#loc4))
#loc23 = loc("a"(#loc5))
#loc24 = loc("a"(#loc6))
#loc25 = loc("a"(#loc7))
#loc26 = loc("a"(#loc8))
#loc27 = loc("b"(#loc9))
#loc28 = loc("b"(#loc10))
#loc29 = loc("b"(#loc11))
#loc30 = loc("c"(#loc12))


// -----// IR Dump Before TritonGPUPlanCTAPass (triton-nvidia-gpu-plan-cta) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked5 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc17 = loc("a_ptr"(#loc))
#loc18 = loc("b_ptr"(#loc))
#loc19 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked1> loc(#loc1)
    %offs = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #blocked2> loc(#loc20)
    %a = ttg.convert_layout %offs : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc21)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<16x1xi32, #blocked3> loc(#loc21)
    %a_2 = ttg.convert_layout %a_1 : tensor<16x1xi32, #blocked3> -> tensor<16x1xi32, #blocked1> loc(#loc22)
    %a_3 = arith.muli %a_2, %cst_0 : tensor<16x1xi32, #blocked1> loc(#loc22)
    %a_4 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc23)
    %a_5 = tt.addptr %a_4, %a_3 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc23)
    %a_6 = ttg.convert_layout %offs : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked4}>> loc(#loc24)
    %a_7 = tt.expand_dims %a_6 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked4}>> -> tensor<1x16xi32, #blocked4> loc(#loc24)
    %a_8 = ttg.convert_layout %a_7 : tensor<1x16xi32, #blocked4> -> tensor<1x16xi32, #blocked> loc(#loc25)
    %a_9 = tt.broadcast %a_5 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc25)
    %a_10 = ttg.convert_layout %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc25)
    %a_11 = tt.broadcast %a_8 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc25)
    %a_12 = tt.addptr %a_10, %a_11 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc25)
    %a_13 = ttg.convert_layout %a_12 : tensor<16x16x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc26)
    %a_14 = tt.load %a_13 : tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc26)
    %a_15 = ttg.convert_layout %a_14 : tensor<16x16xf16, #blocked5> -> tensor<16x16xf16, #blocked> loc(#loc26)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc27)
    %b_16 = tt.addptr %b, %a_3 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc27)
    %b_17 = tt.broadcast %b_16 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc28)
    %b_18 = ttg.convert_layout %b_17 : tensor<16x16x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc28)
    %b_19 = tt.addptr %b_18, %a_11 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc28)
    %b_20 = ttg.convert_layout %b_19 : tensor<16x16x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc29)
    %b_21 = tt.load %b_20 : tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc29)
    %b_22 = ttg.convert_layout %b_21 : tensor<16x16xf16, #blocked5> -> tensor<16x16xf16, #blocked> loc(#loc29)
    %a_23 = ttg.convert_layout %a_15 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #blocked}>> loc(#loc26)
    %b_24 = ttg.convert_layout %b_22 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked}>> loc(#loc29)
    %0 = ttg.convert_layout %cst : tensor<16x16xf32, #blocked> -> tensor<16x16xf32, #blocked> loc(#loc1)
    %c = tt.dot %a_23, %b_24, %0, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #blocked}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked}>> -> tensor<16x16xf32, #blocked> loc(#loc30)
    %1 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc13)
    %2 = tt.addptr %1, %a_3 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc13)
    %3 = tt.broadcast %2 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc14)
    %4 = ttg.convert_layout %3 : tensor<16x16x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    %5 = tt.addptr %4, %a_11 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc14)
    %6 = arith.truncf %c : tensor<16x16xf32, #blocked> to tensor<16x16xf16, #blocked> loc(#loc15)
    %7 = ttg.convert_layout %5 : tensor<16x16x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc15)
    %8 = ttg.convert_layout %6 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #blocked5> loc(#loc15)
    tt.store %7, %8 : tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc15)
    tt.return loc(#loc16)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":18:24)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc16 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc20 = loc("offs"(#loc2))
#loc21 = loc("a"(#loc3))
#loc22 = loc("a"(#loc4))
#loc23 = loc("a"(#loc5))
#loc24 = loc("a"(#loc6))
#loc25 = loc("a"(#loc7))
#loc26 = loc("a"(#loc8))
#loc27 = loc("b"(#loc9))
#loc28 = loc("b"(#loc10))
#loc29 = loc("b"(#loc11))
#loc30 = loc("c"(#loc12))


// -----// IR Dump Before TritonGPURemoveLayoutConversions (tritongpu-remove-layout-conversions) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked5 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc17 = loc("a_ptr"(#loc))
#loc18 = loc("b_ptr"(#loc))
#loc19 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked1> loc(#loc1)
    %offs = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #blocked2> loc(#loc20)
    %a = ttg.convert_layout %offs : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc21)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<16x1xi32, #blocked3> loc(#loc21)
    %a_2 = ttg.convert_layout %a_1 : tensor<16x1xi32, #blocked3> -> tensor<16x1xi32, #blocked1> loc(#loc22)
    %a_3 = arith.muli %a_2, %cst_0 : tensor<16x1xi32, #blocked1> loc(#loc22)
    %a_4 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc23)
    %a_5 = tt.addptr %a_4, %a_3 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc23)
    %a_6 = ttg.convert_layout %offs : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked4}>> loc(#loc24)
    %a_7 = tt.expand_dims %a_6 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked4}>> -> tensor<1x16xi32, #blocked4> loc(#loc24)
    %a_8 = ttg.convert_layout %a_7 : tensor<1x16xi32, #blocked4> -> tensor<1x16xi32, #blocked> loc(#loc25)
    %a_9 = tt.broadcast %a_5 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc25)
    %a_10 = ttg.convert_layout %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc25)
    %a_11 = tt.broadcast %a_8 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc25)
    %a_12 = tt.addptr %a_10, %a_11 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc25)
    %a_13 = ttg.convert_layout %a_12 : tensor<16x16x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc26)
    %a_14 = tt.load %a_13 : tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc26)
    %a_15 = ttg.convert_layout %a_14 : tensor<16x16xf16, #blocked5> -> tensor<16x16xf16, #blocked> loc(#loc26)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc27)
    %b_16 = tt.addptr %b, %a_3 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc27)
    %b_17 = tt.broadcast %b_16 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc28)
    %b_18 = ttg.convert_layout %b_17 : tensor<16x16x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc28)
    %b_19 = tt.addptr %b_18, %a_11 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc28)
    %b_20 = ttg.convert_layout %b_19 : tensor<16x16x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc29)
    %b_21 = tt.load %b_20 : tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc29)
    %b_22 = ttg.convert_layout %b_21 : tensor<16x16xf16, #blocked5> -> tensor<16x16xf16, #blocked> loc(#loc29)
    %a_23 = ttg.convert_layout %a_15 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #blocked}>> loc(#loc26)
    %b_24 = ttg.convert_layout %b_22 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked}>> loc(#loc29)
    %0 = ttg.convert_layout %cst : tensor<16x16xf32, #blocked> -> tensor<16x16xf32, #blocked> loc(#loc1)
    %c = tt.dot %a_23, %b_24, %0, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #blocked}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked}>> -> tensor<16x16xf32, #blocked> loc(#loc30)
    %1 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc13)
    %2 = tt.addptr %1, %a_3 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc13)
    %3 = tt.broadcast %2 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc14)
    %4 = ttg.convert_layout %3 : tensor<16x16x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    %5 = tt.addptr %4, %a_11 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc14)
    %6 = arith.truncf %c : tensor<16x16xf32, #blocked> to tensor<16x16xf16, #blocked> loc(#loc15)
    %7 = ttg.convert_layout %5 : tensor<16x16x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc15)
    %8 = ttg.convert_layout %6 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #blocked5> loc(#loc15)
    tt.store %7, %8 : tensor<16x16x!tt.ptr<f16>, #blocked5> loc(#loc15)
    tt.return loc(#loc16)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":18:24)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc16 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc20 = loc("offs"(#loc2))
#loc21 = loc("a"(#loc3))
#loc22 = loc("a"(#loc4))
#loc23 = loc("a"(#loc5))
#loc24 = loc("a"(#loc6))
#loc25 = loc("a"(#loc7))
#loc26 = loc("a"(#loc8))
#loc27 = loc("b"(#loc9))
#loc28 = loc("b"(#loc10))
#loc29 = loc("b"(#loc11))
#loc30 = loc("c"(#loc12))


// -----// IR Dump Before TritonGPUOptimizeThreadLocality (tritongpu-optimize-thread-locality) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked1> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<16x1xi32, #blocked1> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked1> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked1> -> tensor<16x16xi32, #blocked1> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked1>, tensor<16x16xi32, #blocked1> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked1>, tensor<16x16xi32, #blocked1> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked1> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #blocked}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked1> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #blocked}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked}>> -> tensor<16x16xf32, #blocked> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked1>, tensor<16x16xi32, #blocked1> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #blocked> to tensor<16x16xf16, #blocked> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #blocked1> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUAccelerateMatmul (tritongpu-accelerate-matmul) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked1> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<16x1xi32, #blocked1> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked1> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked1> -> tensor<16x16xi32, #blocked1> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked1>, tensor<16x16xi32, #blocked1> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked1>, tensor<16x16xi32, #blocked1> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked1> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #blocked}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked1> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #blocked}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked}>> -> tensor<16x16xf32, #blocked> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked1>, tensor<16x16xi32, #blocked1> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #blocked> to tensor<16x16xf16, #blocked> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #blocked1> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPURemoveLayoutConversions (tritongpu-remove-layout-conversions) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked1> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<16x1xi32, #blocked1> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked1> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked1> -> tensor<16x16xi32, #blocked1> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked1>, tensor<16x16xi32, #blocked1> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked1>, tensor<16x16xi32, #blocked1> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked1> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #blocked}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked1> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked}>> loc(#loc27)
    %0 = ttg.convert_layout %cst : tensor<16x16xf32, #blocked> -> tensor<16x16xf32, #mma> loc(#loc1)
    %a_17 = ttg.convert_layout %a_15 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #blocked}>> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.convert_layout %b_16 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked}>> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %0, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %c_19 = ttg.convert_layout %c : tensor<16x16xf32, #mma> -> tensor<16x16xf32, #blocked> loc(#loc28)
    %1 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc12)
    %2 = tt.addptr %1, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc12)
    %3 = tt.broadcast %2 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc13)
    %4 = tt.addptr %3, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked1>, tensor<16x16xi32, #blocked1> loc(#loc13)
    %5 = arith.truncf %c_19 : tensor<16x16xf32, #blocked> to tensor<16x16xf16, #blocked> loc(#loc14)
    %6 = ttg.convert_layout %5 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #blocked1> loc(#loc14)
    tt.store %4, %6 : tensor<16x16x!tt.ptr<f16>, #blocked1> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUOptimizeDotOperands (tritongpu-optimize-dot-operands) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonNvidiaGPUOptimizeDescriptorEncodingPass (triton-nvidia-optimize-descriptor-encoding) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonLoopAwareCSE (triton-loop-aware-cse) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUFuseNestedLoops (tritongpu-fuse-nested-loops) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonLoopInvariantCodeMotion (triton-licm) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUCombineTensorSelectAndIf (tritongpu-combine-tensor-select-and-if) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before NVGPUWarpSpecialization (nvgpu-warp-specialization) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUAssignLatencies (tritongpu-assign-latencies) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUScheduleLoops (tritongpu-schedule-loops) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUPipeline (tritongpu-pipeline) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// SoftwarePipeliner internal IR Dump After: LowerLoops
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %0 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %1 = tt.expand_dims %0 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %2 = arith.muli %1, %cst_0 : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %3 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %4 = tt.addptr %3, %2 : tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %6 = tt.expand_dims %5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %7 = tt.broadcast %4 : tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %8 = tt.broadcast %6 : tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x16xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %9 = tt.addptr %7, %8 : tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x16xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %10 = tt.load %9 : tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %11 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %12 = tt.addptr %11, %2 : tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %13 = tt.broadcast %12 : tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %14 = tt.addptr %13, %8 : tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x16xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %15 = tt.load %14 : tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %16 = ttg.convert_layout %10 : tensor<16x16xf16, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %17 = ttg.convert_layout %15 : tensor<16x16xf16, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %18 = tt.dot %16, %17, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<16x16xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %19 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %20 = tt.addptr %19, %2 : tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %21 = tt.broadcast %20 : tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %22 = tt.addptr %21, %8 : tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x16xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %23 = arith.truncf %18 : tensor<16x16xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<16x16xf16, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %24 = ttg.convert_layout %23 : tensor<16x16xf16, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<16x16xf16, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    tt.store %22, %24 : tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    tt.return
  }
}


// -----// SoftwarePipeliner internal IR Dump After: ExpandLoops
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %0 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %1 = tt.expand_dims %0 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %2 = arith.muli %1, %cst_0 : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %3 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %4 = tt.addptr %3, %2 : tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %6 = tt.expand_dims %5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %7 = tt.broadcast %4 : tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %8 = tt.broadcast %6 : tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x16xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %9 = tt.addptr %7, %8 : tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x16xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %10 = tt.load %9 : tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %11 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %12 = tt.addptr %11, %2 : tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %13 = tt.broadcast %12 : tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %14 = tt.addptr %13, %8 : tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x16xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %15 = tt.load %14 : tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %16 = ttg.convert_layout %10 : tensor<16x16xf16, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %17 = ttg.convert_layout %15 : tensor<16x16xf16, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>>
    %18 = tt.dot %16, %17, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 2}>> -> tensor<16x16xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %19 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %20 = tt.addptr %19, %2 : tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %21 = tt.broadcast %20 : tensor<16x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %22 = tt.addptr %21, %8 : tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x16xi32, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %23 = arith.truncf %18 : tensor<16x16xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<16x16xf16, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %24 = ttg.convert_layout %23 : tensor<16x16xf16, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<16x16xf16, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    tt.store %22, %24 : tensor<16x16x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    tt.return
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonLoopAwareCSE (triton-loop-aware-cse) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUPrefetch (tritongpu-prefetch) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUOptimizeDotOperands (tritongpu-optimize-dot-operands) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUCoalesceAsyncCopy (tritongpu-coalesce-async-copy) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonNvidiaGPUOptimizeTMemLayoutsPass (triton-nvidia-optimize-tmem-layouts) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPURemoveLayoutConversions (tritongpu-remove-layout-conversions) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonNvidiaGPUInterleaveTMemPass (triton-nvidia-interleave-tmem) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUReduceDataDuplication (tritongpu-reduce-data-duplication) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.convert_layout %a_10 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_16 = ttg.convert_layout %b_14 : tensor<16x16xf16, #blocked> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_15, %b_16, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUReorderInstructions (tritongpu-reorder-instructions) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_11 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_12 = tt.broadcast %b_11 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_13 = tt.addptr %b_12, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_14 = tt.load %b_13 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %a_15 = ttg.local_alloc %a_10 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %a_16 = ttg.local_load %a_15 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_17 = ttg.local_alloc %b_14 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %b_18 = ttg.local_load %b_17 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_16, %b_18, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonLoopAwareCSE (triton-loop-aware-cse) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %a_11 = ttg.local_alloc %a_10 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_12 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_13 = tt.broadcast %b_12 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_14 = tt.addptr %b_13, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_15 = tt.load %b_14 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %b_16 = ttg.local_alloc %b_15 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %a_17 = ttg.local_load %a_11 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.local_load %b_16 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before SymbolDCE (symbol-dce) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %a_11 = ttg.local_alloc %a_10 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_12 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_13 = tt.broadcast %b_12 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_14 = tt.addptr %b_13, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_15 = tt.load %b_14 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %b_16 = ttg.local_alloc %b_15 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %a_17 = ttg.local_load %a_11 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.local_load %b_16 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonNvidiaGPUTMALoweringPass (triton-nvidia-tma-lowering) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %a_11 = ttg.local_alloc %a_10 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_12 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_13 = tt.broadcast %b_12 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_14 = tt.addptr %b_13, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_15 = tt.load %b_14 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %b_16 = ttg.local_alloc %b_15 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %a_17 = ttg.local_load %a_11 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.local_load %b_16 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUFenceInsertion (triton-nvidia-gpu-fence-insertion) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %a_11 = ttg.local_alloc %a_10 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_12 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_13 = tt.broadcast %b_12 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_14 = tt.addptr %b_13, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_15 = tt.load %b_14 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %b_16 = ttg.local_alloc %b_15 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %a_17 = ttg.local_load %a_11 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.local_load %b_16 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonNvidiaGPUMMALoweringPass (triton-nvidia-mma-lowering) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %a_11 = ttg.local_alloc %a_10 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_12 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_13 = tt.broadcast %b_12 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_14 = tt.addptr %b_13, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_15 = tt.load %b_14 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %b_16 = ttg.local_alloc %b_15 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %a_17 = ttg.local_load %a_11 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.local_load %b_16 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before SCCP (sccp) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst_0 : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %a_11 = ttg.local_alloc %a_10 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_12 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_13 = tt.broadcast %b_12 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_14 = tt.addptr %b_13, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_15 = tt.load %b_14 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %b_16 = ttg.local_alloc %b_15 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %a_17 = ttg.local_load %a_11 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.local_load %b_16 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %cst, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %a_11 = ttg.local_alloc %a_10 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_12 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_13 = tt.broadcast %b_12 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_14 = tt.addptr %b_13, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_15 = tt.load %b_14 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %b_16 = ttg.local_alloc %b_15 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %a_17 = ttg.local_load %a_11 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.local_load %b_16 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %cst_0, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUCombineTensorSelectAndIf (tritongpu-combine-tensor-select-and-if) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %a_11 = ttg.local_alloc %a_10 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_12 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_13 = tt.broadcast %b_12 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_14 = tt.addptr %b_13, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_15 = tt.load %b_14 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %b_16 = ttg.local_alloc %b_15 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %a_17 = ttg.local_load %a_11 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.local_load %b_16 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %cst_0, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUAllocateWarpGroups (tritongpu-allocate-warp-groups) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %a_11 = ttg.local_alloc %a_10 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_12 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_13 = tt.broadcast %b_12 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_14 = tt.addptr %b_13, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_15 = tt.load %b_14 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %b_16 = ttg.local_alloc %b_15 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %a_17 = ttg.local_load %a_11 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.local_load %b_16 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %cst_0, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before SCFToControlFlowPass (convert-scf-to-cf) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %a_11 = ttg.local_alloc %a_10 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_12 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_13 = tt.broadcast %b_12 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_14 = tt.addptr %b_13, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_15 = tt.load %b_14 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %b_16 = ttg.local_alloc %b_15 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %a_17 = ttg.local_load %a_11 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.local_load %b_16 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %cst_0, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before AllocateSharedMemory (allocate-shared-memory) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %a_11 = ttg.local_alloc %a_10 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_12 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_13 = tt.broadcast %b_12 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_14 = tt.addptr %b_13, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_15 = tt.load %b_14 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %b_16 = ttg.local_alloc %b_15 : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %a_17 = ttg.local_load %a_11 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.local_load %b_16 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %cst_0, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


[Allocation] sharedLayoutAttr: vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0
[Allocation] parsedLayout: 
 - vector=1 -> (0, 1)
 - bank=1 -> (1, 0)
   bank=2 -> (2, 0)
   bank=4 -> (0, 2)
   bank=8 -> (0, 4)
   bank=16 -> (0, 8)
 - segment=1 -> (8, 0)
   segment=2 -> (4, 8)
 - reps is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)]
[optimalSwizzling] src: 
 - register=1 -> (0, 1)
   register=2 -> (8, 0)
 - lane=1 -> (0, 2)
   lane=2 -> (0, 4)
   lane=4 -> (1, 0)
   lane=8 -> (2, 0)
   lane=16 -> (4, 0)
 - warp=1 -> (0, 8)
   warp=2 -> (0, 0)
 - block is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)], dst: 
 - register=1 -> (0, 1)
 - lane=1 -> (0, 2)
   lane=2 -> (0, 4)
   lane=4 -> (0, 8)
   lane=8 -> (1, 0)
   lane=16 -> (2, 0)
 - warp=1 -> (4, 0)
   warp=2 -> (8, 0)
 - block is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)], bitwidth: 16
[Allocation] parsedLayout matches smem: 
 - vector=1 -> (0, 1)
 - bank=1 -> (1, 0)
   bank=2 -> (2, 0)
   bank=4 -> (0, 2)
   bank=8 -> (0, 4)
   bank=16 -> (0, 8)
 - segment=1 -> (8, 0)
   segment=2 -> (4, 8)
 - reps is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)]
[Allocation] smem: 
 - vector=1 -> (0, 1)
 - bank=1 -> (1, 0)
   bank=2 -> (2, 0)
   bank=4 -> (0, 2)
   bank=8 -> (0, 4)
   bank=16 -> (0, 8)
 - segment=1 -> (8, 0)
   segment=2 -> (4, 8)
 - reps is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)]
// -----// IR Dump Before TritonTensorMemoryAllocationPass (triton-tensor-memory-allocation) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 1024 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %a_11 = ttg.local_alloc %a_10 {allocation.offset = 0 : i32} : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_12 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_13 = tt.broadcast %b_12 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_14 = tt.addptr %b_13, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_15 = tt.load %b_14 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %b_16 = ttg.local_alloc %b_15 {allocation.offset = 512 : i32} : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %a_17 = ttg.local_load %a_11 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.local_load %b_16 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %cst_0, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 {allocation.offset = 0 : i32} : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUGlobalScratchAllocationPass (tritongpu-global-scratch-memory-allocation) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 1024 : i32, ttg.target = "cuda:90", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false} {
    %cst = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %a_11 = ttg.local_alloc %a_10 {allocation.offset = 0 : i32} : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_12 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_13 = tt.broadcast %b_12 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_14 = tt.addptr %b_13, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_15 = tt.load %b_14 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %b_16 = ttg.local_alloc %b_15 {allocation.offset = 512 : i32} : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %a_17 = ttg.local_load %a_11 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.local_load %b_16 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %cst_0, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 {allocation.offset = 0 : i32} : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before TritonGPUProxyFenceInsertion (triton-nvidia-gpu-proxy-fence-insertion) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 1024 : i32, ttg.target = "cuda:90", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %cst = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %a_11 = ttg.local_alloc %a_10 {allocation.offset = 0 : i32} : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_12 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_13 = tt.broadcast %b_12 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_14 = tt.addptr %b_13, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_15 = tt.load %b_14 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %b_16 = ttg.local_alloc %b_15 {allocation.offset = 512 : i32} : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %a_17 = ttg.local_load %a_11 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.local_load %b_16 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %cst_0, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 {allocation.offset = 0 : i32} : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


[Allocation] sharedLayoutAttr: vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0
[Allocation] parsedLayout: 
 - vector=1 -> (0, 1)
 - bank=1 -> (1, 0)
   bank=2 -> (2, 0)
   bank=4 -> (0, 2)
   bank=8 -> (0, 4)
   bank=16 -> (0, 8)
 - segment=1 -> (8, 0)
   segment=2 -> (4, 8)
 - reps is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)]
[optimalSwizzling] src: 
 - register=1 -> (0, 1)
   register=2 -> (8, 0)
 - lane=1 -> (0, 2)
   lane=2 -> (0, 4)
   lane=4 -> (1, 0)
   lane=8 -> (2, 0)
   lane=16 -> (4, 0)
 - warp=1 -> (0, 8)
   warp=2 -> (0, 0)
 - block is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)], dst: 
 - register=1 -> (0, 1)
 - lane=1 -> (0, 2)
   lane=2 -> (0, 4)
   lane=4 -> (0, 8)
   lane=8 -> (1, 0)
   lane=16 -> (2, 0)
 - warp=1 -> (4, 0)
   warp=2 -> (8, 0)
 - block is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)], bitwidth: 16
[Allocation] parsedLayout matches smem: 
 - vector=1 -> (0, 1)
 - bank=1 -> (1, 0)
   bank=2 -> (2, 0)
   bank=4 -> (0, 2)
   bank=8 -> (0, 4)
   bank=16 -> (0, 8)
 - segment=1 -> (8, 0)
   segment=2 -> (4, 8)
 - reps is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)]
[Allocation] smem: 
 - vector=1 -> (0, 1)
 - bank=1 -> (1, 0)
   bank=2 -> (2, 0)
   bank=4 -> (0, 2)
   bank=8 -> (0, 4)
   bank=16 -> (0, 8)
 - segment=1 -> (8, 0)
   segment=2 -> (4, 8)
 - reps is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)]
// -----// IR Dump Before ConvertTritonGPUToLLVM (convert-triton-gpu-to-llvm) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 4, maxPhase = 2, order = [1, 0]}>
#smem = #ttg.shared_memory
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 1024 : i32, ttg.target = "cuda:90", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  tt.func public @tiny_matmul_kernel(%a_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc))) attributes {noinline = false, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %cst = arith.constant dense<16> : tensor<16x1xi32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<16x16xf32, #mma> loc(#loc1)
    %a = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc19)
    %a_1 = tt.expand_dims %a {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc19)
    %a_2 = arith.muli %a_1, %cst : tensor<16x1xi32, #blocked> loc(#loc20)
    %a_3 = tt.splat %a_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc21)
    %a_4 = tt.addptr %a_3, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc21)
    %a_5 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc22)
    %a_6 = tt.expand_dims %a_5 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc22)
    %a_7 = tt.broadcast %a_4 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc23)
    %a_8 = tt.broadcast %a_6 : tensor<1x16xi32, #blocked> -> tensor<16x16xi32, #blocked> loc(#loc23)
    %a_9 = tt.addptr %a_7, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc23)
    %a_10 = tt.load %a_9 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc24)
    %a_11 = ttg.local_alloc %a_10 {allocation.offset = 0 : i32} : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc24)
    %b = tt.splat %b_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc25)
    %b_12 = tt.addptr %b, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc25)
    %b_13 = tt.broadcast %b_12 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc26)
    %b_14 = tt.addptr %b_13, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc26)
    %b_15 = tt.load %b_14 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc27)
    %b_16 = ttg.local_alloc %b_15 {allocation.offset = 512 : i32} : (tensor<16x16xf16, #blocked>) -> !ttg.memdesc<16x16xf16, #shared, #smem> loc(#loc27)
    %a_17 = ttg.local_load %a_11 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc24)
    %b_18 = ttg.local_load %b_16 : !ttg.memdesc<16x16xf16, #shared, #smem> -> tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> loc(#loc27)
    %c = tt.dot %a_17, %b_18, %cst_0, inputPrecision = tf32 : tensor<16x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * tensor<16x16xf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 2}>> -> tensor<16x16xf32, #mma> loc(#loc28)
    %0 = tt.splat %c_ptr : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked> loc(#loc12)
    %1 = tt.addptr %0, %a_2 : tensor<16x1x!tt.ptr<f16>, #blocked>, tensor<16x1xi32, #blocked> loc(#loc12)
    %2 = tt.broadcast %1 : tensor<16x1x!tt.ptr<f16>, #blocked> -> tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc13)
    %3 = tt.addptr %2, %a_8 : tensor<16x16x!tt.ptr<f16>, #blocked>, tensor<16x16xi32, #blocked> loc(#loc13)
    %4 = arith.truncf %c : tensor<16x16xf32, #mma> to tensor<16x16xf16, #mma> loc(#loc14)
    %5 = ttg.convert_layout %4 {allocation.offset = 0 : i32} : tensor<16x16xf16, #mma> -> tensor<16x16xf16, #blocked> loc(#loc14)
    tt.store %3, %5 : tensor<16x16x!tt.ptr<f16>, #blocked> loc(#loc14)
    tt.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


[Allocation] sharedLayoutAttr: vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0
[Allocation] parsedLayout: 
 - vector=1 -> (0, 1)
 - bank=1 -> (1, 0)
   bank=2 -> (2, 0)
   bank=4 -> (0, 2)
   bank=8 -> (0, 4)
   bank=16 -> (0, 8)
 - segment=1 -> (8, 0)
   segment=2 -> (4, 8)
 - reps is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)]
[optimalSwizzling] src: 
 - register=1 -> (0, 1)
   register=2 -> (8, 0)
 - lane=1 -> (0, 2)
   lane=2 -> (0, 4)
   lane=4 -> (1, 0)
   lane=8 -> (2, 0)
   lane=16 -> (4, 0)
 - warp=1 -> (0, 8)
   warp=2 -> (0, 0)
 - block is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)], dst: 
 - register=1 -> (0, 1)
 - lane=1 -> (0, 2)
   lane=2 -> (0, 4)
   lane=4 -> (0, 8)
   lane=8 -> (1, 0)
   lane=16 -> (2, 0)
 - warp=1 -> (4, 0)
   warp=2 -> (8, 0)
 - block is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)], bitwidth: 16
[Allocation] parsedLayout matches smem: 
 - vector=1 -> (0, 1)
 - bank=1 -> (1, 0)
   bank=2 -> (2, 0)
   bank=4 -> (0, 2)
   bank=8 -> (0, 4)
   bank=16 -> (0, 8)
 - segment=1 -> (8, 0)
   segment=2 -> (4, 8)
 - reps is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)]
[Allocation] smem: 
 - vector=1 -> (0, 1)
 - bank=1 -> (1, 0)
   bank=2 -> (2, 0)
   bank=4 -> (0, 2)
   bank=8 -> (0, 4)
   bank=16 -> (0, 8)
 - segment=1 -> (8, 0)
   segment=2 -> (4, 8)
 - reps is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)]
Utility sharedLayoutAttr: vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0
Utility parsedLayout: 
 - vector=1 -> (0, 1)
 - bank=1 -> (1, 0)
   bank=2 -> (2, 0)
   bank=4 -> (0, 2)
   bank=8 -> (0, 4)
   bank=16 -> (0, 8)
 - segment=1 -> (8, 0)
   segment=2 -> (4, 8)
 - reps is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)]
[optimalSwizzling] src: 
 - register=1 -> (0, 1)
   register=2 -> (8, 0)
 - lane=1 -> (0, 2)
   lane=2 -> (0, 4)
   lane=4 -> (1, 0)
   lane=8 -> (2, 0)
   lane=16 -> (4, 0)
 - warp=1 -> (0, 8)
   warp=2 -> (0, 0)
where out dims are: [dim0 (size 16), dim1 (size 16)], dst: 
 - register=1 -> (0, 1)
 - lane=1 -> (0, 2)
   lane=2 -> (0, 4)
   lane=4 -> (0, 8)
   lane=8 -> (1, 0)
   lane=16 -> (2, 0)
 - warp=1 -> (4, 0)
   warp=2 -> (8, 0)
where out dims are: [dim0 (size 16), dim1 (size 16)], bitwidth: 16
Utility parsedLayout matches smem: 
 - vector=1 -> (0, 1)
 - bank=1 -> (1, 0)
   bank=2 -> (2, 0)
   bank=4 -> (0, 2)
   bank=8 -> (0, 4)
   bank=16 -> (0, 8)
 - segment=1 -> (8, 0)
   segment=2 -> (4, 8)
 - reps is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)]
Utility smem: 
 - vector=1 -> (0, 1)
 - bank=1 -> (1, 0)
   bank=2 -> (2, 0)
   bank=4 -> (0, 2)
   bank=8 -> (0, 4)
   bank=16 -> (0, 8)
 - segment=1 -> (8, 0)
   segment=2 -> (4, 8)
 - reps is a size 1 dimension
where out dims are: [dim0 (size 16), dim1 (size 16)]
// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 1024 : i32, ttg.target = "cuda:90", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @tiny_matmul_kernel(%a_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc)), %arg3: !llvm.ptr<1> loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %1 = llvm.bitcast %0 : i32 to i32 loc(#loc1)
    %2 = llvm.mlir.undef : !llvm.struct<(i32, i32)> loc(#loc1)
    %3 = llvm.insertvalue %1, %2[0] : !llvm.struct<(i32, i32)>  loc(#loc1)
    %4 = llvm.insertvalue %1, %3[1] : !llvm.struct<(i32, i32)>  loc(#loc1)
    %5 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %6 = llvm.bitcast %5 : f32 to f32 loc(#loc1)
    %7 = llvm.mlir.undef : !llvm.struct<(f32, f32, f32, f32)> loc(#loc1)
    %8 = llvm.insertvalue %6, %7[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc1)
    %9 = llvm.insertvalue %6, %8[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc1)
    %10 = llvm.insertvalue %6, %9[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc1)
    %11 = llvm.insertvalue %6, %10[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc1)
    %a = llvm.mlir.constant(0 : index) : i32 loc(#loc19)
    %a_0 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc19)
    %a_1 = llvm.mlir.constant(127 : i32) : i32 loc(#loc19)
    %a_2 = llvm.and %a_0, %a_1 : i32 loc(#loc19)
    %a_3 = llvm.mlir.constant(32 : i32) : i32 loc(#loc19)
    %a_4 = llvm.urem %a_2, %a_3 : i32 loc(#loc19)
    %a_5 = llvm.udiv %a_2, %a_3 : i32 loc(#loc19)
    %a_6 = llvm.mlir.constant(0 : i32) : i32 loc(#loc19)
    %a_7 = nvgpu.cluster_id loc(#loc19)
    %a_8 = llvm.mlir.constant(0 : i32) : i32 loc(#loc19)
    %a_9 = llvm.mlir.constant(0 : i32) : i32 loc(#loc19)
    %a_10 = llvm.mlir.constant(0 : i32) : i32 loc(#loc19)
    %a_11 = llvm.mlir.constant(0 : i32) : i32 loc(#loc19)
    %a_12 = llvm.mlir.constant(0 : i32) : i32 loc(#loc19)
    %a_13 = llvm.shl %a_4, %a_12 : i32 loc(#loc19)
    %a_14 = llvm.or %a_11, %a_13 : i32 loc(#loc19)
    %a_15 = llvm.mlir.constant(5 : i32) : i32 loc(#loc19)
    %a_16 = llvm.shl %a_5, %a_15 : i32 loc(#loc19)
    %a_17 = llvm.or %a_14, %a_16 : i32 loc(#loc19)
    %a_18 = llvm.mlir.constant(7 : i32) : i32 loc(#loc19)
    %a_19 = llvm.shl %a_6, %a_18 : i32 loc(#loc19)
    %a_20 = llvm.or %a_17, %a_19 : i32 loc(#loc19)
    %a_21 = llvm.mlir.constant(0 : i32) : i32 loc(#loc19)
    %a_22 = llvm.mlir.constant(120 : i32) : i32 loc(#loc19)
    %a_23 = llvm.and %a_20, %a_22 : i32 loc(#loc19)
    %a_24 = llvm.mlir.constant(3 : i32) : i32 loc(#loc19)
    %a_25 = llvm.lshr %a_23, %a_24 : i32 loc(#loc19)
    %a_26 = llvm.xor %a_21, %a_25 : i32 loc(#loc19)
    %a_27 = llvm.mlir.constant(0 : i32) : i32 loc(#loc19)
    %a_28 = llvm.xor %a_10, %a_26 : i32 loc(#loc19)
    %a_29 = llvm.mlir.constant(0 : i32) : i32 loc(#loc19)
    %a_30 = llvm.xor %a_28, %a_29 : i32 loc(#loc19)
    %a_31 = llvm.add %a_30, %a : i32 loc(#loc19)
    %a_32 = llvm.mlir.undef : !llvm.struct<(i32)> loc(#loc19)
    %a_33 = llvm.insertvalue %a_31, %a_32[0] : !llvm.struct<(i32)>  loc(#loc19)
    %a_34 = llvm.extractvalue %a_33[0] : !llvm.struct<(i32)>  loc(#loc19)
    %a_35 = llvm.mlir.undef : !llvm.struct<(i32, i32)> loc(#loc19)
    %a_36 = llvm.insertvalue %a_34, %a_35[0] : !llvm.struct<(i32, i32)>  loc(#loc19)
    %a_37 = llvm.insertvalue %a_34, %a_36[1] : !llvm.struct<(i32, i32)>  loc(#loc19)
    %a_38 = llvm.extractvalue %a_37[0] : !llvm.struct<(i32, i32)>  loc(#loc20)
    %a_39 = llvm.extractvalue %a_37[1] : !llvm.struct<(i32, i32)>  loc(#loc20)
    %a_40 = llvm.extractvalue %4[0] : !llvm.struct<(i32, i32)>  loc(#loc20)
    %a_41 = llvm.extractvalue %4[1] : !llvm.struct<(i32, i32)>  loc(#loc20)
    %a_42 = llvm.mul %a_38, %a_40 : i32 loc(#loc20)
    %a_43 = llvm.mul %a_39, %a_41 : i32 loc(#loc20)
    %a_44 = llvm.mlir.undef : !llvm.struct<(i32, i32)> loc(#loc20)
    %a_45 = llvm.insertvalue %a_42, %a_44[0] : !llvm.struct<(i32, i32)>  loc(#loc20)
    %a_46 = llvm.insertvalue %a_43, %a_45[1] : !llvm.struct<(i32, i32)>  loc(#loc20)
    %a_47 = llvm.bitcast %a_ptr : !llvm.ptr<1> to !llvm.ptr<1> loc(#loc21)
    %a_48 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>)> loc(#loc21)
    %a_49 = llvm.insertvalue %a_47, %a_48[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc21)
    %a_50 = llvm.insertvalue %a_47, %a_49[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc21)
    %a_51 = llvm.extractvalue %a_50[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc21)
    %a_52 = llvm.extractvalue %a_50[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc21)
    %a_53 = llvm.extractvalue %a_46[0] : !llvm.struct<(i32, i32)>  loc(#loc21)
    %a_54 = llvm.extractvalue %a_46[1] : !llvm.struct<(i32, i32)>  loc(#loc21)
    %a_55 = llvm.getelementptr %a_51[%a_53] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc21)
    %a_56 = llvm.getelementptr %a_52[%a_54] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc21)
    %a_57 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>)> loc(#loc21)
    %a_58 = llvm.insertvalue %a_55, %a_57[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc21)
    %a_59 = llvm.insertvalue %a_56, %a_58[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc21)
    %a_60 = llvm.mlir.constant(0 : index) : i32 loc(#loc22)
    %a_61 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc22)
    %a_62 = llvm.mlir.constant(127 : i32) : i32 loc(#loc22)
    %a_63 = llvm.and %a_61, %a_62 : i32 loc(#loc22)
    %a_64 = llvm.mlir.constant(32 : i32) : i32 loc(#loc22)
    %a_65 = llvm.urem %a_63, %a_64 : i32 loc(#loc22)
    %a_66 = llvm.udiv %a_63, %a_64 : i32 loc(#loc22)
    %a_67 = llvm.mlir.constant(0 : i32) : i32 loc(#loc22)
    %a_68 = nvgpu.cluster_id loc(#loc22)
    %a_69 = llvm.mlir.constant(0 : i32) : i32 loc(#loc22)
    %a_70 = llvm.mlir.constant(0 : i32) : i32 loc(#loc22)
    %a_71 = llvm.mlir.constant(0 : i32) : i32 loc(#loc22)
    %a_72 = llvm.mlir.constant(0 : i32) : i32 loc(#loc22)
    %a_73 = llvm.mlir.constant(0 : i32) : i32 loc(#loc22)
    %a_74 = llvm.shl %a_65, %a_73 : i32 loc(#loc22)
    %a_75 = llvm.or %a_72, %a_74 : i32 loc(#loc22)
    %a_76 = llvm.mlir.constant(5 : i32) : i32 loc(#loc22)
    %a_77 = llvm.shl %a_66, %a_76 : i32 loc(#loc22)
    %a_78 = llvm.or %a_75, %a_77 : i32 loc(#loc22)
    %a_79 = llvm.mlir.constant(7 : i32) : i32 loc(#loc22)
    %a_80 = llvm.shl %a_67, %a_79 : i32 loc(#loc22)
    %a_81 = llvm.or %a_78, %a_80 : i32 loc(#loc22)
    %a_82 = llvm.mlir.constant(0 : i32) : i32 loc(#loc22)
    %a_83 = llvm.mlir.constant(7 : i32) : i32 loc(#loc22)
    %a_84 = llvm.and %a_81, %a_83 : i32 loc(#loc22)
    %a_85 = llvm.mlir.constant(1 : i32) : i32 loc(#loc22)
    %a_86 = llvm.shl %a_84, %a_85 : i32 loc(#loc22)
    %a_87 = llvm.xor %a_82, %a_86 : i32 loc(#loc22)
    %a_88 = llvm.mlir.constant(0 : i32) : i32 loc(#loc22)
    %a_89 = llvm.xor %a_71, %a_87 : i32 loc(#loc22)
    %a_90 = llvm.mlir.constant(0 : i32) : i32 loc(#loc22)
    %a_91 = llvm.xor %a_89, %a_90 : i32 loc(#loc22)
    %a_92 = llvm.mlir.constant(1 : i32) : i32 loc(#loc22)
    %a_93 = llvm.xor %a_89, %a_92 : i32 loc(#loc22)
    %a_94 = llvm.add %a_91, %a_60 : i32 loc(#loc22)
    %a_95 = llvm.add %a_93, %a_60 : i32 loc(#loc22)
    %a_96 = llvm.mlir.undef : !llvm.struct<(i32, i32)> loc(#loc22)
    %a_97 = llvm.insertvalue %a_94, %a_96[0] : !llvm.struct<(i32, i32)>  loc(#loc22)
    %a_98 = llvm.insertvalue %a_95, %a_97[1] : !llvm.struct<(i32, i32)>  loc(#loc22)
    %a_99 = llvm.extractvalue %a_98[0] : !llvm.struct<(i32, i32)>  loc(#loc22)
    %a_100 = llvm.extractvalue %a_98[1] : !llvm.struct<(i32, i32)>  loc(#loc22)
    %a_101 = llvm.mlir.undef : !llvm.struct<(i32, i32)> loc(#loc22)
    %a_102 = llvm.insertvalue %a_99, %a_101[0] : !llvm.struct<(i32, i32)>  loc(#loc22)
    %a_103 = llvm.insertvalue %a_100, %a_102[1] : !llvm.struct<(i32, i32)>  loc(#loc22)
    %a_104 = llvm.extractvalue %a_59[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc23)
    %a_105 = llvm.extractvalue %a_59[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc23)
    %a_106 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>)> loc(#loc23)
    %a_107 = llvm.insertvalue %a_105, %a_106[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc23)
    %a_108 = llvm.insertvalue %a_105, %a_107[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc23)
    %a_109 = llvm.extractvalue %a_103[0] : !llvm.struct<(i32, i32)>  loc(#loc23)
    %a_110 = llvm.extractvalue %a_103[1] : !llvm.struct<(i32, i32)>  loc(#loc23)
    %a_111 = llvm.mlir.undef : !llvm.struct<(i32, i32)> loc(#loc23)
    %a_112 = llvm.insertvalue %a_109, %a_111[0] : !llvm.struct<(i32, i32)>  loc(#loc23)
    %a_113 = llvm.insertvalue %a_110, %a_112[1] : !llvm.struct<(i32, i32)>  loc(#loc23)
    %a_114 = llvm.extractvalue %a_108[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc23)
    %a_115 = llvm.extractvalue %a_108[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc23)
    %a_116 = llvm.extractvalue %a_113[0] : !llvm.struct<(i32, i32)>  loc(#loc23)
    %a_117 = llvm.extractvalue %a_113[1] : !llvm.struct<(i32, i32)>  loc(#loc23)
    %a_118 = llvm.getelementptr %a_114[%a_116] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc23)
    %a_119 = llvm.getelementptr %a_115[%a_117] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc23)
    %a_120 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>)> loc(#loc23)
    %a_121 = llvm.insertvalue %a_118, %a_120[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc23)
    %a_122 = llvm.insertvalue %a_119, %a_121[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc23)
    %a_123 = llvm.extractvalue %a_122[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc24)
    %a_124 = llvm.extractvalue %a_122[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc24)
    %a_125 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %a_123 : (!llvm.ptr<1>) -> i32 loc(#loc24)
    %a_126 = llvm.bitcast %a_125 : i32 to vector<2xf16> loc(#loc24)
    %a_127 = llvm.mlir.constant(0 : index) : i32 loc(#loc24)
    %a_128 = llvm.extractelement %a_126[%a_127 : i32] : vector<2xf16> loc(#loc24)
    %a_129 = llvm.mlir.constant(1 : index) : i32 loc(#loc24)
    %a_130 = llvm.extractelement %a_126[%a_129 : i32] : vector<2xf16> loc(#loc24)
    %a_131 = llvm.mlir.undef : !llvm.struct<(f16, f16)> loc(#loc24)
    %a_132 = llvm.insertvalue %a_128, %a_131[0] : !llvm.struct<(f16, f16)>  loc(#loc24)
    %a_133 = llvm.insertvalue %a_130, %a_132[1] : !llvm.struct<(f16, f16)>  loc(#loc24)
    %a_134 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %12 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc)
    %a_135 = llvm.getelementptr %12[%a_134] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc24)
    %a_136 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_137 = llvm.extractvalue %a_133[0] : !llvm.struct<(f16, f16)>  loc(#loc24)
    %a_138 = llvm.extractvalue %a_133[1] : !llvm.struct<(f16, f16)>  loc(#loc24)
    %a_139 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc24)
    %a_140 = llvm.mlir.constant(127 : i32) : i32 loc(#loc24)
    %a_141 = llvm.and %a_139, %a_140 : i32 loc(#loc24)
    %a_142 = llvm.mlir.constant(32 : i32) : i32 loc(#loc24)
    %a_143 = llvm.urem %a_141, %a_142 : i32 loc(#loc24)
    %a_144 = llvm.udiv %a_141, %a_142 : i32 loc(#loc24)
    %a_145 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_146 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_147 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_148 = llvm.shl %a_143, %a_147 : i32 loc(#loc24)
    %a_149 = llvm.or %a_146, %a_148 : i32 loc(#loc24)
    %a_150 = llvm.mlir.constant(3 : i32) : i32 loc(#loc24)
    %a_151 = llvm.shl %a_144, %a_150 : i32 loc(#loc24)
    %a_152 = llvm.or %a_149, %a_151 : i32 loc(#loc24)
    %a_153 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_154 = llvm.mlir.constant(23 : i32) : i32 loc(#loc24)
    %a_155 = llvm.and %a_152, %a_154 : i32 loc(#loc24)
    %a_156 = llvm.mlir.constant(3 : i32) : i32 loc(#loc24)
    %a_157 = llvm.shl %a_155, %a_156 : i32 loc(#loc24)
    %a_158 = llvm.xor %a_153, %a_157 : i32 loc(#loc24)
    %a_159 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_160 = llvm.mlir.constant(8 : i32) : i32 loc(#loc24)
    %a_161 = llvm.and %a_152, %a_160 : i32 loc(#loc24)
    %a_162 = llvm.icmp "eq" %a_161, %a_159 : i32 loc(#loc24)
    %a_163 = llvm.mlir.constant(72 : i32) : i32 loc(#loc24)
    %a_164 = llvm.select %a_162, %a_159, %a_163 : i1, i32 loc(#loc24)
    %a_165 = llvm.xor %a_158, %a_164 : i32 loc(#loc24)
    %a_166 = llvm.xor %a_145, %a_165 : i32 loc(#loc24)
    %a_167 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_168 = llvm.xor %a_166, %a_167 : i32 loc(#loc24)
    %a_169 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_170 = llvm.xor %a_168, %a_169 : i32 loc(#loc24)
    %a_171 = llvm.getelementptr inbounds %a_135[%a_170] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_172 = llvm.mlir.undef : vector<2xf16> loc(#loc24)
    %a_173 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_174 = llvm.insertelement %a_137, %a_172[%a_173 : i32] : vector<2xf16> loc(#loc24)
    %a_175 = llvm.mlir.constant(1 : i32) : i32 loc(#loc24)
    %a_176 = llvm.insertelement %a_138, %a_174[%a_175 : i32] : vector<2xf16> loc(#loc24)
    %a_177 = llvm.bitcast %a_176 : vector<2xf16> to i32 loc(#loc24)
    nvvm.stmatrix %a_171, %a_177 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc24)
    %a_178 = llvm.mlir.undef : !llvm.struct<(ptr<3>, i32, i32)> loc(#loc24)
    %a_179 = llvm.insertvalue %a_135, %a_178[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc24)
    %a_180 = llvm.insertvalue %a_136, %a_179[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc24)
    %a_181 = llvm.insertvalue %a_136, %a_180[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc24)
    %b = llvm.bitcast %b_ptr : !llvm.ptr<1> to !llvm.ptr<1> loc(#loc25)
    %b_182 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>)> loc(#loc25)
    %b_183 = llvm.insertvalue %b, %b_182[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc25)
    %b_184 = llvm.insertvalue %b, %b_183[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc25)
    %b_185 = llvm.extractvalue %b_184[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc25)
    %b_186 = llvm.extractvalue %b_184[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc25)
    %b_187 = llvm.extractvalue %a_46[0] : !llvm.struct<(i32, i32)>  loc(#loc25)
    %b_188 = llvm.extractvalue %a_46[1] : !llvm.struct<(i32, i32)>  loc(#loc25)
    %b_189 = llvm.getelementptr %b_185[%b_187] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc25)
    %b_190 = llvm.getelementptr %b_186[%b_188] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc25)
    %b_191 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>)> loc(#loc25)
    %b_192 = llvm.insertvalue %b_189, %b_191[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc25)
    %b_193 = llvm.insertvalue %b_190, %b_192[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc25)
    %b_194 = llvm.extractvalue %b_193[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc26)
    %b_195 = llvm.extractvalue %b_193[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc26)
    %b_196 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>)> loc(#loc26)
    %b_197 = llvm.insertvalue %b_195, %b_196[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc26)
    %b_198 = llvm.insertvalue %b_195, %b_197[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc26)
    %b_199 = llvm.extractvalue %b_198[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc26)
    %b_200 = llvm.extractvalue %b_198[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc26)
    %b_201 = llvm.extractvalue %a_113[0] : !llvm.struct<(i32, i32)>  loc(#loc26)
    %b_202 = llvm.extractvalue %a_113[1] : !llvm.struct<(i32, i32)>  loc(#loc26)
    %b_203 = llvm.getelementptr %b_199[%b_201] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc26)
    %b_204 = llvm.getelementptr %b_200[%b_202] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc26)
    %b_205 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>)> loc(#loc26)
    %b_206 = llvm.insertvalue %b_203, %b_205[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc26)
    %b_207 = llvm.insertvalue %b_204, %b_206[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc26)
    %b_208 = llvm.extractvalue %b_207[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc27)
    %b_209 = llvm.extractvalue %b_207[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc27)
    %b_210 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %b_208 : (!llvm.ptr<1>) -> i32 loc(#loc27)
    %b_211 = llvm.bitcast %b_210 : i32 to vector<2xf16> loc(#loc27)
    %b_212 = llvm.mlir.constant(0 : index) : i32 loc(#loc27)
    %b_213 = llvm.extractelement %b_211[%b_212 : i32] : vector<2xf16> loc(#loc27)
    %b_214 = llvm.mlir.constant(1 : index) : i32 loc(#loc27)
    %b_215 = llvm.extractelement %b_211[%b_214 : i32] : vector<2xf16> loc(#loc27)
    %b_216 = llvm.mlir.undef : !llvm.struct<(f16, f16)> loc(#loc27)
    %b_217 = llvm.insertvalue %b_213, %b_216[0] : !llvm.struct<(f16, f16)>  loc(#loc27)
    %b_218 = llvm.insertvalue %b_215, %b_217[1] : !llvm.struct<(f16, f16)>  loc(#loc27)
    %b_219 = llvm.mlir.constant(512 : i32) : i32 loc(#loc27)
    %13 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc)
    %b_220 = llvm.getelementptr %13[%b_219] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc27)
    %b_221 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_222 = llvm.extractvalue %b_218[0] : !llvm.struct<(f16, f16)>  loc(#loc27)
    %b_223 = llvm.extractvalue %b_218[1] : !llvm.struct<(f16, f16)>  loc(#loc27)
    %b_224 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc27)
    %b_225 = llvm.mlir.constant(127 : i32) : i32 loc(#loc27)
    %b_226 = llvm.and %b_224, %b_225 : i32 loc(#loc27)
    %b_227 = llvm.mlir.constant(32 : i32) : i32 loc(#loc27)
    %b_228 = llvm.urem %b_226, %b_227 : i32 loc(#loc27)
    %b_229 = llvm.udiv %b_226, %b_227 : i32 loc(#loc27)
    %b_230 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_231 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_232 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_233 = llvm.shl %b_228, %b_232 : i32 loc(#loc27)
    %b_234 = llvm.or %b_231, %b_233 : i32 loc(#loc27)
    %b_235 = llvm.mlir.constant(3 : i32) : i32 loc(#loc27)
    %b_236 = llvm.shl %b_229, %b_235 : i32 loc(#loc27)
    %b_237 = llvm.or %b_234, %b_236 : i32 loc(#loc27)
    %b_238 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_239 = llvm.mlir.constant(23 : i32) : i32 loc(#loc27)
    %b_240 = llvm.and %b_237, %b_239 : i32 loc(#loc27)
    %b_241 = llvm.mlir.constant(3 : i32) : i32 loc(#loc27)
    %b_242 = llvm.shl %b_240, %b_241 : i32 loc(#loc27)
    %b_243 = llvm.xor %b_238, %b_242 : i32 loc(#loc27)
    %b_244 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_245 = llvm.mlir.constant(8 : i32) : i32 loc(#loc27)
    %b_246 = llvm.and %b_237, %b_245 : i32 loc(#loc27)
    %b_247 = llvm.icmp "eq" %b_246, %b_244 : i32 loc(#loc27)
    %b_248 = llvm.mlir.constant(72 : i32) : i32 loc(#loc27)
    %b_249 = llvm.select %b_247, %b_244, %b_248 : i1, i32 loc(#loc27)
    %b_250 = llvm.xor %b_243, %b_249 : i32 loc(#loc27)
    %b_251 = llvm.xor %b_230, %b_250 : i32 loc(#loc27)
    %b_252 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_253 = llvm.xor %b_251, %b_252 : i32 loc(#loc27)
    %b_254 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_255 = llvm.xor %b_253, %b_254 : i32 loc(#loc27)
    %b_256 = llvm.getelementptr inbounds %b_220[%b_255] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_257 = llvm.mlir.undef : vector<2xf16> loc(#loc27)
    %b_258 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_259 = llvm.insertelement %b_222, %b_257[%b_258 : i32] : vector<2xf16> loc(#loc27)
    %b_260 = llvm.mlir.constant(1 : i32) : i32 loc(#loc27)
    %b_261 = llvm.insertelement %b_223, %b_259[%b_260 : i32] : vector<2xf16> loc(#loc27)
    %b_262 = llvm.bitcast %b_261 : vector<2xf16> to i32 loc(#loc27)
    nvvm.stmatrix %b_256, %b_262 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc27)
    %b_263 = llvm.mlir.undef : !llvm.struct<(ptr<3>, i32, i32)> loc(#loc27)
    %b_264 = llvm.insertvalue %b_220, %b_263[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc27)
    %b_265 = llvm.insertvalue %b_221, %b_264[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc27)
    %b_266 = llvm.insertvalue %b_221, %b_265[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc27)
    nvvm.barrier0 loc(#loc24)
    %a_267 = llvm.extractvalue %a_181[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc24)
    %a_268 = llvm.extractvalue %a_181[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc24)
    %a_269 = llvm.extractvalue %a_181[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc24)
    %a_270 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc24)
    %a_271 = llvm.mlir.constant(127 : i32) : i32 loc(#loc24)
    %a_272 = llvm.and %a_270, %a_271 : i32 loc(#loc24)
    %a_273 = llvm.mlir.constant(32 : i32) : i32 loc(#loc24)
    %a_274 = llvm.urem %a_272, %a_273 : i32 loc(#loc24)
    %a_275 = llvm.udiv %a_272, %a_273 : i32 loc(#loc24)
    %a_276 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_277 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_278 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_279 = llvm.shl %a_274, %a_278 : i32 loc(#loc24)
    %a_280 = llvm.or %a_277, %a_279 : i32 loc(#loc24)
    %a_281 = llvm.mlir.constant(5 : i32) : i32 loc(#loc24)
    %a_282 = llvm.shl %a_275, %a_281 : i32 loc(#loc24)
    %a_283 = llvm.or %a_280, %a_282 : i32 loc(#loc24)
    %a_284 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_285 = llvm.mlir.constant(11 : i32) : i32 loc(#loc24)
    %a_286 = llvm.and %a_283, %a_285 : i32 loc(#loc24)
    %a_287 = llvm.mlir.constant(4 : i32) : i32 loc(#loc24)
    %a_288 = llvm.shl %a_286, %a_287 : i32 loc(#loc24)
    %a_289 = llvm.xor %a_284, %a_288 : i32 loc(#loc24)
    %a_290 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_291 = llvm.mlir.constant(4 : i32) : i32 loc(#loc24)
    %a_292 = llvm.and %a_283, %a_291 : i32 loc(#loc24)
    %a_293 = llvm.icmp "eq" %a_292, %a_290 : i32 loc(#loc24)
    %a_294 = llvm.mlir.constant(72 : i32) : i32 loc(#loc24)
    %a_295 = llvm.select %a_293, %a_290, %a_294 : i1, i32 loc(#loc24)
    %a_296 = llvm.xor %a_289, %a_295 : i32 loc(#loc24)
    %a_297 = llvm.mlir.constant(16 : i32) : i32 loc(#loc24)
    %a_298 = llvm.and %a_283, %a_297 : i32 loc(#loc24)
    %a_299 = llvm.icmp "eq" %a_298, %a_290 : i32 loc(#loc24)
    %a_300 = llvm.mlir.constant(8 : i32) : i32 loc(#loc24)
    %a_301 = llvm.select %a_299, %a_290, %a_300 : i1, i32 loc(#loc24)
    %a_302 = llvm.xor %a_296, %a_301 : i32 loc(#loc24)
    %a_303 = llvm.xor %a_276, %a_302 : i32 loc(#loc24)
    %a_304 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_305 = llvm.xor %a_303, %a_304 : i32 loc(#loc24)
    %a_306 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_307 = llvm.xor %a_305, %a_306 : i32 loc(#loc24)
    %a_308 = llvm.getelementptr inbounds %a_267[%a_307] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_309 = nvgpu.ldmatrix %a_308, m8n8, 16 : (!llvm.ptr<3>) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc24)
    %a_310 = llvm.extractvalue %a_309[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_311 = llvm.bitcast %a_310 : i32 to vector<2xf16> loc(#loc24)
    %a_312 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_313 = llvm.extractelement %a_311[%a_312 : i32] : vector<2xf16> loc(#loc24)
    %a_314 = llvm.mlir.constant(1 : i32) : i32 loc(#loc24)
    %a_315 = llvm.extractelement %a_311[%a_314 : i32] : vector<2xf16> loc(#loc24)
    %a_316 = llvm.extractvalue %a_309[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_317 = llvm.bitcast %a_316 : i32 to vector<2xf16> loc(#loc24)
    %a_318 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_319 = llvm.extractelement %a_317[%a_318 : i32] : vector<2xf16> loc(#loc24)
    %a_320 = llvm.mlir.constant(1 : i32) : i32 loc(#loc24)
    %a_321 = llvm.extractelement %a_317[%a_320 : i32] : vector<2xf16> loc(#loc24)
    %a_322 = llvm.extractvalue %a_309[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_323 = llvm.bitcast %a_322 : i32 to vector<2xf16> loc(#loc24)
    %a_324 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_325 = llvm.extractelement %a_323[%a_324 : i32] : vector<2xf16> loc(#loc24)
    %a_326 = llvm.mlir.constant(1 : i32) : i32 loc(#loc24)
    %a_327 = llvm.extractelement %a_323[%a_326 : i32] : vector<2xf16> loc(#loc24)
    %a_328 = llvm.extractvalue %a_309[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_329 = llvm.bitcast %a_328 : i32 to vector<2xf16> loc(#loc24)
    %a_330 = llvm.mlir.constant(0 : i32) : i32 loc(#loc24)
    %a_331 = llvm.extractelement %a_329[%a_330 : i32] : vector<2xf16> loc(#loc24)
    %a_332 = llvm.mlir.constant(1 : i32) : i32 loc(#loc24)
    %a_333 = llvm.extractelement %a_329[%a_332 : i32] : vector<2xf16> loc(#loc24)
    %a_334 = llvm.mlir.undef : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)> loc(#loc24)
    %a_335 = llvm.insertvalue %a_313, %a_334[0] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc24)
    %a_336 = llvm.insertvalue %a_315, %a_335[1] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc24)
    %a_337 = llvm.insertvalue %a_319, %a_336[2] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc24)
    %a_338 = llvm.insertvalue %a_321, %a_337[3] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc24)
    %a_339 = llvm.insertvalue %a_325, %a_338[4] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc24)
    %a_340 = llvm.insertvalue %a_327, %a_339[5] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc24)
    %a_341 = llvm.insertvalue %a_331, %a_340[6] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc24)
    %a_342 = llvm.insertvalue %a_333, %a_341[7] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc24)
    %b_343 = llvm.extractvalue %b_266[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc27)
    %b_344 = llvm.extractvalue %b_266[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc27)
    %b_345 = llvm.extractvalue %b_266[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc27)
    %b_346 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc27)
    %b_347 = llvm.mlir.constant(127 : i32) : i32 loc(#loc27)
    %b_348 = llvm.and %b_346, %b_347 : i32 loc(#loc27)
    %b_349 = llvm.mlir.constant(32 : i32) : i32 loc(#loc27)
    %b_350 = llvm.urem %b_348, %b_349 : i32 loc(#loc27)
    %b_351 = llvm.udiv %b_348, %b_349 : i32 loc(#loc27)
    %b_352 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_353 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_354 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_355 = llvm.shl %b_350, %b_354 : i32 loc(#loc27)
    %b_356 = llvm.or %b_353, %b_355 : i32 loc(#loc27)
    %b_357 = llvm.mlir.constant(4 : i32) : i32 loc(#loc27)
    %b_358 = llvm.shl %b_351, %b_357 : i32 loc(#loc27)
    %b_359 = llvm.or %b_356, %b_358 : i32 loc(#loc27)
    %b_360 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_361 = llvm.mlir.constant(11 : i32) : i32 loc(#loc27)
    %b_362 = llvm.and %b_359, %b_361 : i32 loc(#loc27)
    %b_363 = llvm.mlir.constant(4 : i32) : i32 loc(#loc27)
    %b_364 = llvm.shl %b_362, %b_363 : i32 loc(#loc27)
    %b_365 = llvm.xor %b_360, %b_364 : i32 loc(#loc27)
    %b_366 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_367 = llvm.mlir.constant(4 : i32) : i32 loc(#loc27)
    %b_368 = llvm.and %b_359, %b_367 : i32 loc(#loc27)
    %b_369 = llvm.icmp "eq" %b_368, %b_366 : i32 loc(#loc27)
    %b_370 = llvm.mlir.constant(72 : i32) : i32 loc(#loc27)
    %b_371 = llvm.select %b_369, %b_366, %b_370 : i1, i32 loc(#loc27)
    %b_372 = llvm.xor %b_365, %b_371 : i32 loc(#loc27)
    %b_373 = llvm.mlir.constant(16 : i32) : i32 loc(#loc27)
    %b_374 = llvm.and %b_359, %b_373 : i32 loc(#loc27)
    %b_375 = llvm.icmp "eq" %b_374, %b_366 : i32 loc(#loc27)
    %b_376 = llvm.mlir.constant(8 : i32) : i32 loc(#loc27)
    %b_377 = llvm.select %b_375, %b_366, %b_376 : i1, i32 loc(#loc27)
    %b_378 = llvm.xor %b_372, %b_377 : i32 loc(#loc27)
    %b_379 = llvm.xor %b_352, %b_378 : i32 loc(#loc27)
    %b_380 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_381 = llvm.xor %b_379, %b_380 : i32 loc(#loc27)
    %b_382 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_383 = llvm.xor %b_381, %b_382 : i32 loc(#loc27)
    %b_384 = llvm.getelementptr inbounds %b_343[%b_383] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_385 = nvgpu.ldmatrix %b_384, m8n8, 16 {trans} : (!llvm.ptr<3>) -> !llvm.struct<(i32, i32)> loc(#loc27)
    %b_386 = llvm.extractvalue %b_385[0] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_387 = llvm.bitcast %b_386 : i32 to vector<2xf16> loc(#loc27)
    %b_388 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_389 = llvm.extractelement %b_387[%b_388 : i32] : vector<2xf16> loc(#loc27)
    %b_390 = llvm.mlir.constant(1 : i32) : i32 loc(#loc27)
    %b_391 = llvm.extractelement %b_387[%b_390 : i32] : vector<2xf16> loc(#loc27)
    %b_392 = llvm.extractvalue %b_385[1] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_393 = llvm.bitcast %b_392 : i32 to vector<2xf16> loc(#loc27)
    %b_394 = llvm.mlir.constant(0 : i32) : i32 loc(#loc27)
    %b_395 = llvm.extractelement %b_393[%b_394 : i32] : vector<2xf16> loc(#loc27)
    %b_396 = llvm.mlir.constant(1 : i32) : i32 loc(#loc27)
    %b_397 = llvm.extractelement %b_393[%b_396 : i32] : vector<2xf16> loc(#loc27)
    %b_398 = llvm.mlir.undef : !llvm.struct<(f16, f16, f16, f16)> loc(#loc27)
    %b_399 = llvm.insertvalue %b_389, %b_398[0] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc27)
    %b_400 = llvm.insertvalue %b_391, %b_399[1] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc27)
    %b_401 = llvm.insertvalue %b_395, %b_400[2] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc27)
    %b_402 = llvm.insertvalue %b_397, %b_401[3] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc27)
    %c = llvm.extractvalue %a_342[0] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc28)
    %c_403 = llvm.extractvalue %a_342[1] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc28)
    %c_404 = llvm.extractvalue %a_342[2] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc28)
    %c_405 = llvm.extractvalue %a_342[3] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc28)
    %c_406 = llvm.extractvalue %a_342[4] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc28)
    %c_407 = llvm.extractvalue %a_342[5] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc28)
    %c_408 = llvm.extractvalue %a_342[6] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc28)
    %c_409 = llvm.extractvalue %a_342[7] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc28)
    %c_410 = llvm.mlir.undef : vector<2xf16> loc(#loc28)
    %c_411 = llvm.mlir.constant(0 : i32) : i32 loc(#loc28)
    %c_412 = llvm.bitcast %c : f16 to f16 loc(#loc28)
    %c_413 = llvm.insertelement %c_412, %c_410[%c_411 : i32] : vector<2xf16> loc(#loc28)
    %c_414 = llvm.mlir.constant(1 : i32) : i32 loc(#loc28)
    %c_415 = llvm.bitcast %c_403 : f16 to f16 loc(#loc28)
    %c_416 = llvm.insertelement %c_415, %c_413[%c_414 : i32] : vector<2xf16> loc(#loc28)
    %c_417 = llvm.bitcast %c_416 : vector<2xf16> to i32 loc(#loc28)
    %c_418 = llvm.mlir.undef : vector<2xf16> loc(#loc28)
    %c_419 = llvm.mlir.constant(0 : i32) : i32 loc(#loc28)
    %c_420 = llvm.bitcast %c_404 : f16 to f16 loc(#loc28)
    %c_421 = llvm.insertelement %c_420, %c_418[%c_419 : i32] : vector<2xf16> loc(#loc28)
    %c_422 = llvm.mlir.constant(1 : i32) : i32 loc(#loc28)
    %c_423 = llvm.bitcast %c_405 : f16 to f16 loc(#loc28)
    %c_424 = llvm.insertelement %c_423, %c_421[%c_422 : i32] : vector<2xf16> loc(#loc28)
    %c_425 = llvm.bitcast %c_424 : vector<2xf16> to i32 loc(#loc28)
    %c_426 = llvm.mlir.undef : vector<2xf16> loc(#loc28)
    %c_427 = llvm.mlir.constant(0 : i32) : i32 loc(#loc28)
    %c_428 = llvm.bitcast %c_406 : f16 to f16 loc(#loc28)
    %c_429 = llvm.insertelement %c_428, %c_426[%c_427 : i32] : vector<2xf16> loc(#loc28)
    %c_430 = llvm.mlir.constant(1 : i32) : i32 loc(#loc28)
    %c_431 = llvm.bitcast %c_407 : f16 to f16 loc(#loc28)
    %c_432 = llvm.insertelement %c_431, %c_429[%c_430 : i32] : vector<2xf16> loc(#loc28)
    %c_433 = llvm.bitcast %c_432 : vector<2xf16> to i32 loc(#loc28)
    %c_434 = llvm.mlir.undef : vector<2xf16> loc(#loc28)
    %c_435 = llvm.mlir.constant(0 : i32) : i32 loc(#loc28)
    %c_436 = llvm.bitcast %c_408 : f16 to f16 loc(#loc28)
    %c_437 = llvm.insertelement %c_436, %c_434[%c_435 : i32] : vector<2xf16> loc(#loc28)
    %c_438 = llvm.mlir.constant(1 : i32) : i32 loc(#loc28)
    %c_439 = llvm.bitcast %c_409 : f16 to f16 loc(#loc28)
    %c_440 = llvm.insertelement %c_439, %c_437[%c_438 : i32] : vector<2xf16> loc(#loc28)
    %c_441 = llvm.bitcast %c_440 : vector<2xf16> to i32 loc(#loc28)
    %c_442 = llvm.extractvalue %b_402[0] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc28)
    %c_443 = llvm.extractvalue %b_402[1] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc28)
    %c_444 = llvm.extractvalue %b_402[2] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc28)
    %c_445 = llvm.extractvalue %b_402[3] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc28)
    %c_446 = llvm.mlir.undef : vector<2xf16> loc(#loc28)
    %c_447 = llvm.mlir.constant(0 : i32) : i32 loc(#loc28)
    %c_448 = llvm.bitcast %c_442 : f16 to f16 loc(#loc28)
    %c_449 = llvm.insertelement %c_448, %c_446[%c_447 : i32] : vector<2xf16> loc(#loc28)
    %c_450 = llvm.mlir.constant(1 : i32) : i32 loc(#loc28)
    %c_451 = llvm.bitcast %c_443 : f16 to f16 loc(#loc28)
    %c_452 = llvm.insertelement %c_451, %c_449[%c_450 : i32] : vector<2xf16> loc(#loc28)
    %c_453 = llvm.bitcast %c_452 : vector<2xf16> to i32 loc(#loc28)
    %c_454 = llvm.mlir.undef : vector<2xf16> loc(#loc28)
    %c_455 = llvm.mlir.constant(0 : i32) : i32 loc(#loc28)
    %c_456 = llvm.bitcast %c_444 : f16 to f16 loc(#loc28)
    %c_457 = llvm.insertelement %c_456, %c_454[%c_455 : i32] : vector<2xf16> loc(#loc28)
    %c_458 = llvm.mlir.constant(1 : i32) : i32 loc(#loc28)
    %c_459 = llvm.bitcast %c_445 : f16 to f16 loc(#loc28)
    %c_460 = llvm.insertelement %c_459, %c_457[%c_458 : i32] : vector<2xf16> loc(#loc28)
    %c_461 = llvm.bitcast %c_460 : vector<2xf16> to i32 loc(#loc28)
    %c_462 = llvm.extractvalue %11[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_463 = llvm.extractvalue %11[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_464 = llvm.extractvalue %11[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_465 = llvm.extractvalue %11[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_466 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %c_462, %c_463, %c_464, %c_465, %c_417, %c_425, %c_433, %c_441, %c_453, %c_461 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc28)
    %c_467 = llvm.extractvalue %c_466[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_468 = llvm.extractvalue %c_466[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_469 = llvm.extractvalue %c_466[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_470 = llvm.extractvalue %c_466[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_471 = llvm.bitcast %c_467 : f32 to f32 loc(#loc28)
    %c_472 = llvm.bitcast %c_468 : f32 to f32 loc(#loc28)
    %c_473 = llvm.bitcast %c_469 : f32 to f32 loc(#loc28)
    %c_474 = llvm.bitcast %c_470 : f32 to f32 loc(#loc28)
    %c_475 = llvm.mlir.undef : !llvm.struct<(f32, f32, f32, f32)> loc(#loc28)
    %c_476 = llvm.insertvalue %c_471, %c_475[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_477 = llvm.insertvalue %c_472, %c_476[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_478 = llvm.insertvalue %c_473, %c_477[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_479 = llvm.insertvalue %c_474, %c_478[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %14 = llvm.bitcast %c_ptr : !llvm.ptr<1> to !llvm.ptr<1> loc(#loc12)
    %15 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>)> loc(#loc12)
    %16 = llvm.insertvalue %14, %15[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc12)
    %17 = llvm.insertvalue %14, %16[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc12)
    %18 = llvm.extractvalue %17[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc12)
    %19 = llvm.extractvalue %17[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc12)
    %20 = llvm.extractvalue %a_46[0] : !llvm.struct<(i32, i32)>  loc(#loc12)
    %21 = llvm.extractvalue %a_46[1] : !llvm.struct<(i32, i32)>  loc(#loc12)
    %22 = llvm.getelementptr %18[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc12)
    %23 = llvm.getelementptr %19[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc12)
    %24 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>)> loc(#loc12)
    %25 = llvm.insertvalue %22, %24[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc12)
    %26 = llvm.insertvalue %23, %25[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc12)
    %27 = llvm.extractvalue %26[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc13)
    %28 = llvm.extractvalue %26[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc13)
    %29 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>)> loc(#loc13)
    %30 = llvm.insertvalue %28, %29[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc13)
    %31 = llvm.insertvalue %28, %30[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc13)
    %32 = llvm.extractvalue %31[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc13)
    %33 = llvm.extractvalue %31[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc13)
    %34 = llvm.extractvalue %a_113[0] : !llvm.struct<(i32, i32)>  loc(#loc13)
    %35 = llvm.extractvalue %a_113[1] : !llvm.struct<(i32, i32)>  loc(#loc13)
    %36 = llvm.getelementptr %32[%34] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc13)
    %37 = llvm.getelementptr %33[%35] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc13)
    %38 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>)> loc(#loc13)
    %39 = llvm.insertvalue %36, %38[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc13)
    %40 = llvm.insertvalue %37, %39[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc13)
    %41 = llvm.extractvalue %c_479[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc14)
    %42 = llvm.extractvalue %c_479[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc14)
    %43 = llvm.extractvalue %c_479[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc14)
    %44 = llvm.extractvalue %c_479[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc14)
    %45 = llvm.fptrunc %41 : f32 to f16 loc(#loc14)
    %46 = llvm.fptrunc %42 : f32 to f16 loc(#loc14)
    %47 = llvm.fptrunc %43 : f32 to f16 loc(#loc14)
    %48 = llvm.fptrunc %44 : f32 to f16 loc(#loc14)
    %49 = llvm.mlir.undef : !llvm.struct<(f16, f16, f16, f16)> loc(#loc14)
    %50 = llvm.insertvalue %45, %49[0] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc14)
    %51 = llvm.insertvalue %46, %50[1] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc14)
    %52 = llvm.insertvalue %47, %51[2] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc14)
    %53 = llvm.insertvalue %48, %52[3] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %54 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %55 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc)
    %56 = llvm.getelementptr %55[%54] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %57 = llvm.extractvalue %53[0] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc14)
    %58 = llvm.extractvalue %53[1] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc14)
    %59 = llvm.extractvalue %53[2] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc14)
    %60 = llvm.extractvalue %53[3] : !llvm.struct<(f16, f16, f16, f16)>  loc(#loc14)
    %61 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %62 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc14)
    %63 = llvm.mlir.constant(127 : i32) : i32 loc(#loc14)
    %64 = llvm.and %62, %63 : i32 loc(#loc14)
    %65 = llvm.mlir.constant(32 : i32) : i32 loc(#loc14)
    %66 = llvm.urem %64, %65 : i32 loc(#loc14)
    %67 = llvm.udiv %64, %65 : i32 loc(#loc14)
    %68 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %69 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %70 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %71 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %72 = llvm.shl %66, %71 : i32 loc(#loc14)
    %73 = llvm.or %70, %72 : i32 loc(#loc14)
    %74 = llvm.mlir.constant(5 : i32) : i32 loc(#loc14)
    %75 = llvm.shl %67, %74 : i32 loc(#loc14)
    %76 = llvm.or %73, %75 : i32 loc(#loc14)
    %77 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %78 = llvm.mlir.constant(3 : i32) : i32 loc(#loc14)
    %79 = llvm.and %76, %78 : i32 loc(#loc14)
    %80 = llvm.mlir.constant(4 : i32) : i32 loc(#loc14)
    %81 = llvm.shl %79, %80 : i32 loc(#loc14)
    %82 = llvm.xor %77, %81 : i32 loc(#loc14)
    %83 = llvm.mlir.constant(12 : i32) : i32 loc(#loc14)
    %84 = llvm.and %76, %83 : i32 loc(#loc14)
    %85 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %86 = llvm.lshr %84, %85 : i32 loc(#loc14)
    %87 = llvm.xor %82, %86 : i32 loc(#loc14)
    %88 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %89 = llvm.mlir.constant(16 : i32) : i32 loc(#loc14)
    %90 = llvm.and %76, %89 : i32 loc(#loc14)
    %91 = llvm.icmp "eq" %90, %88 : i32 loc(#loc14)
    %92 = llvm.mlir.constant(320 : i32) : i32 loc(#loc14)
    %93 = llvm.select %91, %88, %92 : i1, i32 loc(#loc14)
    %94 = llvm.xor %87, %93 : i32 loc(#loc14)
    %95 = llvm.mlir.constant(32 : i32) : i32 loc(#loc14)
    %96 = llvm.and %76, %95 : i32 loc(#loc14)
    %97 = llvm.icmp "eq" %96, %88 : i32 loc(#loc14)
    %98 = llvm.mlir.constant(64 : i32) : i32 loc(#loc14)
    %99 = llvm.select %97, %88, %98 : i1, i32 loc(#loc14)
    %100 = llvm.xor %94, %99 : i32 loc(#loc14)
    %101 = llvm.xor %69, %100 : i32 loc(#loc14)
    %102 = llvm.mlir.constant(2 : i32) : i32 loc(#loc14)
    %103 = llvm.mul %61, %102 : i32 loc(#loc14)
    %104 = llvm.xor %101, %103 : i32 loc(#loc14)
    %105 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %106 = llvm.xor %104, %105 : i32 loc(#loc14)
    %107 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %108 = llvm.add %106, %107 : i32 loc(#loc14)
    %109 = llvm.getelementptr inbounds %56[%108] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %110 = llvm.mlir.undef : vector<2xf16> loc(#loc14)
    %111 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %112 = llvm.insertelement %57, %110[%111 : i32] : vector<2xf16> loc(#loc14)
    %113 = llvm.mlir.constant(1 : i32) : i32 loc(#loc14)
    %114 = llvm.insertelement %58, %112[%113 : i32] : vector<2xf16> loc(#loc14)
    %115 = llvm.mlir.constant(true) : i1 loc(#loc14)
    %116 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %117 = llvm.extractelement %114[%116 : i32] : vector<2xf16> loc(#loc14)
    %118 = llvm.mlir.constant(1 : i32) : i32 loc(#loc14)
    %119 = llvm.extractelement %114[%118 : i32] : vector<2xf16> loc(#loc14)
    %120 = llvm.bitcast %117 : f16 to i16 loc(#loc14)
    %121 = llvm.bitcast %119 : f16 to i16 loc(#loc14)
    %122 = llvm.mlir.undef : vector<2xi16> loc(#loc14)
    %123 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %124 = llvm.insertelement %120, %122[%123 : i32] : vector<2xi16> loc(#loc14)
    %125 = llvm.mlir.constant(1 : i32) : i32 loc(#loc14)
    %126 = llvm.insertelement %121, %124[%125 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %126, %109 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    %127 = llvm.mlir.constant(128 : i32) : i32 loc(#loc14)
    %128 = llvm.add %106, %127 : i32 loc(#loc14)
    %129 = llvm.getelementptr inbounds %56[%128] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %130 = llvm.mlir.undef : vector<2xf16> loc(#loc14)
    %131 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %132 = llvm.insertelement %59, %130[%131 : i32] : vector<2xf16> loc(#loc14)
    %133 = llvm.mlir.constant(1 : i32) : i32 loc(#loc14)
    %134 = llvm.insertelement %60, %132[%133 : i32] : vector<2xf16> loc(#loc14)
    %135 = llvm.mlir.constant(true) : i1 loc(#loc14)
    %136 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %137 = llvm.extractelement %134[%136 : i32] : vector<2xf16> loc(#loc14)
    %138 = llvm.mlir.constant(1 : i32) : i32 loc(#loc14)
    %139 = llvm.extractelement %134[%138 : i32] : vector<2xf16> loc(#loc14)
    %140 = llvm.bitcast %137 : f16 to i16 loc(#loc14)
    %141 = llvm.bitcast %139 : f16 to i16 loc(#loc14)
    %142 = llvm.mlir.undef : vector<2xi16> loc(#loc14)
    %143 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %144 = llvm.insertelement %140, %142[%143 : i32] : vector<2xi16> loc(#loc14)
    %145 = llvm.mlir.constant(1 : i32) : i32 loc(#loc14)
    %146 = llvm.insertelement %141, %144[%145 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %146, %129 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %147 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc14)
    %148 = llvm.mlir.constant(127 : i32) : i32 loc(#loc14)
    %149 = llvm.and %147, %148 : i32 loc(#loc14)
    %150 = llvm.mlir.constant(32 : i32) : i32 loc(#loc14)
    %151 = llvm.urem %149, %150 : i32 loc(#loc14)
    %152 = llvm.udiv %149, %150 : i32 loc(#loc14)
    %153 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %154 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %155 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %156 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %157 = llvm.shl %151, %156 : i32 loc(#loc14)
    %158 = llvm.or %155, %157 : i32 loc(#loc14)
    %159 = llvm.mlir.constant(5 : i32) : i32 loc(#loc14)
    %160 = llvm.shl %152, %159 : i32 loc(#loc14)
    %161 = llvm.or %158, %160 : i32 loc(#loc14)
    %162 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %163 = llvm.mlir.constant(7 : i32) : i32 loc(#loc14)
    %164 = llvm.and %161, %163 : i32 loc(#loc14)
    %165 = llvm.mlir.constant(4 : i32) : i32 loc(#loc14)
    %166 = llvm.shl %164, %165 : i32 loc(#loc14)
    %167 = llvm.xor %162, %166 : i32 loc(#loc14)
    %168 = llvm.mlir.constant(24 : i32) : i32 loc(#loc14)
    %169 = llvm.and %161, %168 : i32 loc(#loc14)
    %170 = llvm.mlir.constant(1 : i32) : i32 loc(#loc14)
    %171 = llvm.lshr %169, %170 : i32 loc(#loc14)
    %172 = llvm.xor %167, %171 : i32 loc(#loc14)
    %173 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %174 = llvm.mlir.constant(32 : i32) : i32 loc(#loc14)
    %175 = llvm.and %161, %174 : i32 loc(#loc14)
    %176 = llvm.icmp "eq" %175, %173 : i32 loc(#loc14)
    %177 = llvm.mlir.constant(320 : i32) : i32 loc(#loc14)
    %178 = llvm.select %176, %173, %177 : i1, i32 loc(#loc14)
    %179 = llvm.xor %172, %178 : i32 loc(#loc14)
    %180 = llvm.mlir.constant(64 : i32) : i32 loc(#loc14)
    %181 = llvm.and %161, %180 : i32 loc(#loc14)
    %182 = llvm.icmp "eq" %181, %173 : i32 loc(#loc14)
    %183 = llvm.mlir.constant(128 : i32) : i32 loc(#loc14)
    %184 = llvm.select %182, %173, %183 : i1, i32 loc(#loc14)
    %185 = llvm.xor %179, %184 : i32 loc(#loc14)
    %186 = llvm.xor %154, %185 : i32 loc(#loc14)
    %187 = llvm.mlir.constant(2 : i32) : i32 loc(#loc14)
    %188 = llvm.mul %61, %187 : i32 loc(#loc14)
    %189 = llvm.xor %186, %188 : i32 loc(#loc14)
    %190 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %191 = llvm.xor %189, %190 : i32 loc(#loc14)
    %192 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %193 = llvm.add %191, %192 : i32 loc(#loc14)
    %194 = llvm.getelementptr inbounds %56[%193] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %195 = llvm.mlir.constant(true) : i1 loc(#loc14)
    %196 = llvm.load %194 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<2xi16> loc(#loc14)
    %197 = llvm.mlir.undef : !llvm.struct<(i16, i16)> loc(#loc14)
    %198 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %199 = llvm.extractelement %196[%198 : i32] : vector<2xi16> loc(#loc14)
    %200 = llvm.insertvalue %199, %197[0] : !llvm.struct<(i16, i16)>  loc(#loc14)
    %201 = llvm.mlir.constant(1 : i32) : i32 loc(#loc14)
    %202 = llvm.extractelement %196[%201 : i32] : vector<2xi16> loc(#loc14)
    %203 = llvm.insertvalue %202, %200[1] : !llvm.struct<(i16, i16)>  loc(#loc14)
    %204 = llvm.extractvalue %203[0] : !llvm.struct<(i16, i16)>  loc(#loc14)
    %205 = llvm.extractvalue %203[1] : !llvm.struct<(i16, i16)>  loc(#loc14)
    %206 = llvm.mlir.undef : vector<2xi16> loc(#loc14)
    %207 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %208 = llvm.insertelement %204, %206[%207 : i32] : vector<2xi16> loc(#loc14)
    %209 = llvm.mlir.constant(1 : i32) : i32 loc(#loc14)
    %210 = llvm.insertelement %205, %208[%209 : i32] : vector<2xi16> loc(#loc14)
    %211 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %212 = llvm.extractelement %210[%211 : i32] : vector<2xi16> loc(#loc14)
    %213 = llvm.mlir.constant(1 : i32) : i32 loc(#loc14)
    %214 = llvm.extractelement %210[%213 : i32] : vector<2xi16> loc(#loc14)
    %215 = llvm.bitcast %212 : i16 to f16 loc(#loc14)
    %216 = llvm.bitcast %214 : i16 to f16 loc(#loc14)
    %217 = llvm.mlir.undef : vector<2xf16> loc(#loc14)
    %218 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %219 = llvm.insertelement %215, %217[%218 : i32] : vector<2xf16> loc(#loc14)
    %220 = llvm.mlir.constant(1 : i32) : i32 loc(#loc14)
    %221 = llvm.insertelement %216, %219[%220 : i32] : vector<2xf16> loc(#loc14)
    %222 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %223 = llvm.extractelement %221[%222 : i32] : vector<2xf16> loc(#loc14)
    %224 = llvm.mlir.constant(1 : i32) : i32 loc(#loc14)
    %225 = llvm.extractelement %221[%224 : i32] : vector<2xf16> loc(#loc14)
    %226 = llvm.mlir.undef : !llvm.struct<(f16, f16)> loc(#loc14)
    %227 = llvm.insertvalue %223, %226[0] : !llvm.struct<(f16, f16)>  loc(#loc14)
    %228 = llvm.insertvalue %225, %227[1] : !llvm.struct<(f16, f16)>  loc(#loc14)
    %229 = llvm.extractvalue %40[0] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc14)
    %230 = llvm.extractvalue %40[1] : !llvm.struct<(ptr<1>, ptr<1>)>  loc(#loc14)
    %231 = llvm.extractvalue %228[0] : !llvm.struct<(f16, f16)>  loc(#loc14)
    %232 = llvm.extractvalue %228[1] : !llvm.struct<(f16, f16)>  loc(#loc14)
    %233 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %234 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc14)
    %235 = llvm.mlir.constant(127 : i32) : i32 loc(#loc14)
    %236 = llvm.and %234, %235 : i32 loc(#loc14)
    %237 = llvm.mlir.constant(32 : i32) : i32 loc(#loc14)
    %238 = llvm.urem %236, %237 : i32 loc(#loc14)
    %239 = llvm.udiv %236, %237 : i32 loc(#loc14)
    %240 = llvm.mlir.undef : vector<2xf16> loc(#loc14)
    %241 = llvm.bitcast %231 : f16 to f16 loc(#loc14)
    %242 = llvm.mlir.constant(0 : i32) : i32 loc(#loc14)
    %243 = llvm.insertelement %241, %240[%242 : i32] : vector<2xf16> loc(#loc14)
    %244 = llvm.bitcast %232 : f16 to f16 loc(#loc14)
    %245 = llvm.mlir.constant(1 : i32) : i32 loc(#loc14)
    %246 = llvm.insertelement %244, %243[%245 : i32] : vector<2xf16> loc(#loc14)
    %247 = llvm.bitcast %246 : vector<2xf16> to i32 loc(#loc14)
    %248 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "st.global.b32 [ $1 + 0 ], { $0 };", "r,l" %247, %229 : (i32, !llvm.ptr<1>) -> !llvm.void loc(#loc14)
    llvm.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before CSE (cse) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 1024 : i32, ttg.target = "cuda:90", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @tiny_matmul_kernel(%a_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc)), %arg3: !llvm.ptr<1> loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %1 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %2 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %3 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %4 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %5 = llvm.mlir.constant(320 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %7 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(11 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %10 = llvm.mlir.constant(72 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.constant(23 : i32) : i32 loc(#loc1)
    %13 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %14 = llvm.mlir.constant(1 : index) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(120 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %22 = llvm.mlir.constant(127 : i32) : i32 loc(#loc1)
    %23 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %25 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %a = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc19)
    %a_0 = llvm.and %a, %22 : i32 loc(#loc19)
    %a_1 = llvm.urem %a_0, %21 : i32 loc(#loc19)
    %a_2 = llvm.udiv %a_0, %21 : i32 loc(#loc19)
    %a_3 = llvm.shl %a_1, %20 : i32 loc(#loc19)
    %a_4 = llvm.or %20, %a_3 : i32 loc(#loc19)
    %a_5 = llvm.shl %a_2, %19 : i32 loc(#loc19)
    %a_6 = llvm.or %a_4, %a_5 : i32 loc(#loc19)
    %a_7 = llvm.or %a_6, %20 : i32 loc(#loc19)
    %a_8 = llvm.and %a_7, %17 : i32 loc(#loc19)
    %a_9 = llvm.lshr %a_8, %16 : i32 loc(#loc19)
    %a_10 = llvm.xor %20, %a_9 : i32 loc(#loc19)
    %a_11 = llvm.xor %20, %a_10 : i32 loc(#loc19)
    %a_12 = llvm.xor %a_11, %20 : i32 loc(#loc19)
    %a_13 = llvm.add %a_12, %23 : i32 loc(#loc19)
    %a_14 = llvm.mul %a_13, %25 : i32 loc(#loc20)
    %a_15 = llvm.getelementptr %a_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc21)
    %a_16 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc22)
    %a_17 = llvm.and %a_16, %22 : i32 loc(#loc22)
    %a_18 = llvm.urem %a_17, %21 : i32 loc(#loc22)
    %a_19 = llvm.udiv %a_17, %21 : i32 loc(#loc22)
    %a_20 = llvm.shl %a_18, %20 : i32 loc(#loc22)
    %a_21 = llvm.or %20, %a_20 : i32 loc(#loc22)
    %a_22 = llvm.shl %a_19, %19 : i32 loc(#loc22)
    %a_23 = llvm.or %a_21, %a_22 : i32 loc(#loc22)
    %a_24 = llvm.or %a_23, %20 : i32 loc(#loc22)
    %a_25 = llvm.and %a_24, %18 : i32 loc(#loc22)
    %a_26 = llvm.shl %a_25, %15 : i32 loc(#loc22)
    %a_27 = llvm.xor %20, %a_26 : i32 loc(#loc22)
    %a_28 = llvm.xor %20, %a_27 : i32 loc(#loc22)
    %a_29 = llvm.xor %a_28, %20 : i32 loc(#loc22)
    %a_30 = llvm.add %a_29, %23 : i32 loc(#loc22)
    %a_31 = llvm.getelementptr %a_15[%a_30] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc23)
    %a_32 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %a_31 : (!llvm.ptr<1>) -> i32 loc(#loc24)
    %a_33 = llvm.bitcast %a_32 : i32 to vector<2xf16> loc(#loc24)
    %a_34 = llvm.extractelement %a_33[%23 : i32] : vector<2xf16> loc(#loc24)
    %a_35 = llvm.extractelement %a_33[%14 : i32] : vector<2xf16> loc(#loc24)
    %a_36 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc24)
    %a_37 = llvm.and %a_36, %22 : i32 loc(#loc24)
    %a_38 = llvm.urem %a_37, %21 : i32 loc(#loc24)
    %a_39 = llvm.udiv %a_37, %21 : i32 loc(#loc24)
    %a_40 = llvm.shl %a_38, %20 : i32 loc(#loc24)
    %a_41 = llvm.or %20, %a_40 : i32 loc(#loc24)
    %a_42 = llvm.shl %a_39, %16 : i32 loc(#loc24)
    %a_43 = llvm.or %a_41, %a_42 : i32 loc(#loc24)
    %a_44 = llvm.and %a_43, %12 : i32 loc(#loc24)
    %a_45 = llvm.shl %a_44, %16 : i32 loc(#loc24)
    %a_46 = llvm.xor %20, %a_45 : i32 loc(#loc24)
    %a_47 = llvm.and %a_43, %11 : i32 loc(#loc24)
    %a_48 = llvm.icmp "eq" %a_47, %20 : i32 loc(#loc24)
    %a_49 = llvm.select %a_48, %20, %10 : i1, i32 loc(#loc24)
    %a_50 = llvm.xor %a_46, %a_49 : i32 loc(#loc24)
    %a_51 = llvm.xor %20, %a_50 : i32 loc(#loc24)
    %a_52 = llvm.xor %a_51, %20 : i32 loc(#loc24)
    %a_53 = llvm.xor %a_52, %20 : i32 loc(#loc24)
    %a_54 = llvm.getelementptr inbounds %13[%a_53] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_55 = llvm.insertelement %a_34, %9[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_56 = llvm.insertelement %a_35, %a_55[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_57 = llvm.bitcast %a_56 : vector<2xf16> to i32 loc(#loc24)
    nvvm.stmatrix %a_54, %a_57 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc24)
    %b = llvm.getelementptr %b_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc25)
    %b_58 = llvm.getelementptr %b[%a_30] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc26)
    %b_59 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %b_58 : (!llvm.ptr<1>) -> i32 loc(#loc27)
    %b_60 = llvm.bitcast %b_59 : i32 to vector<2xf16> loc(#loc27)
    %b_61 = llvm.extractelement %b_60[%23 : i32] : vector<2xf16> loc(#loc27)
    %b_62 = llvm.extractelement %b_60[%14 : i32] : vector<2xf16> loc(#loc27)
    %b_63 = llvm.getelementptr %13[512] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc27)
    %b_64 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc27)
    %b_65 = llvm.and %b_64, %22 : i32 loc(#loc27)
    %b_66 = llvm.urem %b_65, %21 : i32 loc(#loc27)
    %b_67 = llvm.udiv %b_65, %21 : i32 loc(#loc27)
    %b_68 = llvm.shl %b_66, %20 : i32 loc(#loc27)
    %b_69 = llvm.or %20, %b_68 : i32 loc(#loc27)
    %b_70 = llvm.shl %b_67, %16 : i32 loc(#loc27)
    %b_71 = llvm.or %b_69, %b_70 : i32 loc(#loc27)
    %b_72 = llvm.and %b_71, %12 : i32 loc(#loc27)
    %b_73 = llvm.shl %b_72, %16 : i32 loc(#loc27)
    %b_74 = llvm.xor %20, %b_73 : i32 loc(#loc27)
    %b_75 = llvm.and %b_71, %11 : i32 loc(#loc27)
    %b_76 = llvm.icmp "eq" %b_75, %20 : i32 loc(#loc27)
    %b_77 = llvm.select %b_76, %20, %10 : i1, i32 loc(#loc27)
    %b_78 = llvm.xor %b_74, %b_77 : i32 loc(#loc27)
    %b_79 = llvm.xor %20, %b_78 : i32 loc(#loc27)
    %b_80 = llvm.xor %b_79, %20 : i32 loc(#loc27)
    %b_81 = llvm.xor %b_80, %20 : i32 loc(#loc27)
    %b_82 = llvm.getelementptr inbounds %b_63[%b_81] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_83 = llvm.insertelement %b_61, %9[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_84 = llvm.insertelement %b_62, %b_83[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_85 = llvm.bitcast %b_84 : vector<2xf16> to i32 loc(#loc27)
    nvvm.stmatrix %b_82, %b_85 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc27)
    nvvm.barrier0 loc(#loc24)
    %a_86 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc24)
    %a_87 = llvm.and %a_86, %22 : i32 loc(#loc24)
    %a_88 = llvm.urem %a_87, %21 : i32 loc(#loc24)
    %a_89 = llvm.udiv %a_87, %21 : i32 loc(#loc24)
    %a_90 = llvm.shl %a_88, %20 : i32 loc(#loc24)
    %a_91 = llvm.or %20, %a_90 : i32 loc(#loc24)
    %a_92 = llvm.shl %a_89, %19 : i32 loc(#loc24)
    %a_93 = llvm.or %a_91, %a_92 : i32 loc(#loc24)
    %a_94 = llvm.and %a_93, %8 : i32 loc(#loc24)
    %a_95 = llvm.shl %a_94, %7 : i32 loc(#loc24)
    %a_96 = llvm.xor %20, %a_95 : i32 loc(#loc24)
    %a_97 = llvm.and %a_93, %7 : i32 loc(#loc24)
    %a_98 = llvm.icmp "eq" %a_97, %20 : i32 loc(#loc24)
    %a_99 = llvm.select %a_98, %20, %10 : i1, i32 loc(#loc24)
    %a_100 = llvm.xor %a_96, %a_99 : i32 loc(#loc24)
    %a_101 = llvm.and %a_93, %25 : i32 loc(#loc24)
    %a_102 = llvm.icmp "eq" %a_101, %20 : i32 loc(#loc24)
    %a_103 = llvm.select %a_102, %20, %11 : i1, i32 loc(#loc24)
    %a_104 = llvm.xor %a_100, %a_103 : i32 loc(#loc24)
    %a_105 = llvm.xor %20, %a_104 : i32 loc(#loc24)
    %a_106 = llvm.xor %a_105, %20 : i32 loc(#loc24)
    %a_107 = llvm.xor %a_106, %20 : i32 loc(#loc24)
    %a_108 = llvm.getelementptr inbounds %13[%a_107] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_109 = nvgpu.ldmatrix %a_108, m8n8, 16 : (!llvm.ptr<3>) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc24)
    %a_110 = llvm.extractvalue %a_109[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_111 = llvm.bitcast %a_110 : i32 to vector<2xf16> loc(#loc24)
    %a_112 = llvm.extractelement %a_111[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_113 = llvm.extractelement %a_111[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_114 = llvm.extractvalue %a_109[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_115 = llvm.bitcast %a_114 : i32 to vector<2xf16> loc(#loc24)
    %a_116 = llvm.extractelement %a_115[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_117 = llvm.extractelement %a_115[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_118 = llvm.extractvalue %a_109[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_119 = llvm.bitcast %a_118 : i32 to vector<2xf16> loc(#loc24)
    %a_120 = llvm.extractelement %a_119[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_121 = llvm.extractelement %a_119[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_122 = llvm.extractvalue %a_109[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_123 = llvm.bitcast %a_122 : i32 to vector<2xf16> loc(#loc24)
    %a_124 = llvm.extractelement %a_123[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_125 = llvm.extractelement %a_123[%15 : i32] : vector<2xf16> loc(#loc24)
    %b_126 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc27)
    %b_127 = llvm.and %b_126, %22 : i32 loc(#loc27)
    %b_128 = llvm.urem %b_127, %21 : i32 loc(#loc27)
    %b_129 = llvm.udiv %b_127, %21 : i32 loc(#loc27)
    %b_130 = llvm.shl %b_128, %20 : i32 loc(#loc27)
    %b_131 = llvm.or %20, %b_130 : i32 loc(#loc27)
    %b_132 = llvm.shl %b_129, %7 : i32 loc(#loc27)
    %b_133 = llvm.or %b_131, %b_132 : i32 loc(#loc27)
    %b_134 = llvm.and %b_133, %8 : i32 loc(#loc27)
    %b_135 = llvm.shl %b_134, %7 : i32 loc(#loc27)
    %b_136 = llvm.xor %20, %b_135 : i32 loc(#loc27)
    %b_137 = llvm.and %b_133, %7 : i32 loc(#loc27)
    %b_138 = llvm.icmp "eq" %b_137, %20 : i32 loc(#loc27)
    %b_139 = llvm.select %b_138, %20, %10 : i1, i32 loc(#loc27)
    %b_140 = llvm.xor %b_136, %b_139 : i32 loc(#loc27)
    %b_141 = llvm.and %b_133, %25 : i32 loc(#loc27)
    %b_142 = llvm.icmp "eq" %b_141, %20 : i32 loc(#loc27)
    %b_143 = llvm.select %b_142, %20, %11 : i1, i32 loc(#loc27)
    %b_144 = llvm.xor %b_140, %b_143 : i32 loc(#loc27)
    %b_145 = llvm.xor %20, %b_144 : i32 loc(#loc27)
    %b_146 = llvm.xor %b_145, %20 : i32 loc(#loc27)
    %b_147 = llvm.xor %b_146, %20 : i32 loc(#loc27)
    %b_148 = llvm.getelementptr inbounds %b_63[%b_147] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_149 = nvgpu.ldmatrix %b_148, m8n8, 16 {trans} : (!llvm.ptr<3>) -> !llvm.struct<(i32, i32)> loc(#loc27)
    %b_150 = llvm.extractvalue %b_149[0] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_151 = llvm.bitcast %b_150 : i32 to vector<2xf16> loc(#loc27)
    %b_152 = llvm.extractelement %b_151[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_153 = llvm.extractelement %b_151[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_154 = llvm.extractvalue %b_149[1] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_155 = llvm.bitcast %b_154 : i32 to vector<2xf16> loc(#loc27)
    %b_156 = llvm.extractelement %b_155[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_157 = llvm.extractelement %b_155[%15 : i32] : vector<2xf16> loc(#loc27)
    %c = llvm.insertelement %a_112, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_158 = llvm.insertelement %a_113, %c[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_159 = llvm.bitcast %c_158 : vector<2xf16> to i32 loc(#loc28)
    %c_160 = llvm.insertelement %a_116, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_161 = llvm.insertelement %a_117, %c_160[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_162 = llvm.bitcast %c_161 : vector<2xf16> to i32 loc(#loc28)
    %c_163 = llvm.insertelement %a_120, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_164 = llvm.insertelement %a_121, %c_163[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_165 = llvm.bitcast %c_164 : vector<2xf16> to i32 loc(#loc28)
    %c_166 = llvm.insertelement %a_124, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_167 = llvm.insertelement %a_125, %c_166[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_168 = llvm.bitcast %c_167 : vector<2xf16> to i32 loc(#loc28)
    %c_169 = llvm.insertelement %b_152, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_170 = llvm.insertelement %b_153, %c_169[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_171 = llvm.bitcast %c_170 : vector<2xf16> to i32 loc(#loc28)
    %c_172 = llvm.insertelement %b_156, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_173 = llvm.insertelement %b_157, %c_172[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_174 = llvm.bitcast %c_173 : vector<2xf16> to i32 loc(#loc28)
    %c_175 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %24, %24, %24, %24, %c_159, %c_162, %c_165, %c_168, %c_171, %c_174 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc28)
    %c_176 = llvm.extractvalue %c_175[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_177 = llvm.extractvalue %c_175[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_178 = llvm.extractvalue %c_175[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_179 = llvm.extractvalue %c_175[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %26 = llvm.getelementptr %c_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc12)
    %27 = llvm.getelementptr %26[%a_30] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc13)
    %28 = llvm.fptrunc %c_176 : f32 to f16 loc(#loc14)
    %29 = llvm.fptrunc %c_177 : f32 to f16 loc(#loc14)
    %30 = llvm.fptrunc %c_178 : f32 to f16 loc(#loc14)
    %31 = llvm.fptrunc %c_179 : f32 to f16 loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %32 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc14)
    %33 = llvm.and %32, %22 : i32 loc(#loc14)
    %34 = llvm.urem %33, %21 : i32 loc(#loc14)
    %35 = llvm.udiv %33, %21 : i32 loc(#loc14)
    %36 = llvm.shl %34, %20 : i32 loc(#loc14)
    %37 = llvm.or %20, %36 : i32 loc(#loc14)
    %38 = llvm.shl %35, %19 : i32 loc(#loc14)
    %39 = llvm.or %37, %38 : i32 loc(#loc14)
    %40 = llvm.and %39, %16 : i32 loc(#loc14)
    %41 = llvm.shl %40, %7 : i32 loc(#loc14)
    %42 = llvm.xor %20, %41 : i32 loc(#loc14)
    %43 = llvm.and %39, %6 : i32 loc(#loc14)
    %44 = llvm.lshr %43, %20 : i32 loc(#loc14)
    %45 = llvm.xor %42, %44 : i32 loc(#loc14)
    %46 = llvm.and %39, %25 : i32 loc(#loc14)
    %47 = llvm.icmp "eq" %46, %20 : i32 loc(#loc14)
    %48 = llvm.select %47, %20, %5 : i1, i32 loc(#loc14)
    %49 = llvm.xor %45, %48 : i32 loc(#loc14)
    %50 = llvm.and %39, %21 : i32 loc(#loc14)
    %51 = llvm.icmp "eq" %50, %20 : i32 loc(#loc14)
    %52 = llvm.select %51, %20, %4 : i1, i32 loc(#loc14)
    %53 = llvm.xor %49, %52 : i32 loc(#loc14)
    %54 = llvm.xor %20, %53 : i32 loc(#loc14)
    %55 = llvm.mul %20, %3 : i32 loc(#loc14)
    %56 = llvm.xor %54, %55 : i32 loc(#loc14)
    %57 = llvm.xor %56, %20 : i32 loc(#loc14)
    %58 = llvm.add %57, %20 : i32 loc(#loc14)
    %59 = llvm.getelementptr inbounds %13[%58] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %60 = llvm.insertelement %28, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %61 = llvm.insertelement %29, %60[%15 : i32] : vector<2xf16> loc(#loc14)
    %62 = llvm.extractelement %61[%20 : i32] : vector<2xf16> loc(#loc14)
    %63 = llvm.extractelement %61[%15 : i32] : vector<2xf16> loc(#loc14)
    %64 = llvm.bitcast %62 : f16 to i16 loc(#loc14)
    %65 = llvm.bitcast %63 : f16 to i16 loc(#loc14)
    %66 = llvm.insertelement %64, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %67 = llvm.insertelement %65, %66[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %67, %59 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    %68 = llvm.add %57, %1 : i32 loc(#loc14)
    %69 = llvm.getelementptr inbounds %13[%68] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %70 = llvm.insertelement %30, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %71 = llvm.insertelement %31, %70[%15 : i32] : vector<2xf16> loc(#loc14)
    %72 = llvm.extractelement %71[%20 : i32] : vector<2xf16> loc(#loc14)
    %73 = llvm.extractelement %71[%15 : i32] : vector<2xf16> loc(#loc14)
    %74 = llvm.bitcast %72 : f16 to i16 loc(#loc14)
    %75 = llvm.bitcast %73 : f16 to i16 loc(#loc14)
    %76 = llvm.insertelement %74, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %77 = llvm.insertelement %75, %76[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %77, %69 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %78 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc14)
    %79 = llvm.and %78, %22 : i32 loc(#loc14)
    %80 = llvm.urem %79, %21 : i32 loc(#loc14)
    %81 = llvm.udiv %79, %21 : i32 loc(#loc14)
    %82 = llvm.shl %80, %20 : i32 loc(#loc14)
    %83 = llvm.or %20, %82 : i32 loc(#loc14)
    %84 = llvm.shl %81, %19 : i32 loc(#loc14)
    %85 = llvm.or %83, %84 : i32 loc(#loc14)
    %86 = llvm.and %85, %18 : i32 loc(#loc14)
    %87 = llvm.shl %86, %7 : i32 loc(#loc14)
    %88 = llvm.xor %20, %87 : i32 loc(#loc14)
    %89 = llvm.and %85, %0 : i32 loc(#loc14)
    %90 = llvm.lshr %89, %15 : i32 loc(#loc14)
    %91 = llvm.xor %88, %90 : i32 loc(#loc14)
    %92 = llvm.and %85, %21 : i32 loc(#loc14)
    %93 = llvm.icmp "eq" %92, %20 : i32 loc(#loc14)
    %94 = llvm.select %93, %20, %5 : i1, i32 loc(#loc14)
    %95 = llvm.xor %91, %94 : i32 loc(#loc14)
    %96 = llvm.and %85, %4 : i32 loc(#loc14)
    %97 = llvm.icmp "eq" %96, %20 : i32 loc(#loc14)
    %98 = llvm.select %97, %20, %1 : i1, i32 loc(#loc14)
    %99 = llvm.xor %95, %98 : i32 loc(#loc14)
    %100 = llvm.xor %20, %99 : i32 loc(#loc14)
    %101 = llvm.mul %20, %3 : i32 loc(#loc14)
    %102 = llvm.xor %100, %101 : i32 loc(#loc14)
    %103 = llvm.xor %102, %20 : i32 loc(#loc14)
    %104 = llvm.add %103, %20 : i32 loc(#loc14)
    %105 = llvm.getelementptr inbounds %13[%104] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %106 = llvm.load %105 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<2xi16> loc(#loc14)
    %107 = llvm.extractelement %106[%20 : i32] : vector<2xi16> loc(#loc14)
    %108 = llvm.extractelement %106[%15 : i32] : vector<2xi16> loc(#loc14)
    %109 = llvm.insertelement %107, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %110 = llvm.insertelement %108, %109[%15 : i32] : vector<2xi16> loc(#loc14)
    %111 = llvm.extractelement %110[%20 : i32] : vector<2xi16> loc(#loc14)
    %112 = llvm.extractelement %110[%15 : i32] : vector<2xi16> loc(#loc14)
    %113 = llvm.bitcast %111 : i16 to f16 loc(#loc14)
    %114 = llvm.bitcast %112 : i16 to f16 loc(#loc14)
    %115 = llvm.insertelement %113, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %116 = llvm.insertelement %114, %115[%15 : i32] : vector<2xf16> loc(#loc14)
    %117 = llvm.extractelement %116[%20 : i32] : vector<2xf16> loc(#loc14)
    %118 = llvm.extractelement %116[%15 : i32] : vector<2xf16> loc(#loc14)
    %119 = llvm.insertelement %117, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %120 = llvm.insertelement %118, %119[%15 : i32] : vector<2xf16> loc(#loc14)
    %121 = llvm.bitcast %120 : vector<2xf16> to i32 loc(#loc14)
    %122 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "st.global.b32 [ $1 + 0 ], { $0 };", "r,l" %121, %27 : (i32, !llvm.ptr<1>) -> !llvm.void loc(#loc14)
    llvm.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before ConvertNVGPUToLLVM (convert-nv-gpu-to-llvm) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 1024 : i32, ttg.target = "cuda:90", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @tiny_matmul_kernel(%a_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc)), %arg3: !llvm.ptr<1> loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %1 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %2 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %3 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %4 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %5 = llvm.mlir.constant(320 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %7 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(11 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %10 = llvm.mlir.constant(72 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.constant(23 : i32) : i32 loc(#loc1)
    %13 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %14 = llvm.mlir.constant(1 : index) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(120 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %22 = llvm.mlir.constant(127 : i32) : i32 loc(#loc1)
    %23 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %25 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %a = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc19)
    %a_0 = llvm.and %a, %22 : i32 loc(#loc19)
    %a_1 = llvm.urem %a_0, %21 : i32 loc(#loc19)
    %a_2 = llvm.udiv %a_0, %21 : i32 loc(#loc19)
    %a_3 = llvm.shl %a_1, %20 : i32 loc(#loc19)
    %a_4 = llvm.or %20, %a_3 : i32 loc(#loc19)
    %a_5 = llvm.shl %a_2, %19 : i32 loc(#loc19)
    %a_6 = llvm.or %a_4, %a_5 : i32 loc(#loc19)
    %a_7 = llvm.or %a_6, %20 : i32 loc(#loc19)
    %a_8 = llvm.and %a_7, %17 : i32 loc(#loc19)
    %a_9 = llvm.lshr %a_8, %16 : i32 loc(#loc19)
    %a_10 = llvm.xor %20, %a_9 : i32 loc(#loc19)
    %a_11 = llvm.xor %20, %a_10 : i32 loc(#loc19)
    %a_12 = llvm.xor %a_11, %20 : i32 loc(#loc19)
    %a_13 = llvm.add %a_12, %23 : i32 loc(#loc19)
    %a_14 = llvm.mul %a_13, %25 : i32 loc(#loc20)
    %a_15 = llvm.getelementptr %a_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc21)
    %a_16 = llvm.and %a_7, %18 : i32 loc(#loc22)
    %a_17 = llvm.shl %a_16, %15 : i32 loc(#loc22)
    %a_18 = llvm.xor %20, %a_17 : i32 loc(#loc22)
    %a_19 = llvm.xor %20, %a_18 : i32 loc(#loc22)
    %a_20 = llvm.xor %a_19, %20 : i32 loc(#loc22)
    %a_21 = llvm.add %a_20, %23 : i32 loc(#loc22)
    %a_22 = llvm.getelementptr %a_15[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc23)
    %a_23 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %a_22 : (!llvm.ptr<1>) -> i32 loc(#loc24)
    %a_24 = llvm.bitcast %a_23 : i32 to vector<2xf16> loc(#loc24)
    %a_25 = llvm.extractelement %a_24[%23 : i32] : vector<2xf16> loc(#loc24)
    %a_26 = llvm.extractelement %a_24[%14 : i32] : vector<2xf16> loc(#loc24)
    %a_27 = llvm.shl %a_2, %16 : i32 loc(#loc24)
    %a_28 = llvm.or %a_4, %a_27 : i32 loc(#loc24)
    %a_29 = llvm.and %a_28, %12 : i32 loc(#loc24)
    %a_30 = llvm.shl %a_29, %16 : i32 loc(#loc24)
    %a_31 = llvm.xor %20, %a_30 : i32 loc(#loc24)
    %a_32 = llvm.and %a_28, %11 : i32 loc(#loc24)
    %a_33 = llvm.icmp "eq" %a_32, %20 : i32 loc(#loc24)
    %a_34 = llvm.select %a_33, %20, %10 : i1, i32 loc(#loc24)
    %a_35 = llvm.xor %a_31, %a_34 : i32 loc(#loc24)
    %a_36 = llvm.xor %20, %a_35 : i32 loc(#loc24)
    %a_37 = llvm.xor %a_36, %20 : i32 loc(#loc24)
    %a_38 = llvm.xor %a_37, %20 : i32 loc(#loc24)
    %a_39 = llvm.getelementptr inbounds %13[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_40 = llvm.insertelement %a_25, %9[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_41 = llvm.insertelement %a_26, %a_40[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_42 = llvm.bitcast %a_41 : vector<2xf16> to i32 loc(#loc24)
    nvvm.stmatrix %a_39, %a_42 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc24)
    %b = llvm.getelementptr %b_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc25)
    %b_43 = llvm.getelementptr %b[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc26)
    %b_44 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %b_43 : (!llvm.ptr<1>) -> i32 loc(#loc27)
    %b_45 = llvm.bitcast %b_44 : i32 to vector<2xf16> loc(#loc27)
    %b_46 = llvm.extractelement %b_45[%23 : i32] : vector<2xf16> loc(#loc27)
    %b_47 = llvm.extractelement %b_45[%14 : i32] : vector<2xf16> loc(#loc27)
    %b_48 = llvm.getelementptr %13[512] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc27)
    %b_49 = llvm.getelementptr inbounds %b_48[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_50 = llvm.insertelement %b_46, %9[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_51 = llvm.insertelement %b_47, %b_50[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_52 = llvm.bitcast %b_51 : vector<2xf16> to i32 loc(#loc27)
    nvvm.stmatrix %b_49, %b_52 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc27)
    nvvm.barrier0 loc(#loc24)
    %a_53 = llvm.and %a_6, %8 : i32 loc(#loc24)
    %a_54 = llvm.shl %a_53, %7 : i32 loc(#loc24)
    %a_55 = llvm.xor %20, %a_54 : i32 loc(#loc24)
    %a_56 = llvm.and %a_6, %7 : i32 loc(#loc24)
    %a_57 = llvm.icmp "eq" %a_56, %20 : i32 loc(#loc24)
    %a_58 = llvm.select %a_57, %20, %10 : i1, i32 loc(#loc24)
    %a_59 = llvm.xor %a_55, %a_58 : i32 loc(#loc24)
    %a_60 = llvm.and %a_6, %25 : i32 loc(#loc24)
    %a_61 = llvm.icmp "eq" %a_60, %20 : i32 loc(#loc24)
    %a_62 = llvm.select %a_61, %20, %11 : i1, i32 loc(#loc24)
    %a_63 = llvm.xor %a_59, %a_62 : i32 loc(#loc24)
    %a_64 = llvm.xor %20, %a_63 : i32 loc(#loc24)
    %a_65 = llvm.xor %a_64, %20 : i32 loc(#loc24)
    %a_66 = llvm.xor %a_65, %20 : i32 loc(#loc24)
    %a_67 = llvm.getelementptr inbounds %13[%a_66] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_68 = nvgpu.ldmatrix %a_67, m8n8, 16 : (!llvm.ptr<3>) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc24)
    %a_69 = llvm.extractvalue %a_68[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_70 = llvm.bitcast %a_69 : i32 to vector<2xf16> loc(#loc24)
    %a_71 = llvm.extractelement %a_70[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_72 = llvm.extractelement %a_70[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_73 = llvm.extractvalue %a_68[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_74 = llvm.bitcast %a_73 : i32 to vector<2xf16> loc(#loc24)
    %a_75 = llvm.extractelement %a_74[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_76 = llvm.extractelement %a_74[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_77 = llvm.extractvalue %a_68[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_78 = llvm.bitcast %a_77 : i32 to vector<2xf16> loc(#loc24)
    %a_79 = llvm.extractelement %a_78[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_80 = llvm.extractelement %a_78[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_81 = llvm.extractvalue %a_68[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_82 = llvm.bitcast %a_81 : i32 to vector<2xf16> loc(#loc24)
    %a_83 = llvm.extractelement %a_82[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_84 = llvm.extractelement %a_82[%15 : i32] : vector<2xf16> loc(#loc24)
    %b_85 = llvm.shl %a_2, %7 : i32 loc(#loc27)
    %b_86 = llvm.or %a_4, %b_85 : i32 loc(#loc27)
    %b_87 = llvm.and %b_86, %8 : i32 loc(#loc27)
    %b_88 = llvm.shl %b_87, %7 : i32 loc(#loc27)
    %b_89 = llvm.xor %20, %b_88 : i32 loc(#loc27)
    %b_90 = llvm.and %b_86, %7 : i32 loc(#loc27)
    %b_91 = llvm.icmp "eq" %b_90, %20 : i32 loc(#loc27)
    %b_92 = llvm.select %b_91, %20, %10 : i1, i32 loc(#loc27)
    %b_93 = llvm.xor %b_89, %b_92 : i32 loc(#loc27)
    %b_94 = llvm.and %b_86, %25 : i32 loc(#loc27)
    %b_95 = llvm.icmp "eq" %b_94, %20 : i32 loc(#loc27)
    %b_96 = llvm.select %b_95, %20, %11 : i1, i32 loc(#loc27)
    %b_97 = llvm.xor %b_93, %b_96 : i32 loc(#loc27)
    %b_98 = llvm.xor %20, %b_97 : i32 loc(#loc27)
    %b_99 = llvm.xor %b_98, %20 : i32 loc(#loc27)
    %b_100 = llvm.xor %b_99, %20 : i32 loc(#loc27)
    %b_101 = llvm.getelementptr inbounds %b_48[%b_100] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_102 = nvgpu.ldmatrix %b_101, m8n8, 16 {trans} : (!llvm.ptr<3>) -> !llvm.struct<(i32, i32)> loc(#loc27)
    %b_103 = llvm.extractvalue %b_102[0] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_104 = llvm.bitcast %b_103 : i32 to vector<2xf16> loc(#loc27)
    %b_105 = llvm.extractelement %b_104[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_106 = llvm.extractelement %b_104[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_107 = llvm.extractvalue %b_102[1] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_108 = llvm.bitcast %b_107 : i32 to vector<2xf16> loc(#loc27)
    %b_109 = llvm.extractelement %b_108[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_110 = llvm.extractelement %b_108[%15 : i32] : vector<2xf16> loc(#loc27)
    %c = llvm.insertelement %a_71, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_111 = llvm.insertelement %a_72, %c[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_112 = llvm.bitcast %c_111 : vector<2xf16> to i32 loc(#loc28)
    %c_113 = llvm.insertelement %a_75, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_114 = llvm.insertelement %a_76, %c_113[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_115 = llvm.bitcast %c_114 : vector<2xf16> to i32 loc(#loc28)
    %c_116 = llvm.insertelement %a_79, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_117 = llvm.insertelement %a_80, %c_116[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_118 = llvm.bitcast %c_117 : vector<2xf16> to i32 loc(#loc28)
    %c_119 = llvm.insertelement %a_83, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_120 = llvm.insertelement %a_84, %c_119[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_121 = llvm.bitcast %c_120 : vector<2xf16> to i32 loc(#loc28)
    %c_122 = llvm.insertelement %b_105, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_123 = llvm.insertelement %b_106, %c_122[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_124 = llvm.bitcast %c_123 : vector<2xf16> to i32 loc(#loc28)
    %c_125 = llvm.insertelement %b_109, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_126 = llvm.insertelement %b_110, %c_125[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_127 = llvm.bitcast %c_126 : vector<2xf16> to i32 loc(#loc28)
    %c_128 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %24, %24, %24, %24, %c_112, %c_115, %c_118, %c_121, %c_124, %c_127 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc28)
    %c_129 = llvm.extractvalue %c_128[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_130 = llvm.extractvalue %c_128[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_131 = llvm.extractvalue %c_128[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_132 = llvm.extractvalue %c_128[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %26 = llvm.getelementptr %c_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc12)
    %27 = llvm.getelementptr %26[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc13)
    %28 = llvm.fptrunc %c_129 : f32 to f16 loc(#loc14)
    %29 = llvm.fptrunc %c_130 : f32 to f16 loc(#loc14)
    %30 = llvm.fptrunc %c_131 : f32 to f16 loc(#loc14)
    %31 = llvm.fptrunc %c_132 : f32 to f16 loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %32 = llvm.and %a_6, %16 : i32 loc(#loc14)
    %33 = llvm.shl %32, %7 : i32 loc(#loc14)
    %34 = llvm.xor %20, %33 : i32 loc(#loc14)
    %35 = llvm.and %a_6, %6 : i32 loc(#loc14)
    %36 = llvm.lshr %35, %20 : i32 loc(#loc14)
    %37 = llvm.xor %34, %36 : i32 loc(#loc14)
    %38 = llvm.select %a_61, %20, %5 : i1, i32 loc(#loc14)
    %39 = llvm.xor %37, %38 : i32 loc(#loc14)
    %40 = llvm.and %a_6, %21 : i32 loc(#loc14)
    %41 = llvm.icmp "eq" %40, %20 : i32 loc(#loc14)
    %42 = llvm.select %41, %20, %4 : i1, i32 loc(#loc14)
    %43 = llvm.xor %39, %42 : i32 loc(#loc14)
    %44 = llvm.xor %20, %43 : i32 loc(#loc14)
    %45 = llvm.mul %20, %3 : i32 loc(#loc14)
    %46 = llvm.xor %44, %45 : i32 loc(#loc14)
    %47 = llvm.xor %46, %20 : i32 loc(#loc14)
    %48 = llvm.add %47, %20 : i32 loc(#loc14)
    %49 = llvm.getelementptr inbounds %13[%48] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %50 = llvm.insertelement %28, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %51 = llvm.insertelement %29, %50[%15 : i32] : vector<2xf16> loc(#loc14)
    %52 = llvm.extractelement %51[%20 : i32] : vector<2xf16> loc(#loc14)
    %53 = llvm.extractelement %51[%15 : i32] : vector<2xf16> loc(#loc14)
    %54 = llvm.bitcast %52 : f16 to i16 loc(#loc14)
    %55 = llvm.bitcast %53 : f16 to i16 loc(#loc14)
    %56 = llvm.insertelement %54, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %57 = llvm.insertelement %55, %56[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %57, %49 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    %58 = llvm.add %47, %1 : i32 loc(#loc14)
    %59 = llvm.getelementptr inbounds %13[%58] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %60 = llvm.insertelement %30, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %61 = llvm.insertelement %31, %60[%15 : i32] : vector<2xf16> loc(#loc14)
    %62 = llvm.extractelement %61[%20 : i32] : vector<2xf16> loc(#loc14)
    %63 = llvm.extractelement %61[%15 : i32] : vector<2xf16> loc(#loc14)
    %64 = llvm.bitcast %62 : f16 to i16 loc(#loc14)
    %65 = llvm.bitcast %63 : f16 to i16 loc(#loc14)
    %66 = llvm.insertelement %64, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %67 = llvm.insertelement %65, %66[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %67, %59 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %68 = llvm.and %a_6, %18 : i32 loc(#loc14)
    %69 = llvm.shl %68, %7 : i32 loc(#loc14)
    %70 = llvm.xor %20, %69 : i32 loc(#loc14)
    %71 = llvm.and %a_6, %0 : i32 loc(#loc14)
    %72 = llvm.lshr %71, %15 : i32 loc(#loc14)
    %73 = llvm.xor %70, %72 : i32 loc(#loc14)
    %74 = llvm.select %41, %20, %5 : i1, i32 loc(#loc14)
    %75 = llvm.xor %73, %74 : i32 loc(#loc14)
    %76 = llvm.and %a_6, %4 : i32 loc(#loc14)
    %77 = llvm.icmp "eq" %76, %20 : i32 loc(#loc14)
    %78 = llvm.select %77, %20, %1 : i1, i32 loc(#loc14)
    %79 = llvm.xor %75, %78 : i32 loc(#loc14)
    %80 = llvm.xor %20, %79 : i32 loc(#loc14)
    %81 = llvm.xor %80, %45 : i32 loc(#loc14)
    %82 = llvm.xor %81, %20 : i32 loc(#loc14)
    %83 = llvm.add %82, %20 : i32 loc(#loc14)
    %84 = llvm.getelementptr inbounds %13[%83] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %85 = llvm.load %84 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<2xi16> loc(#loc14)
    %86 = llvm.extractelement %85[%20 : i32] : vector<2xi16> loc(#loc14)
    %87 = llvm.extractelement %85[%15 : i32] : vector<2xi16> loc(#loc14)
    %88 = llvm.insertelement %86, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %89 = llvm.insertelement %87, %88[%15 : i32] : vector<2xi16> loc(#loc14)
    %90 = llvm.extractelement %89[%20 : i32] : vector<2xi16> loc(#loc14)
    %91 = llvm.extractelement %89[%15 : i32] : vector<2xi16> loc(#loc14)
    %92 = llvm.bitcast %90 : i16 to f16 loc(#loc14)
    %93 = llvm.bitcast %91 : i16 to f16 loc(#loc14)
    %94 = llvm.insertelement %92, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %95 = llvm.insertelement %93, %94[%15 : i32] : vector<2xf16> loc(#loc14)
    %96 = llvm.extractelement %95[%20 : i32] : vector<2xf16> loc(#loc14)
    %97 = llvm.extractelement %95[%15 : i32] : vector<2xf16> loc(#loc14)
    %98 = llvm.insertelement %96, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %99 = llvm.insertelement %97, %98[%15 : i32] : vector<2xf16> loc(#loc14)
    %100 = llvm.bitcast %99 : vector<2xf16> to i32 loc(#loc14)
    %101 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "st.global.b32 [ $1 + 0 ], { $0 };", "r,l" %100, %27 : (i32, !llvm.ptr<1>) -> !llvm.void loc(#loc14)
    llvm.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before ConvertWarpSpecializeToLLVM (convert-warp-specialize-to-llvm) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 1024 : i32, ttg.target = "cuda:90", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @tiny_matmul_kernel(%a_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc)), %arg3: !llvm.ptr<1> loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %1 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %2 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %3 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %4 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %5 = llvm.mlir.constant(320 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %7 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(11 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %10 = llvm.mlir.constant(72 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.constant(23 : i32) : i32 loc(#loc1)
    %13 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %14 = llvm.mlir.constant(1 : index) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(120 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %22 = llvm.mlir.constant(127 : i32) : i32 loc(#loc1)
    %23 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %25 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %a = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc19)
    %a_0 = llvm.and %a, %22 : i32 loc(#loc19)
    %a_1 = llvm.urem %a_0, %21 : i32 loc(#loc19)
    %a_2 = llvm.udiv %a_0, %21 : i32 loc(#loc19)
    %a_3 = llvm.shl %a_1, %20 : i32 loc(#loc19)
    %a_4 = llvm.or %20, %a_3 : i32 loc(#loc19)
    %a_5 = llvm.shl %a_2, %19 : i32 loc(#loc19)
    %a_6 = llvm.or %a_4, %a_5 : i32 loc(#loc19)
    %a_7 = llvm.or %a_6, %20 : i32 loc(#loc19)
    %a_8 = llvm.and %a_7, %17 : i32 loc(#loc19)
    %a_9 = llvm.lshr %a_8, %16 : i32 loc(#loc19)
    %a_10 = llvm.xor %20, %a_9 : i32 loc(#loc19)
    %a_11 = llvm.xor %20, %a_10 : i32 loc(#loc19)
    %a_12 = llvm.xor %a_11, %20 : i32 loc(#loc19)
    %a_13 = llvm.add %a_12, %23 : i32 loc(#loc19)
    %a_14 = llvm.mul %a_13, %25 : i32 loc(#loc20)
    %a_15 = llvm.getelementptr %a_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc21)
    %a_16 = llvm.and %a_7, %18 : i32 loc(#loc22)
    %a_17 = llvm.shl %a_16, %15 : i32 loc(#loc22)
    %a_18 = llvm.xor %20, %a_17 : i32 loc(#loc22)
    %a_19 = llvm.xor %20, %a_18 : i32 loc(#loc22)
    %a_20 = llvm.xor %a_19, %20 : i32 loc(#loc22)
    %a_21 = llvm.add %a_20, %23 : i32 loc(#loc22)
    %a_22 = llvm.getelementptr %a_15[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc23)
    %a_23 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %a_22 : (!llvm.ptr<1>) -> i32 loc(#loc24)
    %a_24 = llvm.bitcast %a_23 : i32 to vector<2xf16> loc(#loc24)
    %a_25 = llvm.extractelement %a_24[%23 : i32] : vector<2xf16> loc(#loc24)
    %a_26 = llvm.extractelement %a_24[%14 : i32] : vector<2xf16> loc(#loc24)
    %a_27 = llvm.shl %a_2, %16 : i32 loc(#loc24)
    %a_28 = llvm.or %a_4, %a_27 : i32 loc(#loc24)
    %a_29 = llvm.and %a_28, %12 : i32 loc(#loc24)
    %a_30 = llvm.shl %a_29, %16 : i32 loc(#loc24)
    %a_31 = llvm.xor %20, %a_30 : i32 loc(#loc24)
    %a_32 = llvm.and %a_28, %11 : i32 loc(#loc24)
    %a_33 = llvm.icmp "eq" %a_32, %20 : i32 loc(#loc24)
    %a_34 = llvm.select %a_33, %20, %10 : i1, i32 loc(#loc24)
    %a_35 = llvm.xor %a_31, %a_34 : i32 loc(#loc24)
    %a_36 = llvm.xor %20, %a_35 : i32 loc(#loc24)
    %a_37 = llvm.xor %a_36, %20 : i32 loc(#loc24)
    %a_38 = llvm.xor %a_37, %20 : i32 loc(#loc24)
    %a_39 = llvm.getelementptr inbounds %13[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_40 = llvm.insertelement %a_25, %9[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_41 = llvm.insertelement %a_26, %a_40[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_42 = llvm.bitcast %a_41 : vector<2xf16> to i32 loc(#loc24)
    nvvm.stmatrix %a_39, %a_42 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc24)
    %b = llvm.getelementptr %b_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc25)
    %b_43 = llvm.getelementptr %b[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc26)
    %b_44 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %b_43 : (!llvm.ptr<1>) -> i32 loc(#loc27)
    %b_45 = llvm.bitcast %b_44 : i32 to vector<2xf16> loc(#loc27)
    %b_46 = llvm.extractelement %b_45[%23 : i32] : vector<2xf16> loc(#loc27)
    %b_47 = llvm.extractelement %b_45[%14 : i32] : vector<2xf16> loc(#loc27)
    %b_48 = llvm.getelementptr %13[512] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc27)
    %b_49 = llvm.getelementptr inbounds %b_48[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_50 = llvm.insertelement %b_46, %9[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_51 = llvm.insertelement %b_47, %b_50[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_52 = llvm.bitcast %b_51 : vector<2xf16> to i32 loc(#loc27)
    nvvm.stmatrix %b_49, %b_52 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc27)
    nvvm.barrier0 loc(#loc24)
    %a_53 = llvm.and %a_6, %8 : i32 loc(#loc24)
    %a_54 = llvm.shl %a_53, %7 : i32 loc(#loc24)
    %a_55 = llvm.xor %20, %a_54 : i32 loc(#loc24)
    %a_56 = llvm.and %a_6, %7 : i32 loc(#loc24)
    %a_57 = llvm.icmp "eq" %a_56, %20 : i32 loc(#loc24)
    %a_58 = llvm.select %a_57, %20, %10 : i1, i32 loc(#loc24)
    %a_59 = llvm.xor %a_55, %a_58 : i32 loc(#loc24)
    %a_60 = llvm.and %a_6, %25 : i32 loc(#loc24)
    %a_61 = llvm.icmp "eq" %a_60, %20 : i32 loc(#loc24)
    %a_62 = llvm.select %a_61, %20, %11 : i1, i32 loc(#loc24)
    %a_63 = llvm.xor %a_59, %a_62 : i32 loc(#loc24)
    %a_64 = llvm.xor %20, %a_63 : i32 loc(#loc24)
    %a_65 = llvm.xor %a_64, %20 : i32 loc(#loc24)
    %a_66 = llvm.xor %a_65, %20 : i32 loc(#loc24)
    %a_67 = llvm.getelementptr inbounds %13[%a_66] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_68 = llvm.ptrtoint %a_67 : !llvm.ptr<3> to i32 loc(#loc24)
    %a_69 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %a_68 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc24)
    %a_70 = llvm.extractvalue %a_69[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_71 = llvm.bitcast %a_70 : i32 to vector<2xf16> loc(#loc24)
    %a_72 = llvm.extractelement %a_71[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_73 = llvm.extractelement %a_71[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_74 = llvm.extractvalue %a_69[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_75 = llvm.bitcast %a_74 : i32 to vector<2xf16> loc(#loc24)
    %a_76 = llvm.extractelement %a_75[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_77 = llvm.extractelement %a_75[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_78 = llvm.extractvalue %a_69[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_79 = llvm.bitcast %a_78 : i32 to vector<2xf16> loc(#loc24)
    %a_80 = llvm.extractelement %a_79[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_81 = llvm.extractelement %a_79[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_82 = llvm.extractvalue %a_69[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_83 = llvm.bitcast %a_82 : i32 to vector<2xf16> loc(#loc24)
    %a_84 = llvm.extractelement %a_83[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_85 = llvm.extractelement %a_83[%15 : i32] : vector<2xf16> loc(#loc24)
    %b_86 = llvm.shl %a_2, %7 : i32 loc(#loc27)
    %b_87 = llvm.or %a_4, %b_86 : i32 loc(#loc27)
    %b_88 = llvm.and %b_87, %8 : i32 loc(#loc27)
    %b_89 = llvm.shl %b_88, %7 : i32 loc(#loc27)
    %b_90 = llvm.xor %20, %b_89 : i32 loc(#loc27)
    %b_91 = llvm.and %b_87, %7 : i32 loc(#loc27)
    %b_92 = llvm.icmp "eq" %b_91, %20 : i32 loc(#loc27)
    %b_93 = llvm.select %b_92, %20, %10 : i1, i32 loc(#loc27)
    %b_94 = llvm.xor %b_90, %b_93 : i32 loc(#loc27)
    %b_95 = llvm.and %b_87, %25 : i32 loc(#loc27)
    %b_96 = llvm.icmp "eq" %b_95, %20 : i32 loc(#loc27)
    %b_97 = llvm.select %b_96, %20, %11 : i1, i32 loc(#loc27)
    %b_98 = llvm.xor %b_94, %b_97 : i32 loc(#loc27)
    %b_99 = llvm.xor %20, %b_98 : i32 loc(#loc27)
    %b_100 = llvm.xor %b_99, %20 : i32 loc(#loc27)
    %b_101 = llvm.xor %b_100, %20 : i32 loc(#loc27)
    %b_102 = llvm.getelementptr inbounds %b_48[%b_101] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_103 = llvm.ptrtoint %b_102 : !llvm.ptr<3> to i32 loc(#loc27)
    %b_104 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x2.trans.shared.b16 {$0, $1}, [$2];", "=r,=r,r" %b_103 : (i32) -> !llvm.struct<(i32, i32)> loc(#loc27)
    %b_105 = llvm.extractvalue %b_104[0] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_106 = llvm.bitcast %b_105 : i32 to vector<2xf16> loc(#loc27)
    %b_107 = llvm.extractelement %b_106[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_108 = llvm.extractelement %b_106[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_109 = llvm.extractvalue %b_104[1] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_110 = llvm.bitcast %b_109 : i32 to vector<2xf16> loc(#loc27)
    %b_111 = llvm.extractelement %b_110[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_112 = llvm.extractelement %b_110[%15 : i32] : vector<2xf16> loc(#loc27)
    %c = llvm.insertelement %a_72, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_113 = llvm.insertelement %a_73, %c[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_114 = llvm.bitcast %c_113 : vector<2xf16> to i32 loc(#loc28)
    %c_115 = llvm.insertelement %a_76, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_116 = llvm.insertelement %a_77, %c_115[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_117 = llvm.bitcast %c_116 : vector<2xf16> to i32 loc(#loc28)
    %c_118 = llvm.insertelement %a_80, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_119 = llvm.insertelement %a_81, %c_118[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_120 = llvm.bitcast %c_119 : vector<2xf16> to i32 loc(#loc28)
    %c_121 = llvm.insertelement %a_84, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_122 = llvm.insertelement %a_85, %c_121[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_123 = llvm.bitcast %c_122 : vector<2xf16> to i32 loc(#loc28)
    %c_124 = llvm.insertelement %b_107, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_125 = llvm.insertelement %b_108, %c_124[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_126 = llvm.bitcast %c_125 : vector<2xf16> to i32 loc(#loc28)
    %c_127 = llvm.insertelement %b_111, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_128 = llvm.insertelement %b_112, %c_127[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_129 = llvm.bitcast %c_128 : vector<2xf16> to i32 loc(#loc28)
    %c_130 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %24, %24, %24, %24, %c_114, %c_117, %c_120, %c_123, %c_126, %c_129 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc28)
    %c_131 = llvm.extractvalue %c_130[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_132 = llvm.extractvalue %c_130[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_133 = llvm.extractvalue %c_130[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_134 = llvm.extractvalue %c_130[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %26 = llvm.getelementptr %c_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc12)
    %27 = llvm.getelementptr %26[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc13)
    %28 = llvm.fptrunc %c_131 : f32 to f16 loc(#loc14)
    %29 = llvm.fptrunc %c_132 : f32 to f16 loc(#loc14)
    %30 = llvm.fptrunc %c_133 : f32 to f16 loc(#loc14)
    %31 = llvm.fptrunc %c_134 : f32 to f16 loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %32 = llvm.and %a_6, %16 : i32 loc(#loc14)
    %33 = llvm.shl %32, %7 : i32 loc(#loc14)
    %34 = llvm.xor %20, %33 : i32 loc(#loc14)
    %35 = llvm.and %a_6, %6 : i32 loc(#loc14)
    %36 = llvm.lshr %35, %20 : i32 loc(#loc14)
    %37 = llvm.xor %34, %36 : i32 loc(#loc14)
    %38 = llvm.select %a_61, %20, %5 : i1, i32 loc(#loc14)
    %39 = llvm.xor %37, %38 : i32 loc(#loc14)
    %40 = llvm.and %a_6, %21 : i32 loc(#loc14)
    %41 = llvm.icmp "eq" %40, %20 : i32 loc(#loc14)
    %42 = llvm.select %41, %20, %4 : i1, i32 loc(#loc14)
    %43 = llvm.xor %39, %42 : i32 loc(#loc14)
    %44 = llvm.xor %20, %43 : i32 loc(#loc14)
    %45 = llvm.mul %20, %3 : i32 loc(#loc14)
    %46 = llvm.xor %44, %45 : i32 loc(#loc14)
    %47 = llvm.xor %46, %20 : i32 loc(#loc14)
    %48 = llvm.add %47, %20 : i32 loc(#loc14)
    %49 = llvm.getelementptr inbounds %13[%48] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %50 = llvm.insertelement %28, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %51 = llvm.insertelement %29, %50[%15 : i32] : vector<2xf16> loc(#loc14)
    %52 = llvm.extractelement %51[%20 : i32] : vector<2xf16> loc(#loc14)
    %53 = llvm.extractelement %51[%15 : i32] : vector<2xf16> loc(#loc14)
    %54 = llvm.bitcast %52 : f16 to i16 loc(#loc14)
    %55 = llvm.bitcast %53 : f16 to i16 loc(#loc14)
    %56 = llvm.insertelement %54, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %57 = llvm.insertelement %55, %56[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %57, %49 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    %58 = llvm.add %47, %1 : i32 loc(#loc14)
    %59 = llvm.getelementptr inbounds %13[%58] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %60 = llvm.insertelement %30, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %61 = llvm.insertelement %31, %60[%15 : i32] : vector<2xf16> loc(#loc14)
    %62 = llvm.extractelement %61[%20 : i32] : vector<2xf16> loc(#loc14)
    %63 = llvm.extractelement %61[%15 : i32] : vector<2xf16> loc(#loc14)
    %64 = llvm.bitcast %62 : f16 to i16 loc(#loc14)
    %65 = llvm.bitcast %63 : f16 to i16 loc(#loc14)
    %66 = llvm.insertelement %64, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %67 = llvm.insertelement %65, %66[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %67, %59 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %68 = llvm.and %a_6, %18 : i32 loc(#loc14)
    %69 = llvm.shl %68, %7 : i32 loc(#loc14)
    %70 = llvm.xor %20, %69 : i32 loc(#loc14)
    %71 = llvm.and %a_6, %0 : i32 loc(#loc14)
    %72 = llvm.lshr %71, %15 : i32 loc(#loc14)
    %73 = llvm.xor %70, %72 : i32 loc(#loc14)
    %74 = llvm.select %41, %20, %5 : i1, i32 loc(#loc14)
    %75 = llvm.xor %73, %74 : i32 loc(#loc14)
    %76 = llvm.and %a_6, %4 : i32 loc(#loc14)
    %77 = llvm.icmp "eq" %76, %20 : i32 loc(#loc14)
    %78 = llvm.select %77, %20, %1 : i1, i32 loc(#loc14)
    %79 = llvm.xor %75, %78 : i32 loc(#loc14)
    %80 = llvm.xor %20, %79 : i32 loc(#loc14)
    %81 = llvm.xor %80, %45 : i32 loc(#loc14)
    %82 = llvm.xor %81, %20 : i32 loc(#loc14)
    %83 = llvm.add %82, %20 : i32 loc(#loc14)
    %84 = llvm.getelementptr inbounds %13[%83] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %85 = llvm.load %84 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<2xi16> loc(#loc14)
    %86 = llvm.extractelement %85[%20 : i32] : vector<2xi16> loc(#loc14)
    %87 = llvm.extractelement %85[%15 : i32] : vector<2xi16> loc(#loc14)
    %88 = llvm.insertelement %86, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %89 = llvm.insertelement %87, %88[%15 : i32] : vector<2xi16> loc(#loc14)
    %90 = llvm.extractelement %89[%20 : i32] : vector<2xi16> loc(#loc14)
    %91 = llvm.extractelement %89[%15 : i32] : vector<2xi16> loc(#loc14)
    %92 = llvm.bitcast %90 : i16 to f16 loc(#loc14)
    %93 = llvm.bitcast %91 : i16 to f16 loc(#loc14)
    %94 = llvm.insertelement %92, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %95 = llvm.insertelement %93, %94[%15 : i32] : vector<2xf16> loc(#loc14)
    %96 = llvm.extractelement %95[%20 : i32] : vector<2xf16> loc(#loc14)
    %97 = llvm.extractelement %95[%15 : i32] : vector<2xf16> loc(#loc14)
    %98 = llvm.insertelement %96, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %99 = llvm.insertelement %97, %98[%15 : i32] : vector<2xf16> loc(#loc14)
    %100 = llvm.bitcast %99 : vector<2xf16> to i32 loc(#loc14)
    %101 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "st.global.b32 [ $1 + 0 ], { $0 };", "r,l" %100, %27 : (i32, !llvm.ptr<1>) -> !llvm.void loc(#loc14)
    llvm.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before ReconcileUnrealizedCastsPass (reconcile-unrealized-casts) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 1024 : i32, ttg.target = "cuda:90", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @tiny_matmul_kernel(%a_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc)), %arg3: !llvm.ptr<1> loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %1 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %2 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %3 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %4 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %5 = llvm.mlir.constant(320 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %7 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(11 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %10 = llvm.mlir.constant(72 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.constant(23 : i32) : i32 loc(#loc1)
    %13 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %14 = llvm.mlir.constant(1 : index) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(120 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %22 = llvm.mlir.constant(127 : i32) : i32 loc(#loc1)
    %23 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %25 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %a = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc19)
    %a_0 = llvm.and %a, %22 : i32 loc(#loc19)
    %a_1 = llvm.urem %a_0, %21 : i32 loc(#loc19)
    %a_2 = llvm.udiv %a_0, %21 : i32 loc(#loc19)
    %a_3 = llvm.shl %a_1, %20 : i32 loc(#loc19)
    %a_4 = llvm.or %20, %a_3 : i32 loc(#loc19)
    %a_5 = llvm.shl %a_2, %19 : i32 loc(#loc19)
    %a_6 = llvm.or %a_4, %a_5 : i32 loc(#loc19)
    %a_7 = llvm.or %a_6, %20 : i32 loc(#loc19)
    %a_8 = llvm.and %a_7, %17 : i32 loc(#loc19)
    %a_9 = llvm.lshr %a_8, %16 : i32 loc(#loc19)
    %a_10 = llvm.xor %20, %a_9 : i32 loc(#loc19)
    %a_11 = llvm.xor %20, %a_10 : i32 loc(#loc19)
    %a_12 = llvm.xor %a_11, %20 : i32 loc(#loc19)
    %a_13 = llvm.add %a_12, %23 : i32 loc(#loc19)
    %a_14 = llvm.mul %a_13, %25 : i32 loc(#loc20)
    %a_15 = llvm.getelementptr %a_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc21)
    %a_16 = llvm.and %a_7, %18 : i32 loc(#loc22)
    %a_17 = llvm.shl %a_16, %15 : i32 loc(#loc22)
    %a_18 = llvm.xor %20, %a_17 : i32 loc(#loc22)
    %a_19 = llvm.xor %20, %a_18 : i32 loc(#loc22)
    %a_20 = llvm.xor %a_19, %20 : i32 loc(#loc22)
    %a_21 = llvm.add %a_20, %23 : i32 loc(#loc22)
    %a_22 = llvm.getelementptr %a_15[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc23)
    %a_23 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %a_22 : (!llvm.ptr<1>) -> i32 loc(#loc24)
    %a_24 = llvm.bitcast %a_23 : i32 to vector<2xf16> loc(#loc24)
    %a_25 = llvm.extractelement %a_24[%23 : i32] : vector<2xf16> loc(#loc24)
    %a_26 = llvm.extractelement %a_24[%14 : i32] : vector<2xf16> loc(#loc24)
    %a_27 = llvm.shl %a_2, %16 : i32 loc(#loc24)
    %a_28 = llvm.or %a_4, %a_27 : i32 loc(#loc24)
    %a_29 = llvm.and %a_28, %12 : i32 loc(#loc24)
    %a_30 = llvm.shl %a_29, %16 : i32 loc(#loc24)
    %a_31 = llvm.xor %20, %a_30 : i32 loc(#loc24)
    %a_32 = llvm.and %a_28, %11 : i32 loc(#loc24)
    %a_33 = llvm.icmp "eq" %a_32, %20 : i32 loc(#loc24)
    %a_34 = llvm.select %a_33, %20, %10 : i1, i32 loc(#loc24)
    %a_35 = llvm.xor %a_31, %a_34 : i32 loc(#loc24)
    %a_36 = llvm.xor %20, %a_35 : i32 loc(#loc24)
    %a_37 = llvm.xor %a_36, %20 : i32 loc(#loc24)
    %a_38 = llvm.xor %a_37, %20 : i32 loc(#loc24)
    %a_39 = llvm.getelementptr inbounds %13[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_40 = llvm.insertelement %a_25, %9[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_41 = llvm.insertelement %a_26, %a_40[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_42 = llvm.bitcast %a_41 : vector<2xf16> to i32 loc(#loc24)
    nvvm.stmatrix %a_39, %a_42 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc24)
    %b = llvm.getelementptr %b_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc25)
    %b_43 = llvm.getelementptr %b[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc26)
    %b_44 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %b_43 : (!llvm.ptr<1>) -> i32 loc(#loc27)
    %b_45 = llvm.bitcast %b_44 : i32 to vector<2xf16> loc(#loc27)
    %b_46 = llvm.extractelement %b_45[%23 : i32] : vector<2xf16> loc(#loc27)
    %b_47 = llvm.extractelement %b_45[%14 : i32] : vector<2xf16> loc(#loc27)
    %b_48 = llvm.getelementptr %13[512] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc27)
    %b_49 = llvm.getelementptr inbounds %b_48[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_50 = llvm.insertelement %b_46, %9[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_51 = llvm.insertelement %b_47, %b_50[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_52 = llvm.bitcast %b_51 : vector<2xf16> to i32 loc(#loc27)
    nvvm.stmatrix %b_49, %b_52 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc27)
    nvvm.barrier0 loc(#loc24)
    %a_53 = llvm.and %a_6, %8 : i32 loc(#loc24)
    %a_54 = llvm.shl %a_53, %7 : i32 loc(#loc24)
    %a_55 = llvm.xor %20, %a_54 : i32 loc(#loc24)
    %a_56 = llvm.and %a_6, %7 : i32 loc(#loc24)
    %a_57 = llvm.icmp "eq" %a_56, %20 : i32 loc(#loc24)
    %a_58 = llvm.select %a_57, %20, %10 : i1, i32 loc(#loc24)
    %a_59 = llvm.xor %a_55, %a_58 : i32 loc(#loc24)
    %a_60 = llvm.and %a_6, %25 : i32 loc(#loc24)
    %a_61 = llvm.icmp "eq" %a_60, %20 : i32 loc(#loc24)
    %a_62 = llvm.select %a_61, %20, %11 : i1, i32 loc(#loc24)
    %a_63 = llvm.xor %a_59, %a_62 : i32 loc(#loc24)
    %a_64 = llvm.xor %20, %a_63 : i32 loc(#loc24)
    %a_65 = llvm.xor %a_64, %20 : i32 loc(#loc24)
    %a_66 = llvm.xor %a_65, %20 : i32 loc(#loc24)
    %a_67 = llvm.getelementptr inbounds %13[%a_66] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_68 = llvm.ptrtoint %a_67 : !llvm.ptr<3> to i32 loc(#loc24)
    %a_69 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %a_68 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc24)
    %a_70 = llvm.extractvalue %a_69[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_71 = llvm.bitcast %a_70 : i32 to vector<2xf16> loc(#loc24)
    %a_72 = llvm.extractelement %a_71[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_73 = llvm.extractelement %a_71[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_74 = llvm.extractvalue %a_69[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_75 = llvm.bitcast %a_74 : i32 to vector<2xf16> loc(#loc24)
    %a_76 = llvm.extractelement %a_75[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_77 = llvm.extractelement %a_75[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_78 = llvm.extractvalue %a_69[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_79 = llvm.bitcast %a_78 : i32 to vector<2xf16> loc(#loc24)
    %a_80 = llvm.extractelement %a_79[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_81 = llvm.extractelement %a_79[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_82 = llvm.extractvalue %a_69[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_83 = llvm.bitcast %a_82 : i32 to vector<2xf16> loc(#loc24)
    %a_84 = llvm.extractelement %a_83[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_85 = llvm.extractelement %a_83[%15 : i32] : vector<2xf16> loc(#loc24)
    %b_86 = llvm.shl %a_2, %7 : i32 loc(#loc27)
    %b_87 = llvm.or %a_4, %b_86 : i32 loc(#loc27)
    %b_88 = llvm.and %b_87, %8 : i32 loc(#loc27)
    %b_89 = llvm.shl %b_88, %7 : i32 loc(#loc27)
    %b_90 = llvm.xor %20, %b_89 : i32 loc(#loc27)
    %b_91 = llvm.and %b_87, %7 : i32 loc(#loc27)
    %b_92 = llvm.icmp "eq" %b_91, %20 : i32 loc(#loc27)
    %b_93 = llvm.select %b_92, %20, %10 : i1, i32 loc(#loc27)
    %b_94 = llvm.xor %b_90, %b_93 : i32 loc(#loc27)
    %b_95 = llvm.and %b_87, %25 : i32 loc(#loc27)
    %b_96 = llvm.icmp "eq" %b_95, %20 : i32 loc(#loc27)
    %b_97 = llvm.select %b_96, %20, %11 : i1, i32 loc(#loc27)
    %b_98 = llvm.xor %b_94, %b_97 : i32 loc(#loc27)
    %b_99 = llvm.xor %20, %b_98 : i32 loc(#loc27)
    %b_100 = llvm.xor %b_99, %20 : i32 loc(#loc27)
    %b_101 = llvm.xor %b_100, %20 : i32 loc(#loc27)
    %b_102 = llvm.getelementptr inbounds %b_48[%b_101] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_103 = llvm.ptrtoint %b_102 : !llvm.ptr<3> to i32 loc(#loc27)
    %b_104 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x2.trans.shared.b16 {$0, $1}, [$2];", "=r,=r,r" %b_103 : (i32) -> !llvm.struct<(i32, i32)> loc(#loc27)
    %b_105 = llvm.extractvalue %b_104[0] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_106 = llvm.bitcast %b_105 : i32 to vector<2xf16> loc(#loc27)
    %b_107 = llvm.extractelement %b_106[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_108 = llvm.extractelement %b_106[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_109 = llvm.extractvalue %b_104[1] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_110 = llvm.bitcast %b_109 : i32 to vector<2xf16> loc(#loc27)
    %b_111 = llvm.extractelement %b_110[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_112 = llvm.extractelement %b_110[%15 : i32] : vector<2xf16> loc(#loc27)
    %c = llvm.insertelement %a_72, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_113 = llvm.insertelement %a_73, %c[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_114 = llvm.bitcast %c_113 : vector<2xf16> to i32 loc(#loc28)
    %c_115 = llvm.insertelement %a_76, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_116 = llvm.insertelement %a_77, %c_115[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_117 = llvm.bitcast %c_116 : vector<2xf16> to i32 loc(#loc28)
    %c_118 = llvm.insertelement %a_80, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_119 = llvm.insertelement %a_81, %c_118[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_120 = llvm.bitcast %c_119 : vector<2xf16> to i32 loc(#loc28)
    %c_121 = llvm.insertelement %a_84, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_122 = llvm.insertelement %a_85, %c_121[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_123 = llvm.bitcast %c_122 : vector<2xf16> to i32 loc(#loc28)
    %c_124 = llvm.insertelement %b_107, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_125 = llvm.insertelement %b_108, %c_124[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_126 = llvm.bitcast %c_125 : vector<2xf16> to i32 loc(#loc28)
    %c_127 = llvm.insertelement %b_111, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_128 = llvm.insertelement %b_112, %c_127[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_129 = llvm.bitcast %c_128 : vector<2xf16> to i32 loc(#loc28)
    %c_130 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %24, %24, %24, %24, %c_114, %c_117, %c_120, %c_123, %c_126, %c_129 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc28)
    %c_131 = llvm.extractvalue %c_130[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_132 = llvm.extractvalue %c_130[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_133 = llvm.extractvalue %c_130[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_134 = llvm.extractvalue %c_130[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %26 = llvm.getelementptr %c_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc12)
    %27 = llvm.getelementptr %26[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc13)
    %28 = llvm.fptrunc %c_131 : f32 to f16 loc(#loc14)
    %29 = llvm.fptrunc %c_132 : f32 to f16 loc(#loc14)
    %30 = llvm.fptrunc %c_133 : f32 to f16 loc(#loc14)
    %31 = llvm.fptrunc %c_134 : f32 to f16 loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %32 = llvm.and %a_6, %16 : i32 loc(#loc14)
    %33 = llvm.shl %32, %7 : i32 loc(#loc14)
    %34 = llvm.xor %20, %33 : i32 loc(#loc14)
    %35 = llvm.and %a_6, %6 : i32 loc(#loc14)
    %36 = llvm.lshr %35, %20 : i32 loc(#loc14)
    %37 = llvm.xor %34, %36 : i32 loc(#loc14)
    %38 = llvm.select %a_61, %20, %5 : i1, i32 loc(#loc14)
    %39 = llvm.xor %37, %38 : i32 loc(#loc14)
    %40 = llvm.and %a_6, %21 : i32 loc(#loc14)
    %41 = llvm.icmp "eq" %40, %20 : i32 loc(#loc14)
    %42 = llvm.select %41, %20, %4 : i1, i32 loc(#loc14)
    %43 = llvm.xor %39, %42 : i32 loc(#loc14)
    %44 = llvm.xor %20, %43 : i32 loc(#loc14)
    %45 = llvm.mul %20, %3 : i32 loc(#loc14)
    %46 = llvm.xor %44, %45 : i32 loc(#loc14)
    %47 = llvm.xor %46, %20 : i32 loc(#loc14)
    %48 = llvm.add %47, %20 : i32 loc(#loc14)
    %49 = llvm.getelementptr inbounds %13[%48] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %50 = llvm.insertelement %28, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %51 = llvm.insertelement %29, %50[%15 : i32] : vector<2xf16> loc(#loc14)
    %52 = llvm.extractelement %51[%20 : i32] : vector<2xf16> loc(#loc14)
    %53 = llvm.extractelement %51[%15 : i32] : vector<2xf16> loc(#loc14)
    %54 = llvm.bitcast %52 : f16 to i16 loc(#loc14)
    %55 = llvm.bitcast %53 : f16 to i16 loc(#loc14)
    %56 = llvm.insertelement %54, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %57 = llvm.insertelement %55, %56[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %57, %49 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    %58 = llvm.add %47, %1 : i32 loc(#loc14)
    %59 = llvm.getelementptr inbounds %13[%58] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %60 = llvm.insertelement %30, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %61 = llvm.insertelement %31, %60[%15 : i32] : vector<2xf16> loc(#loc14)
    %62 = llvm.extractelement %61[%20 : i32] : vector<2xf16> loc(#loc14)
    %63 = llvm.extractelement %61[%15 : i32] : vector<2xf16> loc(#loc14)
    %64 = llvm.bitcast %62 : f16 to i16 loc(#loc14)
    %65 = llvm.bitcast %63 : f16 to i16 loc(#loc14)
    %66 = llvm.insertelement %64, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %67 = llvm.insertelement %65, %66[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %67, %59 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %68 = llvm.and %a_6, %18 : i32 loc(#loc14)
    %69 = llvm.shl %68, %7 : i32 loc(#loc14)
    %70 = llvm.xor %20, %69 : i32 loc(#loc14)
    %71 = llvm.and %a_6, %0 : i32 loc(#loc14)
    %72 = llvm.lshr %71, %15 : i32 loc(#loc14)
    %73 = llvm.xor %70, %72 : i32 loc(#loc14)
    %74 = llvm.select %41, %20, %5 : i1, i32 loc(#loc14)
    %75 = llvm.xor %73, %74 : i32 loc(#loc14)
    %76 = llvm.and %a_6, %4 : i32 loc(#loc14)
    %77 = llvm.icmp "eq" %76, %20 : i32 loc(#loc14)
    %78 = llvm.select %77, %20, %1 : i1, i32 loc(#loc14)
    %79 = llvm.xor %75, %78 : i32 loc(#loc14)
    %80 = llvm.xor %20, %79 : i32 loc(#loc14)
    %81 = llvm.xor %80, %45 : i32 loc(#loc14)
    %82 = llvm.xor %81, %20 : i32 loc(#loc14)
    %83 = llvm.add %82, %20 : i32 loc(#loc14)
    %84 = llvm.getelementptr inbounds %13[%83] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %85 = llvm.load %84 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<2xi16> loc(#loc14)
    %86 = llvm.extractelement %85[%20 : i32] : vector<2xi16> loc(#loc14)
    %87 = llvm.extractelement %85[%15 : i32] : vector<2xi16> loc(#loc14)
    %88 = llvm.insertelement %86, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %89 = llvm.insertelement %87, %88[%15 : i32] : vector<2xi16> loc(#loc14)
    %90 = llvm.extractelement %89[%20 : i32] : vector<2xi16> loc(#loc14)
    %91 = llvm.extractelement %89[%15 : i32] : vector<2xi16> loc(#loc14)
    %92 = llvm.bitcast %90 : i16 to f16 loc(#loc14)
    %93 = llvm.bitcast %91 : i16 to f16 loc(#loc14)
    %94 = llvm.insertelement %92, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %95 = llvm.insertelement %93, %94[%15 : i32] : vector<2xf16> loc(#loc14)
    %96 = llvm.extractelement %95[%20 : i32] : vector<2xf16> loc(#loc14)
    %97 = llvm.extractelement %95[%15 : i32] : vector<2xf16> loc(#loc14)
    %98 = llvm.insertelement %96, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %99 = llvm.insertelement %97, %98[%15 : i32] : vector<2xf16> loc(#loc14)
    %100 = llvm.bitcast %99 : vector<2xf16> to i32 loc(#loc14)
    %101 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "st.global.b32 [ $1 + 0 ], { $0 };", "r,l" %100, %27 : (i32, !llvm.ptr<1>) -> !llvm.void loc(#loc14)
    llvm.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 1024 : i32, ttg.target = "cuda:90", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @tiny_matmul_kernel(%a_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc)), %arg3: !llvm.ptr<1> loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %1 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %2 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %3 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %4 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %5 = llvm.mlir.constant(320 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %7 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(11 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %10 = llvm.mlir.constant(72 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.constant(23 : i32) : i32 loc(#loc1)
    %13 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %14 = llvm.mlir.constant(1 : index) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(120 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %22 = llvm.mlir.constant(127 : i32) : i32 loc(#loc1)
    %23 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %25 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %a = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc19)
    %a_0 = llvm.and %a, %22 : i32 loc(#loc19)
    %a_1 = llvm.urem %a_0, %21 : i32 loc(#loc19)
    %a_2 = llvm.udiv %a_0, %21 : i32 loc(#loc19)
    %a_3 = llvm.shl %a_1, %20 : i32 loc(#loc19)
    %a_4 = llvm.or %20, %a_3 : i32 loc(#loc19)
    %a_5 = llvm.shl %a_2, %19 : i32 loc(#loc19)
    %a_6 = llvm.or %a_4, %a_5 : i32 loc(#loc19)
    %a_7 = llvm.or %a_6, %20 : i32 loc(#loc19)
    %a_8 = llvm.and %a_7, %17 : i32 loc(#loc19)
    %a_9 = llvm.lshr %a_8, %16 : i32 loc(#loc19)
    %a_10 = llvm.xor %20, %a_9 : i32 loc(#loc19)
    %a_11 = llvm.xor %20, %a_10 : i32 loc(#loc19)
    %a_12 = llvm.xor %a_11, %20 : i32 loc(#loc19)
    %a_13 = llvm.add %a_12, %23 : i32 loc(#loc19)
    %a_14 = llvm.mul %a_13, %25 : i32 loc(#loc20)
    %a_15 = llvm.getelementptr %a_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc21)
    %a_16 = llvm.and %a_7, %18 : i32 loc(#loc22)
    %a_17 = llvm.shl %a_16, %15 : i32 loc(#loc22)
    %a_18 = llvm.xor %20, %a_17 : i32 loc(#loc22)
    %a_19 = llvm.xor %20, %a_18 : i32 loc(#loc22)
    %a_20 = llvm.xor %a_19, %20 : i32 loc(#loc22)
    %a_21 = llvm.add %a_20, %23 : i32 loc(#loc22)
    %a_22 = llvm.getelementptr %a_15[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc23)
    %a_23 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %a_22 : (!llvm.ptr<1>) -> i32 loc(#loc24)
    %a_24 = llvm.bitcast %a_23 : i32 to vector<2xf16> loc(#loc24)
    %a_25 = llvm.extractelement %a_24[%23 : i32] : vector<2xf16> loc(#loc24)
    %a_26 = llvm.extractelement %a_24[%14 : i32] : vector<2xf16> loc(#loc24)
    %a_27 = llvm.shl %a_2, %16 : i32 loc(#loc24)
    %a_28 = llvm.or %a_4, %a_27 : i32 loc(#loc24)
    %a_29 = llvm.and %a_28, %12 : i32 loc(#loc24)
    %a_30 = llvm.shl %a_29, %16 : i32 loc(#loc24)
    %a_31 = llvm.xor %20, %a_30 : i32 loc(#loc24)
    %a_32 = llvm.and %a_28, %11 : i32 loc(#loc24)
    %a_33 = llvm.icmp "eq" %a_32, %20 : i32 loc(#loc24)
    %a_34 = llvm.select %a_33, %20, %10 : i1, i32 loc(#loc24)
    %a_35 = llvm.xor %a_31, %a_34 : i32 loc(#loc24)
    %a_36 = llvm.xor %20, %a_35 : i32 loc(#loc24)
    %a_37 = llvm.xor %a_36, %20 : i32 loc(#loc24)
    %a_38 = llvm.xor %a_37, %20 : i32 loc(#loc24)
    %a_39 = llvm.getelementptr inbounds %13[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_40 = llvm.insertelement %a_25, %9[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_41 = llvm.insertelement %a_26, %a_40[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_42 = llvm.bitcast %a_41 : vector<2xf16> to i32 loc(#loc24)
    nvvm.stmatrix %a_39, %a_42 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc24)
    %b = llvm.getelementptr %b_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc25)
    %b_43 = llvm.getelementptr %b[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc26)
    %b_44 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %b_43 : (!llvm.ptr<1>) -> i32 loc(#loc27)
    %b_45 = llvm.bitcast %b_44 : i32 to vector<2xf16> loc(#loc27)
    %b_46 = llvm.extractelement %b_45[%23 : i32] : vector<2xf16> loc(#loc27)
    %b_47 = llvm.extractelement %b_45[%14 : i32] : vector<2xf16> loc(#loc27)
    %b_48 = llvm.getelementptr %13[512] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc27)
    %b_49 = llvm.getelementptr inbounds %b_48[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_50 = llvm.insertelement %b_46, %9[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_51 = llvm.insertelement %b_47, %b_50[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_52 = llvm.bitcast %b_51 : vector<2xf16> to i32 loc(#loc27)
    nvvm.stmatrix %b_49, %b_52 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc27)
    nvvm.barrier0 loc(#loc24)
    %a_53 = llvm.and %a_6, %8 : i32 loc(#loc24)
    %a_54 = llvm.shl %a_53, %7 : i32 loc(#loc24)
    %a_55 = llvm.xor %20, %a_54 : i32 loc(#loc24)
    %a_56 = llvm.and %a_6, %7 : i32 loc(#loc24)
    %a_57 = llvm.icmp "eq" %a_56, %20 : i32 loc(#loc24)
    %a_58 = llvm.select %a_57, %20, %10 : i1, i32 loc(#loc24)
    %a_59 = llvm.xor %a_55, %a_58 : i32 loc(#loc24)
    %a_60 = llvm.and %a_6, %25 : i32 loc(#loc24)
    %a_61 = llvm.icmp "eq" %a_60, %20 : i32 loc(#loc24)
    %a_62 = llvm.select %a_61, %20, %11 : i1, i32 loc(#loc24)
    %a_63 = llvm.xor %a_59, %a_62 : i32 loc(#loc24)
    %a_64 = llvm.xor %20, %a_63 : i32 loc(#loc24)
    %a_65 = llvm.xor %a_64, %20 : i32 loc(#loc24)
    %a_66 = llvm.xor %a_65, %20 : i32 loc(#loc24)
    %a_67 = llvm.getelementptr inbounds %13[%a_66] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_68 = llvm.ptrtoint %a_67 : !llvm.ptr<3> to i32 loc(#loc24)
    %a_69 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %a_68 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc24)
    %a_70 = llvm.extractvalue %a_69[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_71 = llvm.bitcast %a_70 : i32 to vector<2xf16> loc(#loc24)
    %a_72 = llvm.extractelement %a_71[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_73 = llvm.extractelement %a_71[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_74 = llvm.extractvalue %a_69[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_75 = llvm.bitcast %a_74 : i32 to vector<2xf16> loc(#loc24)
    %a_76 = llvm.extractelement %a_75[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_77 = llvm.extractelement %a_75[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_78 = llvm.extractvalue %a_69[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_79 = llvm.bitcast %a_78 : i32 to vector<2xf16> loc(#loc24)
    %a_80 = llvm.extractelement %a_79[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_81 = llvm.extractelement %a_79[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_82 = llvm.extractvalue %a_69[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_83 = llvm.bitcast %a_82 : i32 to vector<2xf16> loc(#loc24)
    %a_84 = llvm.extractelement %a_83[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_85 = llvm.extractelement %a_83[%15 : i32] : vector<2xf16> loc(#loc24)
    %b_86 = llvm.shl %a_2, %7 : i32 loc(#loc27)
    %b_87 = llvm.or %a_4, %b_86 : i32 loc(#loc27)
    %b_88 = llvm.and %b_87, %8 : i32 loc(#loc27)
    %b_89 = llvm.shl %b_88, %7 : i32 loc(#loc27)
    %b_90 = llvm.xor %20, %b_89 : i32 loc(#loc27)
    %b_91 = llvm.and %b_87, %7 : i32 loc(#loc27)
    %b_92 = llvm.icmp "eq" %b_91, %20 : i32 loc(#loc27)
    %b_93 = llvm.select %b_92, %20, %10 : i1, i32 loc(#loc27)
    %b_94 = llvm.xor %b_90, %b_93 : i32 loc(#loc27)
    %b_95 = llvm.and %b_87, %25 : i32 loc(#loc27)
    %b_96 = llvm.icmp "eq" %b_95, %20 : i32 loc(#loc27)
    %b_97 = llvm.select %b_96, %20, %11 : i1, i32 loc(#loc27)
    %b_98 = llvm.xor %b_94, %b_97 : i32 loc(#loc27)
    %b_99 = llvm.xor %20, %b_98 : i32 loc(#loc27)
    %b_100 = llvm.xor %b_99, %20 : i32 loc(#loc27)
    %b_101 = llvm.xor %b_100, %20 : i32 loc(#loc27)
    %b_102 = llvm.getelementptr inbounds %b_48[%b_101] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_103 = llvm.ptrtoint %b_102 : !llvm.ptr<3> to i32 loc(#loc27)
    %b_104 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x2.trans.shared.b16 {$0, $1}, [$2];", "=r,=r,r" %b_103 : (i32) -> !llvm.struct<(i32, i32)> loc(#loc27)
    %b_105 = llvm.extractvalue %b_104[0] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_106 = llvm.bitcast %b_105 : i32 to vector<2xf16> loc(#loc27)
    %b_107 = llvm.extractelement %b_106[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_108 = llvm.extractelement %b_106[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_109 = llvm.extractvalue %b_104[1] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_110 = llvm.bitcast %b_109 : i32 to vector<2xf16> loc(#loc27)
    %b_111 = llvm.extractelement %b_110[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_112 = llvm.extractelement %b_110[%15 : i32] : vector<2xf16> loc(#loc27)
    %c = llvm.insertelement %a_72, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_113 = llvm.insertelement %a_73, %c[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_114 = llvm.bitcast %c_113 : vector<2xf16> to i32 loc(#loc28)
    %c_115 = llvm.insertelement %a_76, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_116 = llvm.insertelement %a_77, %c_115[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_117 = llvm.bitcast %c_116 : vector<2xf16> to i32 loc(#loc28)
    %c_118 = llvm.insertelement %a_80, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_119 = llvm.insertelement %a_81, %c_118[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_120 = llvm.bitcast %c_119 : vector<2xf16> to i32 loc(#loc28)
    %c_121 = llvm.insertelement %a_84, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_122 = llvm.insertelement %a_85, %c_121[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_123 = llvm.bitcast %c_122 : vector<2xf16> to i32 loc(#loc28)
    %c_124 = llvm.insertelement %b_107, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_125 = llvm.insertelement %b_108, %c_124[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_126 = llvm.bitcast %c_125 : vector<2xf16> to i32 loc(#loc28)
    %c_127 = llvm.insertelement %b_111, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_128 = llvm.insertelement %b_112, %c_127[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_129 = llvm.bitcast %c_128 : vector<2xf16> to i32 loc(#loc28)
    %c_130 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %24, %24, %24, %24, %c_114, %c_117, %c_120, %c_123, %c_126, %c_129 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc28)
    %c_131 = llvm.extractvalue %c_130[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_132 = llvm.extractvalue %c_130[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_133 = llvm.extractvalue %c_130[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_134 = llvm.extractvalue %c_130[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %26 = llvm.getelementptr %c_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc12)
    %27 = llvm.getelementptr %26[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc13)
    %28 = llvm.fptrunc %c_131 : f32 to f16 loc(#loc14)
    %29 = llvm.fptrunc %c_132 : f32 to f16 loc(#loc14)
    %30 = llvm.fptrunc %c_133 : f32 to f16 loc(#loc14)
    %31 = llvm.fptrunc %c_134 : f32 to f16 loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %32 = llvm.and %a_6, %16 : i32 loc(#loc14)
    %33 = llvm.shl %32, %7 : i32 loc(#loc14)
    %34 = llvm.xor %20, %33 : i32 loc(#loc14)
    %35 = llvm.and %a_6, %6 : i32 loc(#loc14)
    %36 = llvm.lshr %35, %20 : i32 loc(#loc14)
    %37 = llvm.xor %34, %36 : i32 loc(#loc14)
    %38 = llvm.select %a_61, %20, %5 : i1, i32 loc(#loc14)
    %39 = llvm.xor %37, %38 : i32 loc(#loc14)
    %40 = llvm.and %a_6, %21 : i32 loc(#loc14)
    %41 = llvm.icmp "eq" %40, %20 : i32 loc(#loc14)
    %42 = llvm.select %41, %20, %4 : i1, i32 loc(#loc14)
    %43 = llvm.xor %39, %42 : i32 loc(#loc14)
    %44 = llvm.xor %20, %43 : i32 loc(#loc14)
    %45 = llvm.mul %20, %3 : i32 loc(#loc14)
    %46 = llvm.xor %44, %45 : i32 loc(#loc14)
    %47 = llvm.xor %46, %20 : i32 loc(#loc14)
    %48 = llvm.add %47, %20 : i32 loc(#loc14)
    %49 = llvm.getelementptr inbounds %13[%48] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %50 = llvm.insertelement %28, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %51 = llvm.insertelement %29, %50[%15 : i32] : vector<2xf16> loc(#loc14)
    %52 = llvm.extractelement %51[%20 : i32] : vector<2xf16> loc(#loc14)
    %53 = llvm.extractelement %51[%15 : i32] : vector<2xf16> loc(#loc14)
    %54 = llvm.bitcast %52 : f16 to i16 loc(#loc14)
    %55 = llvm.bitcast %53 : f16 to i16 loc(#loc14)
    %56 = llvm.insertelement %54, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %57 = llvm.insertelement %55, %56[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %57, %49 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    %58 = llvm.add %47, %1 : i32 loc(#loc14)
    %59 = llvm.getelementptr inbounds %13[%58] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %60 = llvm.insertelement %30, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %61 = llvm.insertelement %31, %60[%15 : i32] : vector<2xf16> loc(#loc14)
    %62 = llvm.extractelement %61[%20 : i32] : vector<2xf16> loc(#loc14)
    %63 = llvm.extractelement %61[%15 : i32] : vector<2xf16> loc(#loc14)
    %64 = llvm.bitcast %62 : f16 to i16 loc(#loc14)
    %65 = llvm.bitcast %63 : f16 to i16 loc(#loc14)
    %66 = llvm.insertelement %64, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %67 = llvm.insertelement %65, %66[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %67, %59 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %68 = llvm.and %a_6, %18 : i32 loc(#loc14)
    %69 = llvm.shl %68, %7 : i32 loc(#loc14)
    %70 = llvm.xor %20, %69 : i32 loc(#loc14)
    %71 = llvm.and %a_6, %0 : i32 loc(#loc14)
    %72 = llvm.lshr %71, %15 : i32 loc(#loc14)
    %73 = llvm.xor %70, %72 : i32 loc(#loc14)
    %74 = llvm.select %41, %20, %5 : i1, i32 loc(#loc14)
    %75 = llvm.xor %73, %74 : i32 loc(#loc14)
    %76 = llvm.and %a_6, %4 : i32 loc(#loc14)
    %77 = llvm.icmp "eq" %76, %20 : i32 loc(#loc14)
    %78 = llvm.select %77, %20, %1 : i1, i32 loc(#loc14)
    %79 = llvm.xor %75, %78 : i32 loc(#loc14)
    %80 = llvm.xor %20, %79 : i32 loc(#loc14)
    %81 = llvm.xor %80, %45 : i32 loc(#loc14)
    %82 = llvm.xor %81, %20 : i32 loc(#loc14)
    %83 = llvm.add %82, %20 : i32 loc(#loc14)
    %84 = llvm.getelementptr inbounds %13[%83] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %85 = llvm.load %84 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<2xi16> loc(#loc14)
    %86 = llvm.extractelement %85[%20 : i32] : vector<2xi16> loc(#loc14)
    %87 = llvm.extractelement %85[%15 : i32] : vector<2xi16> loc(#loc14)
    %88 = llvm.insertelement %86, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %89 = llvm.insertelement %87, %88[%15 : i32] : vector<2xi16> loc(#loc14)
    %90 = llvm.extractelement %89[%20 : i32] : vector<2xi16> loc(#loc14)
    %91 = llvm.extractelement %89[%15 : i32] : vector<2xi16> loc(#loc14)
    %92 = llvm.bitcast %90 : i16 to f16 loc(#loc14)
    %93 = llvm.bitcast %91 : i16 to f16 loc(#loc14)
    %94 = llvm.insertelement %92, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %95 = llvm.insertelement %93, %94[%15 : i32] : vector<2xf16> loc(#loc14)
    %96 = llvm.extractelement %95[%20 : i32] : vector<2xf16> loc(#loc14)
    %97 = llvm.extractelement %95[%15 : i32] : vector<2xf16> loc(#loc14)
    %98 = llvm.insertelement %96, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %99 = llvm.insertelement %97, %98[%15 : i32] : vector<2xf16> loc(#loc14)
    %100 = llvm.bitcast %99 : vector<2xf16> to i32 loc(#loc14)
    %101 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "st.global.b32 [ $1 + 0 ], { $0 };", "r,l" %100, %27 : (i32, !llvm.ptr<1>) -> !llvm.void loc(#loc14)
    llvm.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before CSE (cse) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 1024 : i32, ttg.target = "cuda:90", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @tiny_matmul_kernel(%a_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc)), %arg3: !llvm.ptr<1> loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %1 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %2 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %3 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %4 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %5 = llvm.mlir.constant(320 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %7 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(11 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %10 = llvm.mlir.constant(72 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.constant(23 : i32) : i32 loc(#loc1)
    %13 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %14 = llvm.mlir.constant(1 : index) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(120 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %22 = llvm.mlir.constant(127 : i32) : i32 loc(#loc1)
    %23 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %25 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %a = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc19)
    %a_0 = llvm.and %a, %22 : i32 loc(#loc19)
    %a_1 = llvm.urem %a_0, %21 : i32 loc(#loc19)
    %a_2 = llvm.udiv %a_0, %21 : i32 loc(#loc19)
    %a_3 = llvm.shl %a_1, %20 : i32 loc(#loc19)
    %a_4 = llvm.or %20, %a_3 : i32 loc(#loc19)
    %a_5 = llvm.shl %a_2, %19 : i32 loc(#loc19)
    %a_6 = llvm.or %a_4, %a_5 : i32 loc(#loc19)
    %a_7 = llvm.or %a_6, %20 : i32 loc(#loc19)
    %a_8 = llvm.and %a_7, %17 : i32 loc(#loc19)
    %a_9 = llvm.lshr %a_8, %16 : i32 loc(#loc19)
    %a_10 = llvm.xor %20, %a_9 : i32 loc(#loc19)
    %a_11 = llvm.xor %20, %a_10 : i32 loc(#loc19)
    %a_12 = llvm.xor %a_11, %20 : i32 loc(#loc19)
    %a_13 = llvm.add %a_12, %23 : i32 loc(#loc19)
    %a_14 = llvm.mul %a_13, %25 : i32 loc(#loc20)
    %a_15 = llvm.getelementptr %a_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc21)
    %a_16 = llvm.and %a_7, %18 : i32 loc(#loc22)
    %a_17 = llvm.shl %a_16, %15 : i32 loc(#loc22)
    %a_18 = llvm.xor %20, %a_17 : i32 loc(#loc22)
    %a_19 = llvm.xor %20, %a_18 : i32 loc(#loc22)
    %a_20 = llvm.xor %a_19, %20 : i32 loc(#loc22)
    %a_21 = llvm.add %a_20, %23 : i32 loc(#loc22)
    %a_22 = llvm.getelementptr %a_15[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc23)
    %a_23 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %a_22 : (!llvm.ptr<1>) -> i32 loc(#loc24)
    %a_24 = llvm.bitcast %a_23 : i32 to vector<2xf16> loc(#loc24)
    %a_25 = llvm.extractelement %a_24[%23 : i32] : vector<2xf16> loc(#loc24)
    %a_26 = llvm.extractelement %a_24[%14 : i32] : vector<2xf16> loc(#loc24)
    %a_27 = llvm.shl %a_2, %16 : i32 loc(#loc24)
    %a_28 = llvm.or %a_4, %a_27 : i32 loc(#loc24)
    %a_29 = llvm.and %a_28, %12 : i32 loc(#loc24)
    %a_30 = llvm.shl %a_29, %16 : i32 loc(#loc24)
    %a_31 = llvm.xor %20, %a_30 : i32 loc(#loc24)
    %a_32 = llvm.and %a_28, %11 : i32 loc(#loc24)
    %a_33 = llvm.icmp "eq" %a_32, %20 : i32 loc(#loc24)
    %a_34 = llvm.select %a_33, %20, %10 : i1, i32 loc(#loc24)
    %a_35 = llvm.xor %a_31, %a_34 : i32 loc(#loc24)
    %a_36 = llvm.xor %20, %a_35 : i32 loc(#loc24)
    %a_37 = llvm.xor %a_36, %20 : i32 loc(#loc24)
    %a_38 = llvm.xor %a_37, %20 : i32 loc(#loc24)
    %a_39 = llvm.getelementptr inbounds %13[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_40 = llvm.insertelement %a_25, %9[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_41 = llvm.insertelement %a_26, %a_40[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_42 = llvm.bitcast %a_41 : vector<2xf16> to i32 loc(#loc24)
    nvvm.stmatrix %a_39, %a_42 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc24)
    %b = llvm.getelementptr %b_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc25)
    %b_43 = llvm.getelementptr %b[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc26)
    %b_44 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %b_43 : (!llvm.ptr<1>) -> i32 loc(#loc27)
    %b_45 = llvm.bitcast %b_44 : i32 to vector<2xf16> loc(#loc27)
    %b_46 = llvm.extractelement %b_45[%23 : i32] : vector<2xf16> loc(#loc27)
    %b_47 = llvm.extractelement %b_45[%14 : i32] : vector<2xf16> loc(#loc27)
    %b_48 = llvm.getelementptr %13[512] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc27)
    %b_49 = llvm.getelementptr inbounds %b_48[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_50 = llvm.insertelement %b_46, %9[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_51 = llvm.insertelement %b_47, %b_50[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_52 = llvm.bitcast %b_51 : vector<2xf16> to i32 loc(#loc27)
    nvvm.stmatrix %b_49, %b_52 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc27)
    nvvm.barrier0 loc(#loc24)
    %a_53 = llvm.and %a_6, %8 : i32 loc(#loc24)
    %a_54 = llvm.shl %a_53, %7 : i32 loc(#loc24)
    %a_55 = llvm.xor %20, %a_54 : i32 loc(#loc24)
    %a_56 = llvm.and %a_6, %7 : i32 loc(#loc24)
    %a_57 = llvm.icmp "eq" %a_56, %20 : i32 loc(#loc24)
    %a_58 = llvm.select %a_57, %20, %10 : i1, i32 loc(#loc24)
    %a_59 = llvm.xor %a_55, %a_58 : i32 loc(#loc24)
    %a_60 = llvm.and %a_6, %25 : i32 loc(#loc24)
    %a_61 = llvm.icmp "eq" %a_60, %20 : i32 loc(#loc24)
    %a_62 = llvm.select %a_61, %20, %11 : i1, i32 loc(#loc24)
    %a_63 = llvm.xor %a_59, %a_62 : i32 loc(#loc24)
    %a_64 = llvm.xor %20, %a_63 : i32 loc(#loc24)
    %a_65 = llvm.xor %a_64, %20 : i32 loc(#loc24)
    %a_66 = llvm.xor %a_65, %20 : i32 loc(#loc24)
    %a_67 = llvm.getelementptr inbounds %13[%a_66] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_68 = llvm.ptrtoint %a_67 : !llvm.ptr<3> to i32 loc(#loc24)
    %a_69 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %a_68 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc24)
    %a_70 = llvm.extractvalue %a_69[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_71 = llvm.bitcast %a_70 : i32 to vector<2xf16> loc(#loc24)
    %a_72 = llvm.extractelement %a_71[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_73 = llvm.extractelement %a_71[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_74 = llvm.extractvalue %a_69[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_75 = llvm.bitcast %a_74 : i32 to vector<2xf16> loc(#loc24)
    %a_76 = llvm.extractelement %a_75[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_77 = llvm.extractelement %a_75[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_78 = llvm.extractvalue %a_69[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_79 = llvm.bitcast %a_78 : i32 to vector<2xf16> loc(#loc24)
    %a_80 = llvm.extractelement %a_79[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_81 = llvm.extractelement %a_79[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_82 = llvm.extractvalue %a_69[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_83 = llvm.bitcast %a_82 : i32 to vector<2xf16> loc(#loc24)
    %a_84 = llvm.extractelement %a_83[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_85 = llvm.extractelement %a_83[%15 : i32] : vector<2xf16> loc(#loc24)
    %b_86 = llvm.shl %a_2, %7 : i32 loc(#loc27)
    %b_87 = llvm.or %a_4, %b_86 : i32 loc(#loc27)
    %b_88 = llvm.and %b_87, %8 : i32 loc(#loc27)
    %b_89 = llvm.shl %b_88, %7 : i32 loc(#loc27)
    %b_90 = llvm.xor %20, %b_89 : i32 loc(#loc27)
    %b_91 = llvm.and %b_87, %7 : i32 loc(#loc27)
    %b_92 = llvm.icmp "eq" %b_91, %20 : i32 loc(#loc27)
    %b_93 = llvm.select %b_92, %20, %10 : i1, i32 loc(#loc27)
    %b_94 = llvm.xor %b_90, %b_93 : i32 loc(#loc27)
    %b_95 = llvm.and %b_87, %25 : i32 loc(#loc27)
    %b_96 = llvm.icmp "eq" %b_95, %20 : i32 loc(#loc27)
    %b_97 = llvm.select %b_96, %20, %11 : i1, i32 loc(#loc27)
    %b_98 = llvm.xor %b_94, %b_97 : i32 loc(#loc27)
    %b_99 = llvm.xor %20, %b_98 : i32 loc(#loc27)
    %b_100 = llvm.xor %b_99, %20 : i32 loc(#loc27)
    %b_101 = llvm.xor %b_100, %20 : i32 loc(#loc27)
    %b_102 = llvm.getelementptr inbounds %b_48[%b_101] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_103 = llvm.ptrtoint %b_102 : !llvm.ptr<3> to i32 loc(#loc27)
    %b_104 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x2.trans.shared.b16 {$0, $1}, [$2];", "=r,=r,r" %b_103 : (i32) -> !llvm.struct<(i32, i32)> loc(#loc27)
    %b_105 = llvm.extractvalue %b_104[0] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_106 = llvm.bitcast %b_105 : i32 to vector<2xf16> loc(#loc27)
    %b_107 = llvm.extractelement %b_106[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_108 = llvm.extractelement %b_106[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_109 = llvm.extractvalue %b_104[1] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_110 = llvm.bitcast %b_109 : i32 to vector<2xf16> loc(#loc27)
    %b_111 = llvm.extractelement %b_110[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_112 = llvm.extractelement %b_110[%15 : i32] : vector<2xf16> loc(#loc27)
    %c = llvm.insertelement %a_72, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_113 = llvm.insertelement %a_73, %c[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_114 = llvm.bitcast %c_113 : vector<2xf16> to i32 loc(#loc28)
    %c_115 = llvm.insertelement %a_76, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_116 = llvm.insertelement %a_77, %c_115[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_117 = llvm.bitcast %c_116 : vector<2xf16> to i32 loc(#loc28)
    %c_118 = llvm.insertelement %a_80, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_119 = llvm.insertelement %a_81, %c_118[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_120 = llvm.bitcast %c_119 : vector<2xf16> to i32 loc(#loc28)
    %c_121 = llvm.insertelement %a_84, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_122 = llvm.insertelement %a_85, %c_121[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_123 = llvm.bitcast %c_122 : vector<2xf16> to i32 loc(#loc28)
    %c_124 = llvm.insertelement %b_107, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_125 = llvm.insertelement %b_108, %c_124[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_126 = llvm.bitcast %c_125 : vector<2xf16> to i32 loc(#loc28)
    %c_127 = llvm.insertelement %b_111, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_128 = llvm.insertelement %b_112, %c_127[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_129 = llvm.bitcast %c_128 : vector<2xf16> to i32 loc(#loc28)
    %c_130 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %24, %24, %24, %24, %c_114, %c_117, %c_120, %c_123, %c_126, %c_129 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc28)
    %c_131 = llvm.extractvalue %c_130[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_132 = llvm.extractvalue %c_130[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_133 = llvm.extractvalue %c_130[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_134 = llvm.extractvalue %c_130[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %26 = llvm.getelementptr %c_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc12)
    %27 = llvm.getelementptr %26[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc13)
    %28 = llvm.fptrunc %c_131 : f32 to f16 loc(#loc14)
    %29 = llvm.fptrunc %c_132 : f32 to f16 loc(#loc14)
    %30 = llvm.fptrunc %c_133 : f32 to f16 loc(#loc14)
    %31 = llvm.fptrunc %c_134 : f32 to f16 loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %32 = llvm.and %a_6, %16 : i32 loc(#loc14)
    %33 = llvm.shl %32, %7 : i32 loc(#loc14)
    %34 = llvm.xor %20, %33 : i32 loc(#loc14)
    %35 = llvm.and %a_6, %6 : i32 loc(#loc14)
    %36 = llvm.lshr %35, %20 : i32 loc(#loc14)
    %37 = llvm.xor %34, %36 : i32 loc(#loc14)
    %38 = llvm.select %a_61, %20, %5 : i1, i32 loc(#loc14)
    %39 = llvm.xor %37, %38 : i32 loc(#loc14)
    %40 = llvm.and %a_6, %21 : i32 loc(#loc14)
    %41 = llvm.icmp "eq" %40, %20 : i32 loc(#loc14)
    %42 = llvm.select %41, %20, %4 : i1, i32 loc(#loc14)
    %43 = llvm.xor %39, %42 : i32 loc(#loc14)
    %44 = llvm.xor %20, %43 : i32 loc(#loc14)
    %45 = llvm.mul %20, %3 : i32 loc(#loc14)
    %46 = llvm.xor %44, %45 : i32 loc(#loc14)
    %47 = llvm.xor %46, %20 : i32 loc(#loc14)
    %48 = llvm.add %47, %20 : i32 loc(#loc14)
    %49 = llvm.getelementptr inbounds %13[%48] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %50 = llvm.insertelement %28, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %51 = llvm.insertelement %29, %50[%15 : i32] : vector<2xf16> loc(#loc14)
    %52 = llvm.extractelement %51[%20 : i32] : vector<2xf16> loc(#loc14)
    %53 = llvm.extractelement %51[%15 : i32] : vector<2xf16> loc(#loc14)
    %54 = llvm.bitcast %52 : f16 to i16 loc(#loc14)
    %55 = llvm.bitcast %53 : f16 to i16 loc(#loc14)
    %56 = llvm.insertelement %54, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %57 = llvm.insertelement %55, %56[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %57, %49 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    %58 = llvm.add %47, %1 : i32 loc(#loc14)
    %59 = llvm.getelementptr inbounds %13[%58] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %60 = llvm.insertelement %30, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %61 = llvm.insertelement %31, %60[%15 : i32] : vector<2xf16> loc(#loc14)
    %62 = llvm.extractelement %61[%20 : i32] : vector<2xf16> loc(#loc14)
    %63 = llvm.extractelement %61[%15 : i32] : vector<2xf16> loc(#loc14)
    %64 = llvm.bitcast %62 : f16 to i16 loc(#loc14)
    %65 = llvm.bitcast %63 : f16 to i16 loc(#loc14)
    %66 = llvm.insertelement %64, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %67 = llvm.insertelement %65, %66[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %67, %59 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %68 = llvm.and %a_6, %18 : i32 loc(#loc14)
    %69 = llvm.shl %68, %7 : i32 loc(#loc14)
    %70 = llvm.xor %20, %69 : i32 loc(#loc14)
    %71 = llvm.and %a_6, %0 : i32 loc(#loc14)
    %72 = llvm.lshr %71, %15 : i32 loc(#loc14)
    %73 = llvm.xor %70, %72 : i32 loc(#loc14)
    %74 = llvm.select %41, %20, %5 : i1, i32 loc(#loc14)
    %75 = llvm.xor %73, %74 : i32 loc(#loc14)
    %76 = llvm.and %a_6, %4 : i32 loc(#loc14)
    %77 = llvm.icmp "eq" %76, %20 : i32 loc(#loc14)
    %78 = llvm.select %77, %20, %1 : i1, i32 loc(#loc14)
    %79 = llvm.xor %75, %78 : i32 loc(#loc14)
    %80 = llvm.xor %20, %79 : i32 loc(#loc14)
    %81 = llvm.xor %80, %45 : i32 loc(#loc14)
    %82 = llvm.xor %81, %20 : i32 loc(#loc14)
    %83 = llvm.add %82, %20 : i32 loc(#loc14)
    %84 = llvm.getelementptr inbounds %13[%83] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %85 = llvm.load %84 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<2xi16> loc(#loc14)
    %86 = llvm.extractelement %85[%20 : i32] : vector<2xi16> loc(#loc14)
    %87 = llvm.extractelement %85[%15 : i32] : vector<2xi16> loc(#loc14)
    %88 = llvm.insertelement %86, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %89 = llvm.insertelement %87, %88[%15 : i32] : vector<2xi16> loc(#loc14)
    %90 = llvm.extractelement %89[%20 : i32] : vector<2xi16> loc(#loc14)
    %91 = llvm.extractelement %89[%15 : i32] : vector<2xi16> loc(#loc14)
    %92 = llvm.bitcast %90 : i16 to f16 loc(#loc14)
    %93 = llvm.bitcast %91 : i16 to f16 loc(#loc14)
    %94 = llvm.insertelement %92, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %95 = llvm.insertelement %93, %94[%15 : i32] : vector<2xf16> loc(#loc14)
    %96 = llvm.extractelement %95[%20 : i32] : vector<2xf16> loc(#loc14)
    %97 = llvm.extractelement %95[%15 : i32] : vector<2xf16> loc(#loc14)
    %98 = llvm.insertelement %96, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %99 = llvm.insertelement %97, %98[%15 : i32] : vector<2xf16> loc(#loc14)
    %100 = llvm.bitcast %99 : vector<2xf16> to i32 loc(#loc14)
    %101 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "st.global.b32 [ $1 + 0 ], { $0 };", "r,l" %100, %27 : (i32, !llvm.ptr<1>) -> !llvm.void loc(#loc14)
    llvm.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before SymbolDCE (symbol-dce) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 1024 : i32, ttg.target = "cuda:90", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @tiny_matmul_kernel(%a_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc)), %arg3: !llvm.ptr<1> loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %1 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %2 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %3 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %4 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %5 = llvm.mlir.constant(320 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %7 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(11 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %10 = llvm.mlir.constant(72 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.constant(23 : i32) : i32 loc(#loc1)
    %13 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %14 = llvm.mlir.constant(1 : index) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(120 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %22 = llvm.mlir.constant(127 : i32) : i32 loc(#loc1)
    %23 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %25 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %a = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc19)
    %a_0 = llvm.and %a, %22 : i32 loc(#loc19)
    %a_1 = llvm.urem %a_0, %21 : i32 loc(#loc19)
    %a_2 = llvm.udiv %a_0, %21 : i32 loc(#loc19)
    %a_3 = llvm.shl %a_1, %20 : i32 loc(#loc19)
    %a_4 = llvm.or %20, %a_3 : i32 loc(#loc19)
    %a_5 = llvm.shl %a_2, %19 : i32 loc(#loc19)
    %a_6 = llvm.or %a_4, %a_5 : i32 loc(#loc19)
    %a_7 = llvm.or %a_6, %20 : i32 loc(#loc19)
    %a_8 = llvm.and %a_7, %17 : i32 loc(#loc19)
    %a_9 = llvm.lshr %a_8, %16 : i32 loc(#loc19)
    %a_10 = llvm.xor %20, %a_9 : i32 loc(#loc19)
    %a_11 = llvm.xor %20, %a_10 : i32 loc(#loc19)
    %a_12 = llvm.xor %a_11, %20 : i32 loc(#loc19)
    %a_13 = llvm.add %a_12, %23 : i32 loc(#loc19)
    %a_14 = llvm.mul %a_13, %25 : i32 loc(#loc20)
    %a_15 = llvm.getelementptr %a_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc21)
    %a_16 = llvm.and %a_7, %18 : i32 loc(#loc22)
    %a_17 = llvm.shl %a_16, %15 : i32 loc(#loc22)
    %a_18 = llvm.xor %20, %a_17 : i32 loc(#loc22)
    %a_19 = llvm.xor %20, %a_18 : i32 loc(#loc22)
    %a_20 = llvm.xor %a_19, %20 : i32 loc(#loc22)
    %a_21 = llvm.add %a_20, %23 : i32 loc(#loc22)
    %a_22 = llvm.getelementptr %a_15[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc23)
    %a_23 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %a_22 : (!llvm.ptr<1>) -> i32 loc(#loc24)
    %a_24 = llvm.bitcast %a_23 : i32 to vector<2xf16> loc(#loc24)
    %a_25 = llvm.extractelement %a_24[%23 : i32] : vector<2xf16> loc(#loc24)
    %a_26 = llvm.extractelement %a_24[%14 : i32] : vector<2xf16> loc(#loc24)
    %a_27 = llvm.shl %a_2, %16 : i32 loc(#loc24)
    %a_28 = llvm.or %a_4, %a_27 : i32 loc(#loc24)
    %a_29 = llvm.and %a_28, %12 : i32 loc(#loc24)
    %a_30 = llvm.shl %a_29, %16 : i32 loc(#loc24)
    %a_31 = llvm.xor %20, %a_30 : i32 loc(#loc24)
    %a_32 = llvm.and %a_28, %11 : i32 loc(#loc24)
    %a_33 = llvm.icmp "eq" %a_32, %20 : i32 loc(#loc24)
    %a_34 = llvm.select %a_33, %20, %10 : i1, i32 loc(#loc24)
    %a_35 = llvm.xor %a_31, %a_34 : i32 loc(#loc24)
    %a_36 = llvm.xor %20, %a_35 : i32 loc(#loc24)
    %a_37 = llvm.xor %a_36, %20 : i32 loc(#loc24)
    %a_38 = llvm.xor %a_37, %20 : i32 loc(#loc24)
    %a_39 = llvm.getelementptr inbounds %13[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_40 = llvm.insertelement %a_25, %9[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_41 = llvm.insertelement %a_26, %a_40[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_42 = llvm.bitcast %a_41 : vector<2xf16> to i32 loc(#loc24)
    nvvm.stmatrix %a_39, %a_42 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc24)
    %b = llvm.getelementptr %b_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc25)
    %b_43 = llvm.getelementptr %b[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc26)
    %b_44 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %b_43 : (!llvm.ptr<1>) -> i32 loc(#loc27)
    %b_45 = llvm.bitcast %b_44 : i32 to vector<2xf16> loc(#loc27)
    %b_46 = llvm.extractelement %b_45[%23 : i32] : vector<2xf16> loc(#loc27)
    %b_47 = llvm.extractelement %b_45[%14 : i32] : vector<2xf16> loc(#loc27)
    %b_48 = llvm.getelementptr %13[512] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc27)
    %b_49 = llvm.getelementptr inbounds %b_48[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_50 = llvm.insertelement %b_46, %9[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_51 = llvm.insertelement %b_47, %b_50[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_52 = llvm.bitcast %b_51 : vector<2xf16> to i32 loc(#loc27)
    nvvm.stmatrix %b_49, %b_52 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc27)
    nvvm.barrier0 loc(#loc24)
    %a_53 = llvm.and %a_6, %8 : i32 loc(#loc24)
    %a_54 = llvm.shl %a_53, %7 : i32 loc(#loc24)
    %a_55 = llvm.xor %20, %a_54 : i32 loc(#loc24)
    %a_56 = llvm.and %a_6, %7 : i32 loc(#loc24)
    %a_57 = llvm.icmp "eq" %a_56, %20 : i32 loc(#loc24)
    %a_58 = llvm.select %a_57, %20, %10 : i1, i32 loc(#loc24)
    %a_59 = llvm.xor %a_55, %a_58 : i32 loc(#loc24)
    %a_60 = llvm.and %a_6, %25 : i32 loc(#loc24)
    %a_61 = llvm.icmp "eq" %a_60, %20 : i32 loc(#loc24)
    %a_62 = llvm.select %a_61, %20, %11 : i1, i32 loc(#loc24)
    %a_63 = llvm.xor %a_59, %a_62 : i32 loc(#loc24)
    %a_64 = llvm.xor %20, %a_63 : i32 loc(#loc24)
    %a_65 = llvm.xor %a_64, %20 : i32 loc(#loc24)
    %a_66 = llvm.xor %a_65, %20 : i32 loc(#loc24)
    %a_67 = llvm.getelementptr inbounds %13[%a_66] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_68 = llvm.ptrtoint %a_67 : !llvm.ptr<3> to i32 loc(#loc24)
    %a_69 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %a_68 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc24)
    %a_70 = llvm.extractvalue %a_69[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_71 = llvm.bitcast %a_70 : i32 to vector<2xf16> loc(#loc24)
    %a_72 = llvm.extractelement %a_71[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_73 = llvm.extractelement %a_71[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_74 = llvm.extractvalue %a_69[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_75 = llvm.bitcast %a_74 : i32 to vector<2xf16> loc(#loc24)
    %a_76 = llvm.extractelement %a_75[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_77 = llvm.extractelement %a_75[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_78 = llvm.extractvalue %a_69[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_79 = llvm.bitcast %a_78 : i32 to vector<2xf16> loc(#loc24)
    %a_80 = llvm.extractelement %a_79[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_81 = llvm.extractelement %a_79[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_82 = llvm.extractvalue %a_69[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_83 = llvm.bitcast %a_82 : i32 to vector<2xf16> loc(#loc24)
    %a_84 = llvm.extractelement %a_83[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_85 = llvm.extractelement %a_83[%15 : i32] : vector<2xf16> loc(#loc24)
    %b_86 = llvm.shl %a_2, %7 : i32 loc(#loc27)
    %b_87 = llvm.or %a_4, %b_86 : i32 loc(#loc27)
    %b_88 = llvm.and %b_87, %8 : i32 loc(#loc27)
    %b_89 = llvm.shl %b_88, %7 : i32 loc(#loc27)
    %b_90 = llvm.xor %20, %b_89 : i32 loc(#loc27)
    %b_91 = llvm.and %b_87, %7 : i32 loc(#loc27)
    %b_92 = llvm.icmp "eq" %b_91, %20 : i32 loc(#loc27)
    %b_93 = llvm.select %b_92, %20, %10 : i1, i32 loc(#loc27)
    %b_94 = llvm.xor %b_90, %b_93 : i32 loc(#loc27)
    %b_95 = llvm.and %b_87, %25 : i32 loc(#loc27)
    %b_96 = llvm.icmp "eq" %b_95, %20 : i32 loc(#loc27)
    %b_97 = llvm.select %b_96, %20, %11 : i1, i32 loc(#loc27)
    %b_98 = llvm.xor %b_94, %b_97 : i32 loc(#loc27)
    %b_99 = llvm.xor %20, %b_98 : i32 loc(#loc27)
    %b_100 = llvm.xor %b_99, %20 : i32 loc(#loc27)
    %b_101 = llvm.xor %b_100, %20 : i32 loc(#loc27)
    %b_102 = llvm.getelementptr inbounds %b_48[%b_101] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_103 = llvm.ptrtoint %b_102 : !llvm.ptr<3> to i32 loc(#loc27)
    %b_104 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x2.trans.shared.b16 {$0, $1}, [$2];", "=r,=r,r" %b_103 : (i32) -> !llvm.struct<(i32, i32)> loc(#loc27)
    %b_105 = llvm.extractvalue %b_104[0] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_106 = llvm.bitcast %b_105 : i32 to vector<2xf16> loc(#loc27)
    %b_107 = llvm.extractelement %b_106[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_108 = llvm.extractelement %b_106[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_109 = llvm.extractvalue %b_104[1] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_110 = llvm.bitcast %b_109 : i32 to vector<2xf16> loc(#loc27)
    %b_111 = llvm.extractelement %b_110[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_112 = llvm.extractelement %b_110[%15 : i32] : vector<2xf16> loc(#loc27)
    %c = llvm.insertelement %a_72, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_113 = llvm.insertelement %a_73, %c[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_114 = llvm.bitcast %c_113 : vector<2xf16> to i32 loc(#loc28)
    %c_115 = llvm.insertelement %a_76, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_116 = llvm.insertelement %a_77, %c_115[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_117 = llvm.bitcast %c_116 : vector<2xf16> to i32 loc(#loc28)
    %c_118 = llvm.insertelement %a_80, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_119 = llvm.insertelement %a_81, %c_118[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_120 = llvm.bitcast %c_119 : vector<2xf16> to i32 loc(#loc28)
    %c_121 = llvm.insertelement %a_84, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_122 = llvm.insertelement %a_85, %c_121[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_123 = llvm.bitcast %c_122 : vector<2xf16> to i32 loc(#loc28)
    %c_124 = llvm.insertelement %b_107, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_125 = llvm.insertelement %b_108, %c_124[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_126 = llvm.bitcast %c_125 : vector<2xf16> to i32 loc(#loc28)
    %c_127 = llvm.insertelement %b_111, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_128 = llvm.insertelement %b_112, %c_127[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_129 = llvm.bitcast %c_128 : vector<2xf16> to i32 loc(#loc28)
    %c_130 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %24, %24, %24, %24, %c_114, %c_117, %c_120, %c_123, %c_126, %c_129 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc28)
    %c_131 = llvm.extractvalue %c_130[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_132 = llvm.extractvalue %c_130[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_133 = llvm.extractvalue %c_130[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_134 = llvm.extractvalue %c_130[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %26 = llvm.getelementptr %c_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc12)
    %27 = llvm.getelementptr %26[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc13)
    %28 = llvm.fptrunc %c_131 : f32 to f16 loc(#loc14)
    %29 = llvm.fptrunc %c_132 : f32 to f16 loc(#loc14)
    %30 = llvm.fptrunc %c_133 : f32 to f16 loc(#loc14)
    %31 = llvm.fptrunc %c_134 : f32 to f16 loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %32 = llvm.and %a_6, %16 : i32 loc(#loc14)
    %33 = llvm.shl %32, %7 : i32 loc(#loc14)
    %34 = llvm.xor %20, %33 : i32 loc(#loc14)
    %35 = llvm.and %a_6, %6 : i32 loc(#loc14)
    %36 = llvm.lshr %35, %20 : i32 loc(#loc14)
    %37 = llvm.xor %34, %36 : i32 loc(#loc14)
    %38 = llvm.select %a_61, %20, %5 : i1, i32 loc(#loc14)
    %39 = llvm.xor %37, %38 : i32 loc(#loc14)
    %40 = llvm.and %a_6, %21 : i32 loc(#loc14)
    %41 = llvm.icmp "eq" %40, %20 : i32 loc(#loc14)
    %42 = llvm.select %41, %20, %4 : i1, i32 loc(#loc14)
    %43 = llvm.xor %39, %42 : i32 loc(#loc14)
    %44 = llvm.xor %20, %43 : i32 loc(#loc14)
    %45 = llvm.mul %20, %3 : i32 loc(#loc14)
    %46 = llvm.xor %44, %45 : i32 loc(#loc14)
    %47 = llvm.xor %46, %20 : i32 loc(#loc14)
    %48 = llvm.add %47, %20 : i32 loc(#loc14)
    %49 = llvm.getelementptr inbounds %13[%48] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %50 = llvm.insertelement %28, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %51 = llvm.insertelement %29, %50[%15 : i32] : vector<2xf16> loc(#loc14)
    %52 = llvm.extractelement %51[%20 : i32] : vector<2xf16> loc(#loc14)
    %53 = llvm.extractelement %51[%15 : i32] : vector<2xf16> loc(#loc14)
    %54 = llvm.bitcast %52 : f16 to i16 loc(#loc14)
    %55 = llvm.bitcast %53 : f16 to i16 loc(#loc14)
    %56 = llvm.insertelement %54, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %57 = llvm.insertelement %55, %56[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %57, %49 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    %58 = llvm.add %47, %1 : i32 loc(#loc14)
    %59 = llvm.getelementptr inbounds %13[%58] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %60 = llvm.insertelement %30, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %61 = llvm.insertelement %31, %60[%15 : i32] : vector<2xf16> loc(#loc14)
    %62 = llvm.extractelement %61[%20 : i32] : vector<2xf16> loc(#loc14)
    %63 = llvm.extractelement %61[%15 : i32] : vector<2xf16> loc(#loc14)
    %64 = llvm.bitcast %62 : f16 to i16 loc(#loc14)
    %65 = llvm.bitcast %63 : f16 to i16 loc(#loc14)
    %66 = llvm.insertelement %64, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %67 = llvm.insertelement %65, %66[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %67, %59 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %68 = llvm.and %a_6, %18 : i32 loc(#loc14)
    %69 = llvm.shl %68, %7 : i32 loc(#loc14)
    %70 = llvm.xor %20, %69 : i32 loc(#loc14)
    %71 = llvm.and %a_6, %0 : i32 loc(#loc14)
    %72 = llvm.lshr %71, %15 : i32 loc(#loc14)
    %73 = llvm.xor %70, %72 : i32 loc(#loc14)
    %74 = llvm.select %41, %20, %5 : i1, i32 loc(#loc14)
    %75 = llvm.xor %73, %74 : i32 loc(#loc14)
    %76 = llvm.and %a_6, %4 : i32 loc(#loc14)
    %77 = llvm.icmp "eq" %76, %20 : i32 loc(#loc14)
    %78 = llvm.select %77, %20, %1 : i1, i32 loc(#loc14)
    %79 = llvm.xor %75, %78 : i32 loc(#loc14)
    %80 = llvm.xor %20, %79 : i32 loc(#loc14)
    %81 = llvm.xor %80, %45 : i32 loc(#loc14)
    %82 = llvm.xor %81, %20 : i32 loc(#loc14)
    %83 = llvm.add %82, %20 : i32 loc(#loc14)
    %84 = llvm.getelementptr inbounds %13[%83] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %85 = llvm.load %84 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<2xi16> loc(#loc14)
    %86 = llvm.extractelement %85[%20 : i32] : vector<2xi16> loc(#loc14)
    %87 = llvm.extractelement %85[%15 : i32] : vector<2xi16> loc(#loc14)
    %88 = llvm.insertelement %86, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %89 = llvm.insertelement %87, %88[%15 : i32] : vector<2xi16> loc(#loc14)
    %90 = llvm.extractelement %89[%20 : i32] : vector<2xi16> loc(#loc14)
    %91 = llvm.extractelement %89[%15 : i32] : vector<2xi16> loc(#loc14)
    %92 = llvm.bitcast %90 : i16 to f16 loc(#loc14)
    %93 = llvm.bitcast %91 : i16 to f16 loc(#loc14)
    %94 = llvm.insertelement %92, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %95 = llvm.insertelement %93, %94[%15 : i32] : vector<2xf16> loc(#loc14)
    %96 = llvm.extractelement %95[%20 : i32] : vector<2xf16> loc(#loc14)
    %97 = llvm.extractelement %95[%15 : i32] : vector<2xf16> loc(#loc14)
    %98 = llvm.insertelement %96, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %99 = llvm.insertelement %97, %98[%15 : i32] : vector<2xf16> loc(#loc14)
    %100 = llvm.bitcast %99 : vector<2xf16> to i32 loc(#loc14)
    %101 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "st.global.b32 [ $1 + 0 ], { $0 };", "r,l" %100, %27 : (i32, !llvm.ptr<1>) -> !llvm.void loc(#loc14)
    llvm.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before ConvertNVVMToLLVMPass (convert-nvvm-to-llvm) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 1024 : i32, ttg.target = "cuda:90", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @tiny_matmul_kernel(%a_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc)), %arg3: !llvm.ptr<1> loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %1 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %2 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %3 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %4 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %5 = llvm.mlir.constant(320 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %7 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(11 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %10 = llvm.mlir.constant(72 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.constant(23 : i32) : i32 loc(#loc1)
    %13 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %14 = llvm.mlir.constant(1 : index) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(120 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %22 = llvm.mlir.constant(127 : i32) : i32 loc(#loc1)
    %23 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %25 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %a = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc19)
    %a_0 = llvm.and %a, %22 : i32 loc(#loc19)
    %a_1 = llvm.urem %a_0, %21 : i32 loc(#loc19)
    %a_2 = llvm.udiv %a_0, %21 : i32 loc(#loc19)
    %a_3 = llvm.shl %a_1, %20 : i32 loc(#loc19)
    %a_4 = llvm.or %20, %a_3 : i32 loc(#loc19)
    %a_5 = llvm.shl %a_2, %19 : i32 loc(#loc19)
    %a_6 = llvm.or %a_4, %a_5 : i32 loc(#loc19)
    %a_7 = llvm.or %a_6, %20 : i32 loc(#loc19)
    %a_8 = llvm.and %a_7, %17 : i32 loc(#loc19)
    %a_9 = llvm.lshr %a_8, %16 : i32 loc(#loc19)
    %a_10 = llvm.xor %20, %a_9 : i32 loc(#loc19)
    %a_11 = llvm.xor %20, %a_10 : i32 loc(#loc19)
    %a_12 = llvm.xor %a_11, %20 : i32 loc(#loc19)
    %a_13 = llvm.add %a_12, %23 : i32 loc(#loc19)
    %a_14 = llvm.mul %a_13, %25 : i32 loc(#loc20)
    %a_15 = llvm.getelementptr %a_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc21)
    %a_16 = llvm.and %a_7, %18 : i32 loc(#loc22)
    %a_17 = llvm.shl %a_16, %15 : i32 loc(#loc22)
    %a_18 = llvm.xor %20, %a_17 : i32 loc(#loc22)
    %a_19 = llvm.xor %20, %a_18 : i32 loc(#loc22)
    %a_20 = llvm.xor %a_19, %20 : i32 loc(#loc22)
    %a_21 = llvm.add %a_20, %23 : i32 loc(#loc22)
    %a_22 = llvm.getelementptr %a_15[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc23)
    %a_23 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %a_22 : (!llvm.ptr<1>) -> i32 loc(#loc24)
    %a_24 = llvm.bitcast %a_23 : i32 to vector<2xf16> loc(#loc24)
    %a_25 = llvm.extractelement %a_24[%23 : i32] : vector<2xf16> loc(#loc24)
    %a_26 = llvm.extractelement %a_24[%14 : i32] : vector<2xf16> loc(#loc24)
    %a_27 = llvm.shl %a_2, %16 : i32 loc(#loc24)
    %a_28 = llvm.or %a_4, %a_27 : i32 loc(#loc24)
    %a_29 = llvm.and %a_28, %12 : i32 loc(#loc24)
    %a_30 = llvm.shl %a_29, %16 : i32 loc(#loc24)
    %a_31 = llvm.xor %20, %a_30 : i32 loc(#loc24)
    %a_32 = llvm.and %a_28, %11 : i32 loc(#loc24)
    %a_33 = llvm.icmp "eq" %a_32, %20 : i32 loc(#loc24)
    %a_34 = llvm.select %a_33, %20, %10 : i1, i32 loc(#loc24)
    %a_35 = llvm.xor %a_31, %a_34 : i32 loc(#loc24)
    %a_36 = llvm.xor %20, %a_35 : i32 loc(#loc24)
    %a_37 = llvm.xor %a_36, %20 : i32 loc(#loc24)
    %a_38 = llvm.xor %a_37, %20 : i32 loc(#loc24)
    %a_39 = llvm.getelementptr inbounds %13[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_40 = llvm.insertelement %a_25, %9[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_41 = llvm.insertelement %a_26, %a_40[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_42 = llvm.bitcast %a_41 : vector<2xf16> to i32 loc(#loc24)
    nvvm.stmatrix %a_39, %a_42 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc24)
    %b = llvm.getelementptr %b_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc25)
    %b_43 = llvm.getelementptr %b[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc26)
    %b_44 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %b_43 : (!llvm.ptr<1>) -> i32 loc(#loc27)
    %b_45 = llvm.bitcast %b_44 : i32 to vector<2xf16> loc(#loc27)
    %b_46 = llvm.extractelement %b_45[%23 : i32] : vector<2xf16> loc(#loc27)
    %b_47 = llvm.extractelement %b_45[%14 : i32] : vector<2xf16> loc(#loc27)
    %b_48 = llvm.getelementptr %13[512] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc27)
    %b_49 = llvm.getelementptr inbounds %b_48[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_50 = llvm.insertelement %b_46, %9[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_51 = llvm.insertelement %b_47, %b_50[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_52 = llvm.bitcast %b_51 : vector<2xf16> to i32 loc(#loc27)
    nvvm.stmatrix %b_49, %b_52 {layout = #nvvm.mma_layout<row>} : !llvm.ptr<3>, i32 loc(#loc27)
    nvvm.barrier0 loc(#loc24)
    %a_53 = llvm.and %a_6, %8 : i32 loc(#loc24)
    %a_54 = llvm.shl %a_53, %7 : i32 loc(#loc24)
    %a_55 = llvm.xor %20, %a_54 : i32 loc(#loc24)
    %a_56 = llvm.and %a_6, %7 : i32 loc(#loc24)
    %a_57 = llvm.icmp "eq" %a_56, %20 : i32 loc(#loc24)
    %a_58 = llvm.select %a_57, %20, %10 : i1, i32 loc(#loc24)
    %a_59 = llvm.xor %a_55, %a_58 : i32 loc(#loc24)
    %a_60 = llvm.and %a_6, %25 : i32 loc(#loc24)
    %a_61 = llvm.icmp "eq" %a_60, %20 : i32 loc(#loc24)
    %a_62 = llvm.select %a_61, %20, %11 : i1, i32 loc(#loc24)
    %a_63 = llvm.xor %a_59, %a_62 : i32 loc(#loc24)
    %a_64 = llvm.xor %20, %a_63 : i32 loc(#loc24)
    %a_65 = llvm.xor %a_64, %20 : i32 loc(#loc24)
    %a_66 = llvm.xor %a_65, %20 : i32 loc(#loc24)
    %a_67 = llvm.getelementptr inbounds %13[%a_66] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_68 = llvm.ptrtoint %a_67 : !llvm.ptr<3> to i32 loc(#loc24)
    %a_69 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %a_68 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc24)
    %a_70 = llvm.extractvalue %a_69[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_71 = llvm.bitcast %a_70 : i32 to vector<2xf16> loc(#loc24)
    %a_72 = llvm.extractelement %a_71[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_73 = llvm.extractelement %a_71[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_74 = llvm.extractvalue %a_69[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_75 = llvm.bitcast %a_74 : i32 to vector<2xf16> loc(#loc24)
    %a_76 = llvm.extractelement %a_75[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_77 = llvm.extractelement %a_75[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_78 = llvm.extractvalue %a_69[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_79 = llvm.bitcast %a_78 : i32 to vector<2xf16> loc(#loc24)
    %a_80 = llvm.extractelement %a_79[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_81 = llvm.extractelement %a_79[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_82 = llvm.extractvalue %a_69[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_83 = llvm.bitcast %a_82 : i32 to vector<2xf16> loc(#loc24)
    %a_84 = llvm.extractelement %a_83[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_85 = llvm.extractelement %a_83[%15 : i32] : vector<2xf16> loc(#loc24)
    %b_86 = llvm.shl %a_2, %7 : i32 loc(#loc27)
    %b_87 = llvm.or %a_4, %b_86 : i32 loc(#loc27)
    %b_88 = llvm.and %b_87, %8 : i32 loc(#loc27)
    %b_89 = llvm.shl %b_88, %7 : i32 loc(#loc27)
    %b_90 = llvm.xor %20, %b_89 : i32 loc(#loc27)
    %b_91 = llvm.and %b_87, %7 : i32 loc(#loc27)
    %b_92 = llvm.icmp "eq" %b_91, %20 : i32 loc(#loc27)
    %b_93 = llvm.select %b_92, %20, %10 : i1, i32 loc(#loc27)
    %b_94 = llvm.xor %b_90, %b_93 : i32 loc(#loc27)
    %b_95 = llvm.and %b_87, %25 : i32 loc(#loc27)
    %b_96 = llvm.icmp "eq" %b_95, %20 : i32 loc(#loc27)
    %b_97 = llvm.select %b_96, %20, %11 : i1, i32 loc(#loc27)
    %b_98 = llvm.xor %b_94, %b_97 : i32 loc(#loc27)
    %b_99 = llvm.xor %20, %b_98 : i32 loc(#loc27)
    %b_100 = llvm.xor %b_99, %20 : i32 loc(#loc27)
    %b_101 = llvm.xor %b_100, %20 : i32 loc(#loc27)
    %b_102 = llvm.getelementptr inbounds %b_48[%b_101] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_103 = llvm.ptrtoint %b_102 : !llvm.ptr<3> to i32 loc(#loc27)
    %b_104 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x2.trans.shared.b16 {$0, $1}, [$2];", "=r,=r,r" %b_103 : (i32) -> !llvm.struct<(i32, i32)> loc(#loc27)
    %b_105 = llvm.extractvalue %b_104[0] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_106 = llvm.bitcast %b_105 : i32 to vector<2xf16> loc(#loc27)
    %b_107 = llvm.extractelement %b_106[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_108 = llvm.extractelement %b_106[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_109 = llvm.extractvalue %b_104[1] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_110 = llvm.bitcast %b_109 : i32 to vector<2xf16> loc(#loc27)
    %b_111 = llvm.extractelement %b_110[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_112 = llvm.extractelement %b_110[%15 : i32] : vector<2xf16> loc(#loc27)
    %c = llvm.insertelement %a_72, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_113 = llvm.insertelement %a_73, %c[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_114 = llvm.bitcast %c_113 : vector<2xf16> to i32 loc(#loc28)
    %c_115 = llvm.insertelement %a_76, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_116 = llvm.insertelement %a_77, %c_115[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_117 = llvm.bitcast %c_116 : vector<2xf16> to i32 loc(#loc28)
    %c_118 = llvm.insertelement %a_80, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_119 = llvm.insertelement %a_81, %c_118[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_120 = llvm.bitcast %c_119 : vector<2xf16> to i32 loc(#loc28)
    %c_121 = llvm.insertelement %a_84, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_122 = llvm.insertelement %a_85, %c_121[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_123 = llvm.bitcast %c_122 : vector<2xf16> to i32 loc(#loc28)
    %c_124 = llvm.insertelement %b_107, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_125 = llvm.insertelement %b_108, %c_124[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_126 = llvm.bitcast %c_125 : vector<2xf16> to i32 loc(#loc28)
    %c_127 = llvm.insertelement %b_111, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_128 = llvm.insertelement %b_112, %c_127[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_129 = llvm.bitcast %c_128 : vector<2xf16> to i32 loc(#loc28)
    %c_130 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %24, %24, %24, %24, %c_114, %c_117, %c_120, %c_123, %c_126, %c_129 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc28)
    %c_131 = llvm.extractvalue %c_130[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_132 = llvm.extractvalue %c_130[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_133 = llvm.extractvalue %c_130[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_134 = llvm.extractvalue %c_130[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %26 = llvm.getelementptr %c_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc12)
    %27 = llvm.getelementptr %26[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc13)
    %28 = llvm.fptrunc %c_131 : f32 to f16 loc(#loc14)
    %29 = llvm.fptrunc %c_132 : f32 to f16 loc(#loc14)
    %30 = llvm.fptrunc %c_133 : f32 to f16 loc(#loc14)
    %31 = llvm.fptrunc %c_134 : f32 to f16 loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %32 = llvm.and %a_6, %16 : i32 loc(#loc14)
    %33 = llvm.shl %32, %7 : i32 loc(#loc14)
    %34 = llvm.xor %20, %33 : i32 loc(#loc14)
    %35 = llvm.and %a_6, %6 : i32 loc(#loc14)
    %36 = llvm.lshr %35, %20 : i32 loc(#loc14)
    %37 = llvm.xor %34, %36 : i32 loc(#loc14)
    %38 = llvm.select %a_61, %20, %5 : i1, i32 loc(#loc14)
    %39 = llvm.xor %37, %38 : i32 loc(#loc14)
    %40 = llvm.and %a_6, %21 : i32 loc(#loc14)
    %41 = llvm.icmp "eq" %40, %20 : i32 loc(#loc14)
    %42 = llvm.select %41, %20, %4 : i1, i32 loc(#loc14)
    %43 = llvm.xor %39, %42 : i32 loc(#loc14)
    %44 = llvm.xor %20, %43 : i32 loc(#loc14)
    %45 = llvm.mul %20, %3 : i32 loc(#loc14)
    %46 = llvm.xor %44, %45 : i32 loc(#loc14)
    %47 = llvm.xor %46, %20 : i32 loc(#loc14)
    %48 = llvm.add %47, %20 : i32 loc(#loc14)
    %49 = llvm.getelementptr inbounds %13[%48] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %50 = llvm.insertelement %28, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %51 = llvm.insertelement %29, %50[%15 : i32] : vector<2xf16> loc(#loc14)
    %52 = llvm.extractelement %51[%20 : i32] : vector<2xf16> loc(#loc14)
    %53 = llvm.extractelement %51[%15 : i32] : vector<2xf16> loc(#loc14)
    %54 = llvm.bitcast %52 : f16 to i16 loc(#loc14)
    %55 = llvm.bitcast %53 : f16 to i16 loc(#loc14)
    %56 = llvm.insertelement %54, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %57 = llvm.insertelement %55, %56[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %57, %49 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    %58 = llvm.add %47, %1 : i32 loc(#loc14)
    %59 = llvm.getelementptr inbounds %13[%58] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %60 = llvm.insertelement %30, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %61 = llvm.insertelement %31, %60[%15 : i32] : vector<2xf16> loc(#loc14)
    %62 = llvm.extractelement %61[%20 : i32] : vector<2xf16> loc(#loc14)
    %63 = llvm.extractelement %61[%15 : i32] : vector<2xf16> loc(#loc14)
    %64 = llvm.bitcast %62 : f16 to i16 loc(#loc14)
    %65 = llvm.bitcast %63 : f16 to i16 loc(#loc14)
    %66 = llvm.insertelement %64, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %67 = llvm.insertelement %65, %66[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %67, %59 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %68 = llvm.and %a_6, %18 : i32 loc(#loc14)
    %69 = llvm.shl %68, %7 : i32 loc(#loc14)
    %70 = llvm.xor %20, %69 : i32 loc(#loc14)
    %71 = llvm.and %a_6, %0 : i32 loc(#loc14)
    %72 = llvm.lshr %71, %15 : i32 loc(#loc14)
    %73 = llvm.xor %70, %72 : i32 loc(#loc14)
    %74 = llvm.select %41, %20, %5 : i1, i32 loc(#loc14)
    %75 = llvm.xor %73, %74 : i32 loc(#loc14)
    %76 = llvm.and %a_6, %4 : i32 loc(#loc14)
    %77 = llvm.icmp "eq" %76, %20 : i32 loc(#loc14)
    %78 = llvm.select %77, %20, %1 : i1, i32 loc(#loc14)
    %79 = llvm.xor %75, %78 : i32 loc(#loc14)
    %80 = llvm.xor %20, %79 : i32 loc(#loc14)
    %81 = llvm.xor %80, %45 : i32 loc(#loc14)
    %82 = llvm.xor %81, %20 : i32 loc(#loc14)
    %83 = llvm.add %82, %20 : i32 loc(#loc14)
    %84 = llvm.getelementptr inbounds %13[%83] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %85 = llvm.load %84 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<2xi16> loc(#loc14)
    %86 = llvm.extractelement %85[%20 : i32] : vector<2xi16> loc(#loc14)
    %87 = llvm.extractelement %85[%15 : i32] : vector<2xi16> loc(#loc14)
    %88 = llvm.insertelement %86, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %89 = llvm.insertelement %87, %88[%15 : i32] : vector<2xi16> loc(#loc14)
    %90 = llvm.extractelement %89[%20 : i32] : vector<2xi16> loc(#loc14)
    %91 = llvm.extractelement %89[%15 : i32] : vector<2xi16> loc(#loc14)
    %92 = llvm.bitcast %90 : i16 to f16 loc(#loc14)
    %93 = llvm.bitcast %91 : i16 to f16 loc(#loc14)
    %94 = llvm.insertelement %92, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %95 = llvm.insertelement %93, %94[%15 : i32] : vector<2xf16> loc(#loc14)
    %96 = llvm.extractelement %95[%20 : i32] : vector<2xf16> loc(#loc14)
    %97 = llvm.extractelement %95[%15 : i32] : vector<2xf16> loc(#loc14)
    %98 = llvm.insertelement %96, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %99 = llvm.insertelement %97, %98[%15 : i32] : vector<2xf16> loc(#loc14)
    %100 = llvm.bitcast %99 : vector<2xf16> to i32 loc(#loc14)
    %101 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "st.global.b32 [ $1 + 0 ], { $0 };", "r,l" %100, %27 : (i32, !llvm.ptr<1>) -> !llvm.void loc(#loc14)
    llvm.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


// -----// IR Dump Before LLVMDIScope (enable-line-info) ('builtin.module' operation) //----- //
#loc = loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)
#loc16 = loc("a_ptr"(#loc))
#loc17 = loc("b_ptr"(#loc))
#loc18 = loc("c_ptr"(#loc))
module attributes {triton.shared_layout = "vector:1->(0,1);bank:1->(1,0),2->(2,0),4->(0,2),8->(0,4),16->(0,8);segment:1->(8,0),2->(4,8);outdims:dim0->16,dim1->16;reps:0", ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 1024 : i32, ttg.target = "cuda:90", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @tiny_matmul_kernel(%a_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %b_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %c_ptr: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("c_ptr"(#loc)), %arg3: !llvm.ptr<1> loc("/home/meiziyuan/triton/test_tiny_gemm.py":17:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %1 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %2 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %3 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %4 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %5 = llvm.mlir.constant(320 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %7 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(11 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %10 = llvm.mlir.constant(72 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.constant(23 : i32) : i32 loc(#loc1)
    %13 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %14 = llvm.mlir.constant(1 : index) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(120 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %22 = llvm.mlir.constant(127 : i32) : i32 loc(#loc1)
    %23 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %25 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %a = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc19)
    %a_0 = llvm.and %a, %22 : i32 loc(#loc19)
    %a_1 = llvm.urem %a_0, %21 : i32 loc(#loc19)
    %a_2 = llvm.udiv %a_0, %21 : i32 loc(#loc19)
    %a_3 = llvm.shl %a_1, %20 : i32 loc(#loc19)
    %a_4 = llvm.or %20, %a_3 : i32 loc(#loc19)
    %a_5 = llvm.shl %a_2, %19 : i32 loc(#loc19)
    %a_6 = llvm.or %a_4, %a_5 : i32 loc(#loc19)
    %a_7 = llvm.or %a_6, %20 : i32 loc(#loc19)
    %a_8 = llvm.and %a_7, %17 : i32 loc(#loc19)
    %a_9 = llvm.lshr %a_8, %16 : i32 loc(#loc19)
    %a_10 = llvm.xor %20, %a_9 : i32 loc(#loc19)
    %a_11 = llvm.xor %20, %a_10 : i32 loc(#loc19)
    %a_12 = llvm.xor %a_11, %20 : i32 loc(#loc19)
    %a_13 = llvm.add %a_12, %23 : i32 loc(#loc19)
    %a_14 = llvm.mul %a_13, %25 : i32 loc(#loc20)
    %a_15 = llvm.getelementptr %a_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc21)
    %a_16 = llvm.and %a_7, %18 : i32 loc(#loc22)
    %a_17 = llvm.shl %a_16, %15 : i32 loc(#loc22)
    %a_18 = llvm.xor %20, %a_17 : i32 loc(#loc22)
    %a_19 = llvm.xor %20, %a_18 : i32 loc(#loc22)
    %a_20 = llvm.xor %a_19, %20 : i32 loc(#loc22)
    %a_21 = llvm.add %a_20, %23 : i32 loc(#loc22)
    %a_22 = llvm.getelementptr %a_15[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc23)
    %a_23 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %a_22 : (!llvm.ptr<1>) -> i32 loc(#loc24)
    %a_24 = llvm.bitcast %a_23 : i32 to vector<2xf16> loc(#loc24)
    %a_25 = llvm.extractelement %a_24[%23 : i32] : vector<2xf16> loc(#loc24)
    %a_26 = llvm.extractelement %a_24[%14 : i32] : vector<2xf16> loc(#loc24)
    %a_27 = llvm.shl %a_2, %16 : i32 loc(#loc24)
    %a_28 = llvm.or %a_4, %a_27 : i32 loc(#loc24)
    %a_29 = llvm.and %a_28, %12 : i32 loc(#loc24)
    %a_30 = llvm.shl %a_29, %16 : i32 loc(#loc24)
    %a_31 = llvm.xor %20, %a_30 : i32 loc(#loc24)
    %a_32 = llvm.and %a_28, %11 : i32 loc(#loc24)
    %a_33 = llvm.icmp "eq" %a_32, %20 : i32 loc(#loc24)
    %a_34 = llvm.select %a_33, %20, %10 : i1, i32 loc(#loc24)
    %a_35 = llvm.xor %a_31, %a_34 : i32 loc(#loc24)
    %a_36 = llvm.xor %20, %a_35 : i32 loc(#loc24)
    %a_37 = llvm.xor %a_36, %20 : i32 loc(#loc24)
    %a_38 = llvm.xor %a_37, %20 : i32 loc(#loc24)
    %a_39 = llvm.getelementptr inbounds %13[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_40 = llvm.insertelement %a_25, %9[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_41 = llvm.insertelement %a_26, %a_40[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_42 = llvm.bitcast %a_41 : vector<2xf16> to i32 loc(#loc24)
    llvm.inline_asm has_side_effects asm_dialect = att "stmatrix.sync.aligned.x1.m8n8.shared.b16 [$0], {$1};", "r,r" %a_39, %a_42 : (!llvm.ptr<3>, i32) -> () loc(#loc24)
    %b = llvm.getelementptr %b_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc25)
    %b_43 = llvm.getelementptr %b[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc26)
    %b_44 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mov.u32 $0, 0x0;\0A\09ld.global.b32 { $0 }, [ $1 + 0 ];", "=r,l" %b_43 : (!llvm.ptr<1>) -> i32 loc(#loc27)
    %b_45 = llvm.bitcast %b_44 : i32 to vector<2xf16> loc(#loc27)
    %b_46 = llvm.extractelement %b_45[%23 : i32] : vector<2xf16> loc(#loc27)
    %b_47 = llvm.extractelement %b_45[%14 : i32] : vector<2xf16> loc(#loc27)
    %b_48 = llvm.getelementptr %13[512] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc27)
    %b_49 = llvm.getelementptr inbounds %b_48[%a_38] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_50 = llvm.insertelement %b_46, %9[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_51 = llvm.insertelement %b_47, %b_50[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_52 = llvm.bitcast %b_51 : vector<2xf16> to i32 loc(#loc27)
    llvm.inline_asm has_side_effects asm_dialect = att "stmatrix.sync.aligned.x1.m8n8.shared.b16 [$0], {$1};", "r,r" %b_49, %b_52 : (!llvm.ptr<3>, i32) -> () loc(#loc27)
    nvvm.barrier0 loc(#loc24)
    %a_53 = llvm.and %a_6, %8 : i32 loc(#loc24)
    %a_54 = llvm.shl %a_53, %7 : i32 loc(#loc24)
    %a_55 = llvm.xor %20, %a_54 : i32 loc(#loc24)
    %a_56 = llvm.and %a_6, %7 : i32 loc(#loc24)
    %a_57 = llvm.icmp "eq" %a_56, %20 : i32 loc(#loc24)
    %a_58 = llvm.select %a_57, %20, %10 : i1, i32 loc(#loc24)
    %a_59 = llvm.xor %a_55, %a_58 : i32 loc(#loc24)
    %a_60 = llvm.and %a_6, %25 : i32 loc(#loc24)
    %a_61 = llvm.icmp "eq" %a_60, %20 : i32 loc(#loc24)
    %a_62 = llvm.select %a_61, %20, %11 : i1, i32 loc(#loc24)
    %a_63 = llvm.xor %a_59, %a_62 : i32 loc(#loc24)
    %a_64 = llvm.xor %20, %a_63 : i32 loc(#loc24)
    %a_65 = llvm.xor %a_64, %20 : i32 loc(#loc24)
    %a_66 = llvm.xor %a_65, %20 : i32 loc(#loc24)
    %a_67 = llvm.getelementptr inbounds %13[%a_66] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc24)
    %a_68 = llvm.ptrtoint %a_67 : !llvm.ptr<3> to i32 loc(#loc24)
    %a_69 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %a_68 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc24)
    %a_70 = llvm.extractvalue %a_69[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_71 = llvm.bitcast %a_70 : i32 to vector<2xf16> loc(#loc24)
    %a_72 = llvm.extractelement %a_71[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_73 = llvm.extractelement %a_71[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_74 = llvm.extractvalue %a_69[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_75 = llvm.bitcast %a_74 : i32 to vector<2xf16> loc(#loc24)
    %a_76 = llvm.extractelement %a_75[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_77 = llvm.extractelement %a_75[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_78 = llvm.extractvalue %a_69[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_79 = llvm.bitcast %a_78 : i32 to vector<2xf16> loc(#loc24)
    %a_80 = llvm.extractelement %a_79[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_81 = llvm.extractelement %a_79[%15 : i32] : vector<2xf16> loc(#loc24)
    %a_82 = llvm.extractvalue %a_69[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc24)
    %a_83 = llvm.bitcast %a_82 : i32 to vector<2xf16> loc(#loc24)
    %a_84 = llvm.extractelement %a_83[%20 : i32] : vector<2xf16> loc(#loc24)
    %a_85 = llvm.extractelement %a_83[%15 : i32] : vector<2xf16> loc(#loc24)
    %b_86 = llvm.shl %a_2, %7 : i32 loc(#loc27)
    %b_87 = llvm.or %a_4, %b_86 : i32 loc(#loc27)
    %b_88 = llvm.and %b_87, %8 : i32 loc(#loc27)
    %b_89 = llvm.shl %b_88, %7 : i32 loc(#loc27)
    %b_90 = llvm.xor %20, %b_89 : i32 loc(#loc27)
    %b_91 = llvm.and %b_87, %7 : i32 loc(#loc27)
    %b_92 = llvm.icmp "eq" %b_91, %20 : i32 loc(#loc27)
    %b_93 = llvm.select %b_92, %20, %10 : i1, i32 loc(#loc27)
    %b_94 = llvm.xor %b_90, %b_93 : i32 loc(#loc27)
    %b_95 = llvm.and %b_87, %25 : i32 loc(#loc27)
    %b_96 = llvm.icmp "eq" %b_95, %20 : i32 loc(#loc27)
    %b_97 = llvm.select %b_96, %20, %11 : i1, i32 loc(#loc27)
    %b_98 = llvm.xor %b_94, %b_97 : i32 loc(#loc27)
    %b_99 = llvm.xor %20, %b_98 : i32 loc(#loc27)
    %b_100 = llvm.xor %b_99, %20 : i32 loc(#loc27)
    %b_101 = llvm.xor %b_100, %20 : i32 loc(#loc27)
    %b_102 = llvm.getelementptr inbounds %b_48[%b_101] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc27)
    %b_103 = llvm.ptrtoint %b_102 : !llvm.ptr<3> to i32 loc(#loc27)
    %b_104 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x2.trans.shared.b16 {$0, $1}, [$2];", "=r,=r,r" %b_103 : (i32) -> !llvm.struct<(i32, i32)> loc(#loc27)
    %b_105 = llvm.extractvalue %b_104[0] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_106 = llvm.bitcast %b_105 : i32 to vector<2xf16> loc(#loc27)
    %b_107 = llvm.extractelement %b_106[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_108 = llvm.extractelement %b_106[%15 : i32] : vector<2xf16> loc(#loc27)
    %b_109 = llvm.extractvalue %b_104[1] : !llvm.struct<(i32, i32)>  loc(#loc27)
    %b_110 = llvm.bitcast %b_109 : i32 to vector<2xf16> loc(#loc27)
    %b_111 = llvm.extractelement %b_110[%20 : i32] : vector<2xf16> loc(#loc27)
    %b_112 = llvm.extractelement %b_110[%15 : i32] : vector<2xf16> loc(#loc27)
    %c = llvm.insertelement %a_72, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_113 = llvm.insertelement %a_73, %c[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_114 = llvm.bitcast %c_113 : vector<2xf16> to i32 loc(#loc28)
    %c_115 = llvm.insertelement %a_76, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_116 = llvm.insertelement %a_77, %c_115[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_117 = llvm.bitcast %c_116 : vector<2xf16> to i32 loc(#loc28)
    %c_118 = llvm.insertelement %a_80, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_119 = llvm.insertelement %a_81, %c_118[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_120 = llvm.bitcast %c_119 : vector<2xf16> to i32 loc(#loc28)
    %c_121 = llvm.insertelement %a_84, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_122 = llvm.insertelement %a_85, %c_121[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_123 = llvm.bitcast %c_122 : vector<2xf16> to i32 loc(#loc28)
    %c_124 = llvm.insertelement %b_107, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_125 = llvm.insertelement %b_108, %c_124[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_126 = llvm.bitcast %c_125 : vector<2xf16> to i32 loc(#loc28)
    %c_127 = llvm.insertelement %b_111, %9[%20 : i32] : vector<2xf16> loc(#loc28)
    %c_128 = llvm.insertelement %b_112, %c_127[%15 : i32] : vector<2xf16> loc(#loc28)
    %c_129 = llvm.bitcast %c_128 : vector<2xf16> to i32 loc(#loc28)
    %c_130 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %24, %24, %24, %24, %c_114, %c_117, %c_120, %c_123, %c_126, %c_129 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc28)
    %c_131 = llvm.extractvalue %c_130[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_132 = llvm.extractvalue %c_130[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_133 = llvm.extractvalue %c_130[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %c_134 = llvm.extractvalue %c_130[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc28)
    %26 = llvm.getelementptr %c_ptr[%a_14] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc12)
    %27 = llvm.getelementptr %26[%a_21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc13)
    %28 = llvm.fptrunc %c_131 : f32 to f16 loc(#loc14)
    %29 = llvm.fptrunc %c_132 : f32 to f16 loc(#loc14)
    %30 = llvm.fptrunc %c_133 : f32 to f16 loc(#loc14)
    %31 = llvm.fptrunc %c_134 : f32 to f16 loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %32 = llvm.and %a_6, %16 : i32 loc(#loc14)
    %33 = llvm.shl %32, %7 : i32 loc(#loc14)
    %34 = llvm.xor %20, %33 : i32 loc(#loc14)
    %35 = llvm.and %a_6, %6 : i32 loc(#loc14)
    %36 = llvm.lshr %35, %20 : i32 loc(#loc14)
    %37 = llvm.xor %34, %36 : i32 loc(#loc14)
    %38 = llvm.select %a_61, %20, %5 : i1, i32 loc(#loc14)
    %39 = llvm.xor %37, %38 : i32 loc(#loc14)
    %40 = llvm.and %a_6, %21 : i32 loc(#loc14)
    %41 = llvm.icmp "eq" %40, %20 : i32 loc(#loc14)
    %42 = llvm.select %41, %20, %4 : i1, i32 loc(#loc14)
    %43 = llvm.xor %39, %42 : i32 loc(#loc14)
    %44 = llvm.xor %20, %43 : i32 loc(#loc14)
    %45 = llvm.mul %20, %3 : i32 loc(#loc14)
    %46 = llvm.xor %44, %45 : i32 loc(#loc14)
    %47 = llvm.xor %46, %20 : i32 loc(#loc14)
    %48 = llvm.add %47, %20 : i32 loc(#loc14)
    %49 = llvm.getelementptr inbounds %13[%48] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %50 = llvm.insertelement %28, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %51 = llvm.insertelement %29, %50[%15 : i32] : vector<2xf16> loc(#loc14)
    %52 = llvm.extractelement %51[%20 : i32] : vector<2xf16> loc(#loc14)
    %53 = llvm.extractelement %51[%15 : i32] : vector<2xf16> loc(#loc14)
    %54 = llvm.bitcast %52 : f16 to i16 loc(#loc14)
    %55 = llvm.bitcast %53 : f16 to i16 loc(#loc14)
    %56 = llvm.insertelement %54, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %57 = llvm.insertelement %55, %56[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %57, %49 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    %58 = llvm.add %47, %1 : i32 loc(#loc14)
    %59 = llvm.getelementptr inbounds %13[%58] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %60 = llvm.insertelement %30, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %61 = llvm.insertelement %31, %60[%15 : i32] : vector<2xf16> loc(#loc14)
    %62 = llvm.extractelement %61[%20 : i32] : vector<2xf16> loc(#loc14)
    %63 = llvm.extractelement %61[%15 : i32] : vector<2xf16> loc(#loc14)
    %64 = llvm.bitcast %62 : f16 to i16 loc(#loc14)
    %65 = llvm.bitcast %63 : f16 to i16 loc(#loc14)
    %66 = llvm.insertelement %64, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %67 = llvm.insertelement %65, %66[%15 : i32] : vector<2xi16> loc(#loc14)
    llvm.store %67, %59 {alignment = 4 : i64} : vector<2xi16>, !llvm.ptr<3> loc(#loc14)
    nvvm.barrier0 loc(#loc14)
    %68 = llvm.and %a_6, %18 : i32 loc(#loc14)
    %69 = llvm.shl %68, %7 : i32 loc(#loc14)
    %70 = llvm.xor %20, %69 : i32 loc(#loc14)
    %71 = llvm.and %a_6, %0 : i32 loc(#loc14)
    %72 = llvm.lshr %71, %15 : i32 loc(#loc14)
    %73 = llvm.xor %70, %72 : i32 loc(#loc14)
    %74 = llvm.select %41, %20, %5 : i1, i32 loc(#loc14)
    %75 = llvm.xor %73, %74 : i32 loc(#loc14)
    %76 = llvm.and %a_6, %4 : i32 loc(#loc14)
    %77 = llvm.icmp "eq" %76, %20 : i32 loc(#loc14)
    %78 = llvm.select %77, %20, %1 : i1, i32 loc(#loc14)
    %79 = llvm.xor %75, %78 : i32 loc(#loc14)
    %80 = llvm.xor %20, %79 : i32 loc(#loc14)
    %81 = llvm.xor %80, %45 : i32 loc(#loc14)
    %82 = llvm.xor %81, %20 : i32 loc(#loc14)
    %83 = llvm.add %82, %20 : i32 loc(#loc14)
    %84 = llvm.getelementptr inbounds %13[%83] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc14)
    %85 = llvm.load %84 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<2xi16> loc(#loc14)
    %86 = llvm.extractelement %85[%20 : i32] : vector<2xi16> loc(#loc14)
    %87 = llvm.extractelement %85[%15 : i32] : vector<2xi16> loc(#loc14)
    %88 = llvm.insertelement %86, %2[%20 : i32] : vector<2xi16> loc(#loc14)
    %89 = llvm.insertelement %87, %88[%15 : i32] : vector<2xi16> loc(#loc14)
    %90 = llvm.extractelement %89[%20 : i32] : vector<2xi16> loc(#loc14)
    %91 = llvm.extractelement %89[%15 : i32] : vector<2xi16> loc(#loc14)
    %92 = llvm.bitcast %90 : i16 to f16 loc(#loc14)
    %93 = llvm.bitcast %91 : i16 to f16 loc(#loc14)
    %94 = llvm.insertelement %92, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %95 = llvm.insertelement %93, %94[%15 : i32] : vector<2xf16> loc(#loc14)
    %96 = llvm.extractelement %95[%20 : i32] : vector<2xf16> loc(#loc14)
    %97 = llvm.extractelement %95[%15 : i32] : vector<2xf16> loc(#loc14)
    %98 = llvm.insertelement %96, %9[%20 : i32] : vector<2xf16> loc(#loc14)
    %99 = llvm.insertelement %97, %98[%15 : i32] : vector<2xf16> loc(#loc14)
    %100 = llvm.bitcast %99 : vector<2xf16> to i32 loc(#loc14)
    %101 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "st.global.b32 [ $1 + 0 ], { $0 };", "r,l" %100, %27 : (i32, !llvm.ptr<1>) -> !llvm.void loc(#loc14)
    llvm.return loc(#loc15)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:29)
#loc3 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:40)
#loc4 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:24)
#loc5 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:50)
#loc6 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:45)
#loc7 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":19:16)
#loc8 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:24)
#loc9 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:45)
#loc10 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":20:16)
#loc11 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":21:18)
#loc12 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:21)
#loc13 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:42)
#loc14 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:57)
#loc15 = loc("/home/meiziyuan/triton/test_tiny_gemm.py":22:4)
#loc19 = loc("a"(#loc2))
#loc20 = loc("a"(#loc3))
#loc21 = loc("a"(#loc4))
#loc22 = loc("a"(#loc5))
#loc23 = loc("a"(#loc6))
#loc24 = loc("a"(#loc7))
#loc25 = loc("b"(#loc8))
#loc26 = loc("b"(#loc9))
#loc27 = loc("b"(#loc10))
#loc28 = loc("c"(#loc11))


Test passed!
